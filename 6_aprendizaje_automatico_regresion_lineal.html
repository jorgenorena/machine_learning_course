<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="es" xml:lang="es"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Introducción al Aprendizaje Automático con Regresión Lineal – Aprendizaje Automático para Físicos</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-e13f217ceb0135cb77e1494052e28e8a.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Sin resultados",
    "search-matching-documents-text": "documentos encontrados",
    "search-copy-link-title": "Copiar el enlace en la búsqueda",
    "search-hide-matches-text": "Ocultar resultados adicionales",
    "search-more-match-text": "resultado adicional en este documento",
    "search-more-matches-text": "resultados adicionales en este documento",
    "search-clear-button-title": "Borrar",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar",
    "search-label": "Buscar"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar docked nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Aprendizaje Automático para Físicos</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Buscar"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Navegación de palanca" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-clases" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Clases</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-clases">    
        <li class="dropdown-header">Probabilidad y Estadística</li>
        <li>
    <a class="dropdown-item" href="./1_probabilidad.html">
 <span class="dropdown-text">1. Probabilidad</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./2_distribuciones_y_estimacion.html">
 <span class="dropdown-text">2. Distribuciones y Estimación</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./3_verosimilitud.html">
 <span class="dropdown-text">3. Verosimilitud</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./4_minimos_cuadrados_intervalos.html">
 <span class="dropdown-text">4. Mínimos Cuadrados e Intervalos</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./5_testeo_de_hipotesis_entropia.html">
 <span class="dropdown-text">5. Testeo de Hipótesis y Entropía</span></a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li class="dropdown-header">Aprendizaje Automático</li>
        <li>
    <a class="dropdown-item" href="./6_aprendizaje_automatico_regresion_lineal.html">
 <span class="dropdown-text">6. Aprendizaje Automático y Regresión Lineal</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./7_clasificacion.html">
 <span class="dropdown-text">7. Clasificación</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./8_seleccion_de_modelos.html">
 <span class="dropdown-text">8. Selección de Modelos</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./9_arboles_bosques_boosting.html">
 <span class="dropdown-text">9. Árboles, Bosques y Boosting</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./10_svm_y_no_supervisado.html">
 <span class="dropdown-text">10. SVM y Aprendizaje No Supervisado</span></a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li class="dropdown-header">Redes Neuronales</li>
        <li>
    <a class="dropdown-item" href="./11_perceptron_y_redes_conexas.html">
 <span class="dropdown-text">11. Perceptrón y Redes Conexas y Pérdidas</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./12_gradient_descent_and_autodiff.html">
 <span class="dropdown-text">12. Descenso de Gradiente y Auto-diferenciación</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./13_evaluacion_y_regularizacion_de_nn.html">
 <span class="dropdown-text">13. Evaluación y Regularización de redes neuronales</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./14_redes_convolucionales.html">
 <span class="dropdown-text">14. Redes Convolucionales</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./15_redes_residuales.html">
 <span class="dropdown-text">15. Redes Residuales</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./16_transformadores.html">
 <span class="dropdown-text">16. Transformadores y el mecanismo de atención</span></a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li class="dropdown-header">Algunas aplicaciones</li>
        <li>
    <a class="dropdown-item" href="./17_flujos_normalizantes.html">
 <span class="dropdown-text">17. Flujos Normalizantes</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./18_PINNs.html">
 <span class="dropdown-text">18. Redes Neuronales Informadas por la Física (PINNs)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./19_Operador_Neural.html">
 <span class="dropdown-text">19. Operadores Neuronales</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="./about.html"> 
<span class="menu-text">Acerca de</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./6_aprendizaje_automatico_regresion_lineal.html">Aprendizaje Automático</a></li><li class="breadcrumb-item"><a href="./6_aprendizaje_automatico_regresion_lineal.html">6. Aprendizaje Automático y Regresión Lineal</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Probabilidad y Estadística</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Alternar sección">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1_probabilidad.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1. Probabilidad</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2_distribuciones_y_estimacion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2. Distribuciones y Estimación</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3_verosimilitud.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3. Verosimilitud</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./4_minimos_cuadrados_intervalos.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4. Mínimos Cuadrados e Intervalos</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./5_testeo_de_hipotesis_entropia.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5. Testeo de Hipótesis y Entropía</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Aprendizaje Automático</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Alternar sección">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./6_aprendizaje_automatico_regresion_lineal.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">6. Aprendizaje Automático y Regresión Lineal</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./7_clasificacion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">7. Clasificación</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./8_seleccion_de_modelos.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">8. Selección de Modelos</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./9_arboles_bosques_boosting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">9. Árboles, Bosques y Boosting</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10_svm_y_no_supervisado.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">10. SVM y Aprendizaje No Supervisado</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Redes Neuronales</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Alternar sección">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11_perceptron_y_redes_conexas.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">11. Perceptrón, Redes Conexas y Pérdidas</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12_gradient_descent_and_autodiff.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">12. Descenso de Gradiente y Auto-diferenciación</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13_evaluacion_y_regularizacion_de_nn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">13. Evaluación y Regularización de redes neuronales</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14_redes_convolucionales.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">14. Redes Convolucionales</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./15_redes_residuales.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">15. Redes Residuales</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./16_transformadores.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">16. Transformadores y el mecanismo de atención</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Algunas aplicaciones</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Alternar sección">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./17_flujos_normalizantes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">17. Flujos Normalizantes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./18_PINNs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">18. Redes Neuronales Informadas por la Física (PINNs)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./19_Operador_Neural.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">19. Operadores Neuronales</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">En esta página</h2>
   
  <ul>
  <li><a href="#qué-es-el-aprendizaje-automático" id="toc-qué-es-el-aprendizaje-automático" class="nav-link active" data-scroll-target="#qué-es-el-aprendizaje-automático">¿Qué es el Aprendizaje Automático?</a>
  <ul class="collapse">
  <li><a href="#predicción-vs-inferencia" id="toc-predicción-vs-inferencia" class="nav-link" data-scroll-target="#predicción-vs-inferencia">Predicción vs inferencia</a></li>
  <li><a href="#modelos-paramétricos-vs-no-paramétricos" id="toc-modelos-paramétricos-vs-no-paramétricos" class="nav-link" data-scroll-target="#modelos-paramétricos-vs-no-paramétricos">Modelos paramétricos vs no paramétricos</a></li>
  <li><a href="#aprendizaje-supervisado-vs-no-supervisado" id="toc-aprendizaje-supervisado-vs-no-supervisado" class="nav-link" data-scroll-target="#aprendizaje-supervisado-vs-no-supervisado">Aprendizaje supervisado vs no supervisado</a></li>
  <li><a href="#regresión-contra-clasificación" id="toc-regresión-contra-clasificación" class="nav-link" data-scroll-target="#regresión-contra-clasificación">Regresión contra clasificación</a></li>
  </ul></li>
  <li><a href="#regresión-lineal" id="toc-regresión-lineal" class="nav-link" data-scroll-target="#regresión-lineal">Regresión Lineal</a>
  <ul class="collapse">
  <li><a href="#regresión-lineal-simple" id="toc-regresión-lineal-simple" class="nav-link" data-scroll-target="#regresión-lineal-simple">Regresión lineal simple</a></li>
  <li><a href="#determinando-la-precisión-de-los-coeficientes" id="toc-determinando-la-precisión-de-los-coeficientes" class="nav-link" data-scroll-target="#determinando-la-precisión-de-los-coeficientes">Determinando la precisión de los coeficientes</a></li>
  <li><a href="#evaluar-la-precisión-de-un-modelo" id="toc-evaluar-la-precisión-de-un-modelo" class="nav-link" data-scroll-target="#evaluar-la-precisión-de-un-modelo">Evaluar la precisión de un modelo</a></li>
  <li><a href="#regresión-lineal-múltiple" id="toc-regresión-lineal-múltiple" class="nav-link" data-scroll-target="#regresión-lineal-múltiple">Regresión Lineal Múltiple</a></li>
  <li><a href="#términos-no-lineales-en-regresión-lineal" id="toc-términos-no-lineales-en-regresión-lineal" class="nav-link" data-scroll-target="#términos-no-lineales-en-regresión-lineal">Términos No-Lineales en Regresión Lineal</a></li>
  <li><a href="#problemas-con-la-regresión-lineal" id="toc-problemas-con-la-regresión-lineal" class="nav-link" data-scroll-target="#problemas-con-la-regresión-lineal">Problemas con la regresión lineal</a></li>
  </ul></li>
  <li><a href="#ejercicios-para-la-prueba" id="toc-ejercicios-para-la-prueba" class="nav-link" data-scroll-target="#ejercicios-para-la-prueba">Ejercicios para la prueba</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./6_aprendizaje_automatico_regresion_lineal.html">Aprendizaje Automático</a></li><li class="breadcrumb-item"><a href="./6_aprendizaje_automatico_regresion_lineal.html">6. Aprendizaje Automático y Regresión Lineal</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">Introducción al Aprendizaje Automático con Regresión Lineal</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="qué-es-el-aprendizaje-automático" class="level1">
<h1>¿Qué es el Aprendizaje Automático?</h1>
<p>Esta disciplina existe en la intersección entre la estadística y la informática. Por lo tanto hay un par de maneras de verlo.</p>
<p>Un informático definiría el aprendizaje automático por contraste con la programación clásica. En programación clásica uno le dice al computador qué hacer paso a paso. En aprendizaje automático uno en cambio define un <em>modelo</em> y este aprende o se ajusta a los datos para dar el resultado esperado. Un ejemplo trivial sería convertir entre grados centígrados y fahrenheit: En programación usual uno le pide al computador calcular con la fórmula de conversión. En aprendizaje automático uno tiene muchas parejas de temperaturas en ambas esalas y ajusta un modelo por ejemplo con regresión lineal. En ese sentido decimos que el modelo aprende de los datos.</p>
<p>Un estadístico diría que el aprendizaje automático es una serie de nuevos modelos para trabajar con una cantidad grande de datos y/o parámetros libres. El desarrollo de estos algoritmos fue posible gracias al progreso del hardware de las últimas décadas.</p>
<p>En muchas situacines tenemos una serie de variables que medimos sobre un sistema, las llamamos <span class="math inline">\(X_1, ..., X_n\)</span>, y nos interesa alguna otra variable que depende de ellas <span class="math inline">\(Y = f(X) + \epsilon\)</span>. El <span class="math inline">\(\epsilon\)</span> es un ruido que representa lo que está fuera de nuestro control y capacidad para medir. Puede ser error experimental en las mediciones, o el efecto de otras variables que no estamos tomando en cuenta.</p>
<p>Un ejemplo de un tal problema es el siguiente: Trabajamos para una empresa que vende un producto dado. Esta empresa invierte su presupuesto de publicidad en radio, televisión y periódicos. Tenemos el número de unidades medidas en varios mercados así como la inversión en estos tres tipos de publicidad. De esta forma <span class="math inline">\(X_1, X_2, X_3\)</span> es la inversión en televisión, radio y periódicos respectivamente, mientras <span class="math inline">\(Y\)</span> es la cantidad de unidades medidas.</p>
<section id="predicción-vs-inferencia" class="level2">
<h2 class="anchored" data-anchor-id="predicción-vs-inferencia">Predicción vs inferencia</h2>
<p>En este caso podemos querer determinar <span class="math inline">\(f\)</span> por dos motivos: Predicción o inferencia.</p>
<p>Para predicción, nos importa solamente determinar cuánto vale <span class="math inline">\(Y\)</span> para alguna combinación de las variables de entrada que no hemos visto antes. Por ejemplo saber cuántas unidades se venderán para una dada inversión en publicidad. La mayor parte del aprendizaje automático se ocupa de este tipo de problemas. Lo más importante en este tipo de problemas es reducir el error <span class="math display">\[
\langle (\hat{Y} - Y)^2\rangle = \langle(\hat{f}(X) - f(X) + \epsilon)^2 \rangle = \langle(f(X) - \hat{f}(X))^2\rangle + \operatorname{Var}(\epsilon)\,.
\]</span> Al primer término lo llamamos el error reducible: Podemos esperar disminuirlo encontrlando un modelo mejor. Al segundo término lo llamamos el error irreducible.</p>
<p>Para la inferencia, nos interesa saber la forma de <span class="math inline">\(f\)</span> para responder preguntas cualitativas sobre el fenómeno como por ejemplo: ¿Cuáles variables tienen un efecto importante? ¿Cuál es la incertidumbre de una predicción dada?</p>
<p>En física normalmente nos interesa la inferencia. Predecir no es suficiente dado que el propósito de la física es entender los sistemas que estudia. Además nos interesa tener alguna medida de la incertidumbre de nuestras predicciones y modelos. Algunos estadísticos le llaman <em>aprendizaje estadístico</em> al estudio de este tipo de pregutnas, en contraste con el <em>aprendizaje automático</em> que se preocupa sólo de obtener predicciones de la manera más eficiente posible.</p>
</section>
<section id="modelos-paramétricos-vs-no-paramétricos" class="level2">
<h2 class="anchored" data-anchor-id="modelos-paramétricos-vs-no-paramétricos">Modelos paramétricos vs no paramétricos</h2>
<p>En nuestra discusión anterior hemos tomado en cuenta modelos que dependen de parámetros. En física esto ocurre con mucha frecuencia ya que tenemos leyes físicas que queremos comparar con el experimento. Esas leyes nos proveen el modelo de forma natural junto con sus parámetros libres.</p>
<p>En general, los modelos que dependen de parámetros pueden dar origen a métodos muy potentes cuando son una buena descripción de los datos. Por ejemplo el ajuste lineal que vimos antes y que discutiremos más abajo puede ser un método muy potente si la relación entre los <span class="math inline">\(X_i\)</span> y <span class="math inline">\(Y\)</span> es lineal.</p>
<p>Los modelos paraétricos suelen ser más interpretables y más fáciles de usar para hacer inferencia.</p>
<p>Sin embargo hay casos donde no sabemos cuál es el modelo subyacente. Aún así nos puede interesar hacer predicciones. Un ejemplo que surge en física es cuando algún detalle del detector tiene un efecto sobre la medida, pero no nos interesa o es demasiado complicado modelarlo. Entonces tratamos de aproximar el efecto con funciones muy generales que no tengan parámetros libres.</p>
<p>La ventaja de estos modelos es que para la predicción son más generales que los paramétricos. No necesitamos conocer el sistema para tratar de ajustar uno de estos modelos, y nos puede permitir predecir en situaciones complejas. Por otro lado, suelen ser menos interpretables. Son menos potentes que conocer el modelo subyacente de los datos. Mientras más sabemos sobre un sistema a priori, mejores los métodos que podemos aplicar.</p>
</section>
<section id="aprendizaje-supervisado-vs-no-supervisado" class="level2">
<h2 class="anchored" data-anchor-id="aprendizaje-supervisado-vs-no-supervisado">Aprendizaje supervisado vs no supervisado</h2>
<p>Normalmente los datos toman la forma de una enorme lista de mediciones de las diferentes variables de entrada. Si tenemos <span class="math inline">\(q\)</span> variables de entrada y <span class="math inline">\(n\)</span> mediciones, podemos organizarlas en una matriz donde cada columna corresponde a una variable medida y cada fila es una medición. Es decir <span class="math inline">\(\boldsymbol{X}\)</span> es una matriz <span class="math inline">\(n\times q\)</span>. En algunos casos también tenemos las variables de salida <span class="math inline">\(Y\)</span> que organizamos como un vector <span class="math inline">\(y_i\)</span> con <span class="math inline">\(n\)</span> componentes. Si usamos esas variables de salida para entrenar el modelo hablamos de <strong>aprendizaje supervisado</strong>. La analogía es que el modelo mira varios ejemplos para aprender.</p>
<p>En otras situaciones no tenemos una variable de salida <span class="math inline">\(y_i\)</span>. Por ejemplo si tenemos una aplicación que recomienda restaurantes, nos puede interesar saber cuáles son los gustos de las personas. Podemos entonces agruparlos por gusto, donde los miembros de cada grupo tienen gustos similares. En casos como este decimos que el aprendizaje es <strong>no supervisado</strong>.</p>
<p>También hay mezclas entre ambos. Un ejemplo es reconocer imágenes de células con una cierta característica. Tenemos muchas imágenes pero alguien tiene que etiquetarlas con esa característica a mano. En ese caso podemos etiquetar algunas pocas e intentar entrenar un modelo que mezcle ambos tipos de algoritmos. Esto se llama aprendizaje <strong>semi supervisado</strong>.</p>
</section>
<section id="regresión-contra-clasificación" class="level2">
<h2 class="anchored" data-anchor-id="regresión-contra-clasificación">Regresión contra clasificación</h2>
<p>En problemas de <strong>regresión</strong> las variables de salida son numeros reales. Por ejemplo la masa de una partícula o la densidad del universo.</p>
<p>En problemas de <strong>clasificación</strong> las variables de salida son categorías. Por ejemplo si un evento en un detector es una señal o un ruido instrumental.</p>
</section>
</section>
<section id="regresión-lineal" class="level1">
<h1>Regresión Lineal</h1>
<p>Ilustraremos varios de los conceptos anteriores mediante la sencilla regresión lineal. Este tipo de regresión es muy sencilla, pero es computacionalmente barata y muy fácil de interpretar. Por ese motivo fue muy usada antes de la llegada de computadores suficientemente potentes. Nosotros lo estudiamos aquí porque es fácil y nos permite introducir varios conceptos sin el bagaje adicional de un modelo complicado.</p>
<p>Nos ocuparemos de el siguiente ejemplo: Una compañía quiere saber cómo invertir el dinero de publicidad. Tenemos los datos de gasto publicitario en televisión, radio y periódicos para varios mercados junto con el número de unidades vendidas en cada uno.</p>
<div id="1917974c" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Importamos los datos</p>
<div id="61c696b0" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>datos_publicidad <span class="op">=</span> pd.read_csv(<span class="st">"data/Advertising.csv"</span>, index_col<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>datos_publicidad.describe()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">TV</th>
<th data-quarto-table-cell-role="th">Radio</th>
<th data-quarto-table-cell-role="th">Newspaper</th>
<th data-quarto-table-cell-role="th">Sales</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">count</td>
<td>200.000000</td>
<td>200.000000</td>
<td>200.000000</td>
<td>200.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">mean</td>
<td>147.042500</td>
<td>23.264000</td>
<td>30.554000</td>
<td>14.022500</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">std</td>
<td>85.854236</td>
<td>14.846809</td>
<td>21.778621</td>
<td>5.217457</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">min</td>
<td>0.700000</td>
<td>0.000000</td>
<td>0.300000</td>
<td>1.600000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">25%</td>
<td>74.375000</td>
<td>9.975000</td>
<td>12.750000</td>
<td>10.375000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">50%</td>
<td>149.750000</td>
<td>22.900000</td>
<td>25.750000</td>
<td>12.900000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">75%</td>
<td>218.825000</td>
<td>36.525000</td>
<td>45.100000</td>
<td>17.400000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">max</td>
<td>296.400000</td>
<td>49.600000</td>
<td>114.000000</td>
<td>27.000000</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<section id="regresión-lineal-simple" class="level2">
<h2 class="anchored" data-anchor-id="regresión-lineal-simple">Regresión lineal simple</h2>
<p>Primero reducimos el problema a predecir el número de ventas basados en el gasto en televisión. Por lo tanto nuestro modelo es <span class="math display">\[
f(X) = \beta_0 + \beta_1 X\,,
\]</span> donde <span class="math inline">\(\beta_1\)</span> es el gasto en televisión. Ya vimos cómo estimar los coeficientes minimizando la suma de errores al cuadrado. Esto ya hace parte de muchas librerías en python.</p>
<div id="ee208baa" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Datos </span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> datos_publicidad[[<span class="st">"TV"</span>]]</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> datos_publicidad[<span class="st">"Sales"</span>]</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Crear y ajustar el modelo </span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> LinearRegression()</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>model.fit(X, Y)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Predecir </span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> model.predict(X)</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Graficar</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>plt.scatter(X, Y, color<span class="op">=</span><span class="st">'blue'</span>, label<span class="op">=</span><span class="st">'Datos'</span>)</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>plt.plot(X, y_pred, color<span class="op">=</span><span class="st">'red'</span>, label<span class="op">=</span><span class="st">'Regresión'</span>)</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Televisión"</span>)</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Ventas"</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<pre><code>Text(0, 0.5, 'Ventas')</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="6_aprendizaje_automatico_regresion_lineal_files/figure-html/cell-4-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="determinando-la-precisión-de-los-coeficientes" class="level2">
<h2 class="anchored" data-anchor-id="determinando-la-precisión-de-los-coeficientes">Determinando la precisión de los coeficientes</h2>
<p>Al escribir el modelo nosotros <em>estimamos</em> los coeficientes. Como se calcularon a partir de los datos, tendrán una varianza. Para verlo repetimos el código de arriba pero usando un subconjunto de los datos.</p>
<div id="d461260f" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>datos_subconjunto_1 <span class="op">=</span> datos_publicidad.sample(frac<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>datos_subconjunto_2 <span class="op">=</span> datos_publicidad.sample(frac<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Datos </span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>X_1 <span class="op">=</span> datos_subconjunto_1[[<span class="st">"TV"</span>]]</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>Y_1 <span class="op">=</span> datos_subconjunto_1[<span class="st">"Sales"</span>]</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>X_2 <span class="op">=</span> datos_subconjunto_2[[<span class="st">"TV"</span>]]</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>Y_2 <span class="op">=</span> datos_subconjunto_2[<span class="st">"Sales"</span>]</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Crear y ajustar el modelo </span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>model_1 <span class="op">=</span> LinearRegression()</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>model_1.fit(X_1, Y_1)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>model_2 <span class="op">=</span> LinearRegression()</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>model_2.fit(X_2, Y_2)</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Predecir </span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>y_pred_1 <span class="op">=</span> model_1.predict(X_1)</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>y_pred_2 <span class="op">=</span> model_2.predict(X_2)</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Graficar</span></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>plt.scatter(X_1, Y_1, color<span class="op">=</span><span class="st">'blue'</span>, label<span class="op">=</span><span class="st">'Datos'</span>)</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>plt.plot(X_1, y_pred_1, color<span class="op">=</span><span class="st">'red'</span>, label<span class="op">=</span><span class="st">'Regresión 1'</span>)</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>plt.scatter(X_2, Y_2, color<span class="op">=</span><span class="st">'darkblue'</span>, label<span class="op">=</span><span class="st">'Datos'</span>)</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>plt.plot(X_2, y_pred_2, color<span class="op">=</span><span class="st">'darkred'</span>, label<span class="op">=</span><span class="st">'Regresión 2'</span>)</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Televisión"</span>)</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Ventas"</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>Text(0, 0.5, 'Ventas')</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="6_aprendizaje_automatico_regresion_lineal_files/figure-html/cell-5-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Vemos que las líneas cambian dependiendo de los datos. Esto nos muestra que estas estimaciones tienen una <em>varianza</em> que ya habíamos calculado <span class="math display">\[
\operatorname{Var}(\hat{\beta}_1) = \frac{\sigma^2}{\sum(x_i - x)^2}\,,\quad \operatorname{Var}(\hat{\beta}_0) = \frac{\sigma^2}{n} + \operatorname{Var}(\hat{\beta}_1) \bar{x}^2\,.
\]</span> En general no concemos <span class="math inline">\(\sigma^2\)</span>, que es la varianza de <span class="math inline">\(Y\)</span>. Lo tenemos que estimar de los datos. Para hacerlo tomamos <span class="math inline">\(s^2 = \sum(y_i - \bar{y})^2/(n-2)\)</span>. Es <span class="math inline">\((n-2)\)</span> en vez de <span class="math inline">\((n-1)\)</span> en el denominador porque en este modelo tenemos dos parámetros.</p>
</section>
<section id="evaluar-la-precisión-de-un-modelo" class="level2">
<h2 class="anchored" data-anchor-id="evaluar-la-precisión-de-un-modelo">Evaluar la precisión de un modelo</h2>
<p>Una manera de evaluar lo bueno o malo que es el ajuste es por medio de la estadística <span class="math inline">\(\chi^2\)</span> que vimos antes.</p>
<p>Otra forma muy usada y fácil de interpretar es la suma de errores residuales. Se define como <span class="math display">\[
\text{RSE} = \sqrt{\frac{1}{n - 2} \text{RSS}}\,,
\]</span> donde <span class="math inline">\(\text{RSS} \equiv \sum(y_i - \hat{y}_i)^2\)</span>. Esto nos dice en promedio cuánto se desvía el modelo de las mediciones. Saber si el errror es suficientemente bueno depende de lo que estemos dispuestos a tolerar.</p>
<p>Otra evaluacón que muy usada que no depende del modelo es la <span class="math inline">\(R^2\)</span>. Definida así <span class="math display">\[
R^2 = 1 - \frac{\text{RSS}}{\sum (y_i - \bar{y})^2}\,.
\]</span> El denominador del segundo término se llama la suma total de cuadrados. Nos dice la varianza de <span class="math inline">\(y\)</span> en los datos. El numerador nos dice la desviación de los datos respecto al modelo. Si <span class="math inline">\(R^2\)</span> es cercano a <span class="math inline">\(1\)</span> quiere decir que la desviación de los daotos respecto al modelo es muy pequeña comparada con la desviación total y el modelo es bueno. Si al contrario <span class="math inline">\(R^2\)</span> es cercano a cero, quiere decir que la desviación respecto al modelo es similar a la desviación total tal que el modelo no está haciendo nada (podemos lograr algo similar usando la media). A veces se dice que <span class="math inline">\(R^2\)</span> es la “fracción de la varianza explicada por el modelo”. Para la regresión lineal simple, $R^2% es igual a la correlación entre el modelo y los datos.</p>
</section>
<section id="regresión-lineal-múltiple" class="level2">
<h2 class="anchored" data-anchor-id="regresión-lineal-múltiple">Regresión Lineal Múltiple</h2>
<p>Ahora queremos ajustar un modelo que depende de varias variables de entrada. En nuestro caso son los presupuestos para los diferentes tipos de publicidad. <span class="math display">\[
f(\vec{X}) = \beta_0 + \beta_1 X_1 + ... + \beta_q X_q\,.
\]</span> El ajuste de mínimos cuadrados se logra por medio de la ecuación normal como antes. Para tener más control sobre las propiedades estadísticas usamos otra librería de python.</p>
<div id="d876ae70" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> datos_publicidad.drop(<span class="st">"Sales"</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> sm.add_constant(X)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Ajustar el modelo </span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> sm.OLS(Y, X)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> model.fit()</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(results.summary())</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                  Sales   R-squared:                       0.897
Model:                            OLS   Adj. R-squared:                  0.896
Method:                 Least Squares   F-statistic:                     570.3
Date:                Mon, 29 Dec 2025   Prob (F-statistic):           1.58e-96
Time:                        12:48:04   Log-Likelihood:                -386.18
No. Observations:                 200   AIC:                             780.4
Df Residuals:                     196   BIC:                             793.6
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
const          2.9389      0.312      9.422      0.000       2.324       3.554
TV             0.0458      0.001     32.809      0.000       0.043       0.049
Radio          0.1885      0.009     21.893      0.000       0.172       0.206
Newspaper     -0.0010      0.006     -0.177      0.860      -0.013       0.011
==============================================================================
Omnibus:                       60.414   Durbin-Watson:                   2.084
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              151.241
Skew:                          -1.327   Prob(JB):                     1.44e-33
Kurtosis:                       6.332   Cond. No.                         454.
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</code></pre>
</div>
</div>
<p>Esta librería nos da un el error estándar sobre cada parámetro. Esto nos permite calcular intervalos de confianza.</p>
<p>Además nos presenta con una estadística <span class="math inline">\(t\)</span> que viene de comparar la hipótesis nula de que ese parámetro no afecta los datos con la hipótesis que sí los afecta. En este caso corresponde a <span class="math inline">\(t = \hat{\beta}_i/\operatorname{SE}(\hat{\beta}_i)\)</span>. Sabemos que esta está distribuida según la distribución de Student para grandes números de datos. De aquí podemos obtener la probabilidad de obtener un <span class="math inline">\(t\)</span> así o más extremo, es decir un valor <span class="math inline">\(p\)</span> que también nos lo da esta librería.</p>
<p>Con esto bajo la manga podemos preguntarnos</p>
<p><strong>¿Cuáles variables son importantes?</strong></p>
<p>Estudiaremos más adelante varias maneras de seleccionar variables. Por ahora sólo diremos que si tenemos <span class="math inline">\(p\)</span> coeficientes, tenemos <span class="math inline">\(2^p\)</span> posibles modelos. Estos son demasiados para compararlos a todos. Por lo tanto se usan algunas estrategias aproximadas:</p>
<ul>
<li><p>Empezamos por todos los modelos con un parámetro. Escogemos el mejor de esos, luego le agregamos los parámetros restantes uno a uno para quedarnos con el mejor. Seguimos así hasta que satisfacemos algún criterio. Por ejemplo que el valor <span class="math inline">\(p\)</span> de todo el modelo esté por debajo de un cierto valor.</p></li>
<li><p>Al revés, del modelo completo quitamos parámetros uno a uno. Nos quedamos con el mejor y le quitamos a ese los parámetros uno a uno. Paramos cuando todos los parámetros tengan un valor <span class="math inline">\(p\)</span> por debajo de un cierto valor.</p></li>
</ul>
<p>En nuestro ejemplo es bastante claro que podemos remover el coeficiente de periódicos.</p>
<p>Una vez tengamos un buen modelo podemos hacer predicciones. A partir de las varianzas de los parámetros podemos reportar un intervalo de confianza a un nivel <span class="math inline">\(C\)</span> para la prediccón (propagando errores). Según este modelo, el verdadero valor de <span class="math inline">\(f(X)\)</span> estará en ese intervalo una fracción <span class="math inline">\(C\)</span> de veces. *Esto no quiere decir que al realizar muchas observaciones futuras, una fracción <span class="math inline">\(C\)</span> caerá en ese intervalo. Esto es porque nos falta <span class="math inline">\(\epsilon\)</span>, el error irreducible (recuerde que cada observación es <span class="math inline">\(f(X) + \epsilon\)</span>). A los intervalos que incorporan este error irreducible (estimado a partir de los datos) se los llama <strong>intervalos de predicción</strong>.</p>
</section>
<section id="términos-no-lineales-en-regresión-lineal" class="level2">
<h2 class="anchored" data-anchor-id="términos-no-lineales-en-regresión-lineal">Términos No-Lineales en Regresión Lineal</h2>
<p>Cuando la relación entre variables es no-lineal, al parecer no podemos aplicar este método. En realidad podemos generalizarlo. Por ejemplo podríamos escribir para un solo predictor <span class="math display">\[
f(X) = \beta_0 + \beta_1 X + \beta_2 X^2\,.
\]</span> Más interesante aún, en el caso de varios predictores podemos incluir términos <strong>de interacción</strong>. En nuestro ejemplo podemos escribir <span class="math display">\[
f(X) = \beta_0 + \beta_{\text{TV}}X_{\text{TV}} + \beta_{\text{radio}}X_{\text{radio}} + \beta_{\text{TV}\times\text{radio}}X_{\text{TV}}X_{\text{radio}}\,.
\]</span> Lo que representa este término es que hay un efecto de sinergia entre los dos predictores. El efecto de invertir en televisión depende de si se invierte en radio o no. Veámoslo</p>
<div id="98db8b16" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> datos_publicidad.drop([<span class="st">"Sales"</span>, <span class="st">"Newspaper"</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>X[<span class="st">"Interaction"</span>] <span class="op">=</span> X[<span class="st">"TV"</span>]<span class="op">*</span>X[<span class="st">"Radio"</span>]</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> sm.add_constant(X)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Ajustar el modelo </span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> sm.OLS(Y, X)</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> model.fit()</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(results.summary())</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                  Sales   R-squared:                       0.968
Model:                            OLS   Adj. R-squared:                  0.967
Method:                 Least Squares   F-statistic:                     1963.
Date:                Mon, 29 Dec 2025   Prob (F-statistic):          6.68e-146
Time:                        12:48:04   Log-Likelihood:                -270.14
No. Observations:                 200   AIC:                             548.3
Df Residuals:                     196   BIC:                             561.5
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
===============================================================================
                  coef    std err          t      P&gt;|t|      [0.025      0.975]
-------------------------------------------------------------------------------
const           6.7502      0.248     27.233      0.000       6.261       7.239
TV              0.0191      0.002     12.699      0.000       0.016       0.022
Radio           0.0289      0.009      3.241      0.001       0.011       0.046
Interaction     0.0011   5.24e-05     20.727      0.000       0.001       0.001
==============================================================================
Omnibus:                      128.132   Durbin-Watson:                   2.224
Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1183.719
Skew:                          -2.323   Prob(JB):                    9.09e-258
Kurtosis:                      13.975   Cond. No.                     1.80e+04
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 1.8e+04. This might indicate that there are
strong multicollinearity or other numerical problems.</code></pre>
</div>
</div>
<p>Vemos que el ajuste mejora el <span class="math inline">\(R^2\)</span>. Note que el valor <span class="math inline">\(p\)</span> de radio bajó un poco. Esto es porque la interacción era parte de su efecto. En general, si queremos incluir los términos de interacción, debemos incluir cada uno de sus componentes separadamente para evitar confusiones entre la interacción y la simple variable.</p>
</section>
<section id="problemas-con-la-regresión-lineal" class="level2">
<h2 class="anchored" data-anchor-id="problemas-con-la-regresión-lineal">Problemas con la regresión lineal</h2>
<p>Algunas situaciones que pueden ser problemáticas para la regresión lineal que hemos presentado.</p>
<ul>
<li><p>Correlación entre errores: Si los errores <span class="math inline">\(\epsilon_i\)</span> no son independientes no es suficiente minimizar los cuadrados. Debemos minimizar una suma que incluya la covarianza enre mediciones. En general esto reduce los valores <span class="math inline">\(p\)</span>. Un ejemplo extremo es si la correlación es perfecta. Al realizar la misma medición muchas veces obtenemos el mismo valor, en realidad hemos hecho una sola medida.</p></li>
<li><p>Varianza no constante (heterosedasticidad): Cuando la varianza es diferente para cada medición, de nuevo podeos resolverlo minimizando una suma de cuadrados que incluya la varianza de cada término. Esto si podemos modelarla o estimarla de alguna manera.</p></li>
<li><p>“Outliers”: Si hay puntos atípicos en las mediciones, estos pueden ser errores de registro de los datos o errores sistemáticos aislados. Al estar muy porfuera de la “nube” de puntos usuales pueden modificar el ajuste y contribuir mucho al error total (no estarán descritos por el modelo de los demás puntos). Cuando se detecta un punto fuera de lo normal, con un <span class="math inline">\(t\)</span> muy grande, es necesario examinarlo detenidamente para saber si es un dato genuino o un error.</p></li>
<li><p>Puntos con gran palanca: Los puntos en los extremos del intervalo tienden a afectar la regresión lineal más que puntos cerca del centro. Un error en esos puntos afecta desmesuradamente el ajuste.</p></li>
<li><p>Colinearidad: Cuando dos variables están muy correlacionadas, esto puede inducir problemas a la hora de hacer inferencia con el modelo. Por ejemplo, el ajuste particular puede diluir el valor <span class="math inline">\(p\)</span> de ambas variables, porque puede compensar con una de ellas lo que hace la otra. Para facilitar la interpretación se puede intentar remover una de esas variables y ver cómo cambian las conclusiones.</p></li>
</ul>
</section>
</section>
<section id="ejercicios-para-la-prueba" class="level1">
<h1>Ejercicios para la prueba</h1>
<p>2.1, 3.1, 3.3, 3.4, 3.6</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiado");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiado");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/jorgenorena\.github\.io\/machine_learning_course\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>
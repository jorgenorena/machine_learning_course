<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="es" xml:lang="es"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>SVM y Aprendizaje No Supervisado – Aprendizaje Automático para Físicos</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-e13f217ceb0135cb77e1494052e28e8a.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Sin resultados",
    "search-matching-documents-text": "documentos encontrados",
    "search-copy-link-title": "Copiar el enlace en la búsqueda",
    "search-hide-matches-text": "Ocultar resultados adicionales",
    "search-more-match-text": "resultado adicional en este documento",
    "search-more-matches-text": "resultados adicionales en este documento",
    "search-clear-button-title": "Borrar",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar",
    "search-label": "Buscar"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar docked nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Aprendizaje Automático para Físicos</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Buscar"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Navegación de palanca" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-clases" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Clases</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-clases">    
        <li class="dropdown-header">Probabilidad y Estadística</li>
        <li>
    <a class="dropdown-item" href="./1_probabilidad.html">
 <span class="dropdown-text">1. Probabilidad</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./2_distribuciones_y_estimacion.html">
 <span class="dropdown-text">2. Distribuciones y Estimación</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./3_verosimilitud.html">
 <span class="dropdown-text">3. Verosimilitud</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./4_minimos_cuadrados_intervalos.html">
 <span class="dropdown-text">4. Mínimos Cuadrados e Intervalos</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./5_testeo_de_hipotesis_entropia.html">
 <span class="dropdown-text">5. Testeo de Hipótesis y Entropía</span></a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li class="dropdown-header">Aprendizaje Automático</li>
        <li>
    <a class="dropdown-item" href="./6_aprendizaje_automatico_regresion_lineal.html">
 <span class="dropdown-text">6. Aprendizaje Automático y Regresión Lineal</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./7_clasificacion.html">
 <span class="dropdown-text">7. Clasificación</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./8_seleccion_de_modelos.html">
 <span class="dropdown-text">8. Selección de Modelos</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./9_arboles_bosques_boosting.html">
 <span class="dropdown-text">9. Árboles, Bosques y Boosting</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./10_svm_y_no_supervisado.html">
 <span class="dropdown-text">10. SVM y Aprendizaje No Supervisado</span></a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li class="dropdown-header">Redes Neuronales</li>
        <li>
    <a class="dropdown-item" href="./11_perceptron_y_redes_conexas.html">
 <span class="dropdown-text">11. Perceptrón y Redes Conexas y Pérdidas</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./12_gradient_descent_and_autodiff.html">
 <span class="dropdown-text">12. Descenso de Gradiente y Auto-diferenciación</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./13_evaluacion_y_regularizacion_de_nn.html">
 <span class="dropdown-text">13. Evaluación y Regularización de redes neuronales</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./14_redes_convolucionales.html">
 <span class="dropdown-text">14. Redes Convolucionales</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./15_redes_residuales.html">
 <span class="dropdown-text">15. Redes Residuales</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./16_transformadores.html">
 <span class="dropdown-text">16. Transformadores y el mecanismo de atención</span></a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li class="dropdown-header">Algunas aplicaciones</li>
        <li>
    <a class="dropdown-item" href="./17_flujos_normalizantes.html">
 <span class="dropdown-text">17. Flujos Normalizantes</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./18_PINNs.html">
 <span class="dropdown-text">18. Redes Neuronales Informadas por la Física (PINNs)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./19_Operador_Neural.html">
 <span class="dropdown-text">19. Operadores Neuronales</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="./about.html"> 
<span class="menu-text">Acerca de</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./6_aprendizaje_automatico_regresion_lineal.html">Aprendizaje Automático</a></li><li class="breadcrumb-item"><a href="./10_svm_y_no_supervisado.html">10. SVM y Aprendizaje No Supervisado</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Probabilidad y Estadística</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Alternar sección">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1_probabilidad.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1. Probabilidad</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2_distribuciones_y_estimacion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2. Distribuciones y Estimación</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3_verosimilitud.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3. Verosimilitud</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./4_minimos_cuadrados_intervalos.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4. Mínimos Cuadrados e Intervalos</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./5_testeo_de_hipotesis_entropia.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5. Testeo de Hipótesis y Entropía</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Aprendizaje Automático</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Alternar sección">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./6_aprendizaje_automatico_regresion_lineal.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">6. Aprendizaje Automático y Regresión Lineal</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./7_clasificacion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">7. Clasificación</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./8_seleccion_de_modelos.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">8. Selección de Modelos</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./9_arboles_bosques_boosting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">9. Árboles, Bosques y Boosting</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10_svm_y_no_supervisado.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">10. SVM y Aprendizaje No Supervisado</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Redes Neuronales</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Alternar sección">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11_perceptron_y_redes_conexas.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">11. Perceptrón, Redes Conexas y Pérdidas</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12_gradient_descent_and_autodiff.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">12. Descenso de Gradiente y Auto-diferenciación</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13_evaluacion_y_regularizacion_de_nn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">13. Evaluación y Regularización de redes neuronales</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14_redes_convolucionales.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">14. Redes Convolucionales</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./15_redes_residuales.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">15. Redes Residuales</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./16_transformadores.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">16. Transformadores y el mecanismo de atención</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Algunas aplicaciones</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Alternar sección">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./17_flujos_normalizantes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">17. Flujos Normalizantes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./18_PINNs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">18. Redes Neuronales Informadas por la Física (PINNs)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./19_Operador_Neural.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">19. Operadores Neuronales</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">En esta página</h2>
   
  <ul>
  <li><a href="#máquinas-de-vectores-de-soporte-svm" id="toc-máquinas-de-vectores-de-soporte-svm" class="nav-link active" data-scroll-target="#máquinas-de-vectores-de-soporte-svm">Máquinas de Vectores de Soporte (SVM)</a>
  <ul class="collapse">
  <li><a href="#clasificador-de-margen-máximo" id="toc-clasificador-de-margen-máximo" class="nav-link" data-scroll-target="#clasificador-de-margen-máximo">Clasificador de Margen Máximo</a></li>
  <li><a href="#clasificador-de-vectores-soporte" id="toc-clasificador-de-vectores-soporte" class="nav-link" data-scroll-target="#clasificador-de-vectores-soporte">Clasificador de Vectores Soporte</a></li>
  <li><a href="#máquinas-de-vectores-de-soporte-svm-no-lineales" id="toc-máquinas-de-vectores-de-soporte-svm-no-lineales" class="nav-link" data-scroll-target="#máquinas-de-vectores-de-soporte-svm-no-lineales">Máquinas de Vectores de Soporte (SVM) no lineales</a>
  <ul class="collapse">
  <li><a href="#truco-del-núcleo-kernel-trick" id="toc-truco-del-núcleo-kernel-trick" class="nav-link" data-scroll-target="#truco-del-núcleo-kernel-trick">Truco del núcleo (kernel trick)</a></li>
  <li><a href="#svm-multiclase" id="toc-svm-multiclase" class="nav-link" data-scroll-target="#svm-multiclase">SVM multiclase</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#aprendizaje-no-supervisado" id="toc-aprendizaje-no-supervisado" class="nav-link" data-scroll-target="#aprendizaje-no-supervisado">Aprendizaje no supervisado</a>
  <ul class="collapse">
  <li><a href="#análisis-de-componentes-principales-pca" id="toc-análisis-de-componentes-principales-pca" class="nav-link" data-scroll-target="#análisis-de-componentes-principales-pca">Análisis de componentes principales (PCA)</a>
  <ul class="collapse">
  <li><a href="#definición-de-los-componentes-principales" id="toc-definición-de-los-componentes-principales" class="nav-link" data-scroll-target="#definición-de-los-componentes-principales">Definición de los Componentes Principales</a></li>
  <li><a href="#proporción-de-varianza-explicada-pve" id="toc-proporción-de-varianza-explicada-pve" class="nav-link" data-scroll-target="#proporción-de-varianza-explicada-pve">Proporción de Varianza Explicada (PVE)</a></li>
  <li><a href="#consideraciones-prácticas" id="toc-consideraciones-prácticas" class="nav-link" data-scroll-target="#consideraciones-prácticas">Consideraciones Prácticas</a></li>
  <li><a href="#selección-del-número-de-componentes" id="toc-selección-del-número-de-componentes" class="nav-link" data-scroll-target="#selección-del-número-de-componentes">Selección del Número de Componentes</a></li>
  <li><a href="#usos-adicionales-del-pca" id="toc-usos-adicionales-del-pca" class="nav-link" data-scroll-target="#usos-adicionales-del-pca">Usos Adicionales del PCA</a></li>
  <li><a href="#ejemplo-de-pca-para-compresión-de-imágenes" id="toc-ejemplo-de-pca-para-compresión-de-imágenes" class="nav-link" data-scroll-target="#ejemplo-de-pca-para-compresión-de-imágenes">Ejemplo de PCA para compresión de imágenes</a></li>
  </ul></li>
  <li><a href="#métodos-de-clustering" id="toc-métodos-de-clustering" class="nav-link" data-scroll-target="#métodos-de-clustering">Métodos de Clustering</a>
  <ul class="collapse">
  <li><a href="#introducción" id="toc-introducción" class="nav-link" data-scroll-target="#introducción">Introducción</a></li>
  <li><a href="#clustering-k-means" id="toc-clustering-k-means" class="nav-link" data-scroll-target="#clustering-k-means">Clustering K-means</a></li>
  <li><a href="#elección-de-la-medida-de-disimilitud" id="toc-elección-de-la-medida-de-disimilitud" class="nav-link" data-scroll-target="#elección-de-la-medida-de-disimilitud">Elección de la medida de disimilitud</a></li>
  <li><a href="#cuestiones-prácticas" id="toc-cuestiones-prácticas" class="nav-link" data-scroll-target="#cuestiones-prácticas">Cuestiones prácticas</a></li>
  <li><a href="#ejemplo-de-clustering-k-means" id="toc-ejemplo-de-clustering-k-means" class="nav-link" data-scroll-target="#ejemplo-de-clustering-k-means">Ejemplo de clustering K-means</a></li>
  <li><a href="#ejemplo-de-clustering-para-segmentación-de-imágenes" id="toc-ejemplo-de-clustering-para-segmentación-de-imágenes" class="nav-link" data-scroll-target="#ejemplo-de-clustering-para-segmentación-de-imágenes">Ejemplo de clustering para segmentación de imágenes</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#ejercicios-sugeridos-para-la-prueba" id="toc-ejercicios-sugeridos-para-la-prueba" class="nav-link" data-scroll-target="#ejercicios-sugeridos-para-la-prueba">Ejercicios Sugeridos Para la Prueba</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./6_aprendizaje_automatico_regresion_lineal.html">Aprendizaje Automático</a></li><li class="breadcrumb-item"><a href="./10_svm_y_no_supervisado.html">10. SVM y Aprendizaje No Supervisado</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">SVM y Aprendizaje No Supervisado</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>En esta clase vamos a ver otros algoritmos de aprendizaje automático que no son redes neuronales. Existe una vasta (y creciente) literatura sobre este tema y no vamos a poder cubrirla en esta asignatura. El estudiante puede tomar esta clase como motivación para explorar más a fondo el aprendizaje automático.</p>
<section id="máquinas-de-vectores-de-soporte-svm" class="level1">
<h1>Máquinas de Vectores de Soporte (SVM)</h1>
<p>Las máquinas de vectores de soporte (SVM) fueron desarrolladas en los años 90 y han ganado popularidad debido a su buen rendimiento en distintos contextos. Comenzaremos con el clasificador de margen máximo que es el más simple y funciona cuando las observaciones son linealmente separables (la frontera de decisión es un hiperplano sin solapamiento entre clases). Luego veremos el clasificador de vectores soporte que permite algunos solapamientos admitiendo violaciones del margen. Finalmente discutiremos cómo generalizar el clasificador de vectores soporte para problemas no lineales.</p>
<section id="clasificador-de-margen-máximo" class="level2">
<h2 class="anchored" data-anchor-id="clasificador-de-margen-máximo">Clasificador de Margen Máximo</h2>
<p>Este clasificador busca un hiperplano que separa las observaciones de las dos clases de manera que el margen (distancia mínima) entre el hiperplano y las observaciones más cercanas de cada clase sea lo más grande posible. Es decir, para cada punto de datos calculamos su distancia al hiperplano y el margen es la distancia mínima entre el hiperplano y las observaciones más cercanas de cada clase.</p>
<p>La optimización del hiperplano de margen máximo es:</p>
<p><span class="math display">\[
\text{maximizar } M \quad\text{sujeto a}\quad \sum_{j=1}^{p} \beta_j^2 = 1, \quad y_i(\beta_0 + \beta_1 x_{i1} + \dots + \beta_p x_{ip}) \geq M\,,
\]</span></p>
<p>donde <span class="math inline">\(M\)</span> es el margen y <span class="math inline">\(y_i\)</span> es la clase de la observación <span class="math inline">\(i\)</span> (<span class="math inline">\(y_i \in \{-1, 1\}\)</span>).</p>
<div id="cell-fig-svm-lineal" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> svm</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Datos sintéticos</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>X_pos <span class="op">=</span> np.random.randn(<span class="dv">20</span>, <span class="dv">2</span>) <span class="op">+</span> [<span class="dv">2</span>, <span class="dv">2</span>]     <span class="co"># clase +1</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>X_neg <span class="op">=</span> np.random.randn(<span class="dv">20</span>, <span class="dv">2</span>) <span class="op">+</span> [<span class="op">-</span><span class="dv">2</span>, <span class="op">-</span><span class="dv">2</span>]   <span class="co"># clase −1</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.vstack([X_pos, X_neg])</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.hstack([np.ones(<span class="dv">20</span>), <span class="op">-</span>np.ones(<span class="dv">20</span>)])</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Entrenamiento SVM lineal</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="co">#    (margen máximo: C grande)</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> svm.SVC(kernel<span class="op">=</span><span class="st">"linear"</span>, C<span class="op">=</span><span class="fl">1e5</span>)  <span class="co"># C → ∞ ≈ margen duro</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>clf.fit(X, y)</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> clf.coef_[<span class="dv">0</span>]          <span class="co"># vector normal al hiperplano</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> clf.intercept_[<span class="dv">0</span>]     <span class="co"># término independiente</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>sv <span class="op">=</span> clf.support_vectors_ <span class="co"># vectores soporte</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Gráfica</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">6</span>))</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Puntos</span></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>ax.scatter(X_pos[:, <span class="dv">0</span>], X_pos[:, <span class="dv">1</span>], color<span class="op">=</span><span class="st">"steelblue"</span>, label<span class="op">=</span><span class="st">"Clase +1"</span>)</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>ax.scatter(X_neg[:, <span class="dv">0</span>], X_neg[:, <span class="dv">1</span>], color<span class="op">=</span><span class="st">"darkorange"</span>, label<span class="op">=</span><span class="st">"Clase −1"</span>)</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Vectores soporte</span></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>ax.scatter(sv[:, <span class="dv">0</span>], sv[:, <span class="dv">1</span>], s<span class="op">=</span><span class="dv">120</span>, facecolors<span class="op">=</span><span class="st">"none"</span>,</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>           edgecolors<span class="op">=</span><span class="st">"black"</span>, linewidths<span class="op">=</span><span class="fl">1.5</span>, label<span class="op">=</span><span class="st">"Vectores soporte"</span>)</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Recta de decisión y márgenes</span></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>xx <span class="op">=</span> np.linspace(<span class="op">*</span>ax.get_xlim(), <span class="dv">400</span>)</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>yy <span class="op">=</span> <span class="op">-</span>(w[<span class="dv">0</span>] <span class="op">*</span> xx <span class="op">+</span> b) <span class="op">/</span> w[<span class="dv">1</span>]</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>margin <span class="op">=</span> <span class="dv">1</span> <span class="op">/</span> np.linalg.norm(w)</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>yy_up   <span class="op">=</span> yy <span class="op">+</span> w[<span class="dv">0</span>] <span class="op">/</span> w[<span class="dv">1</span>] <span class="op">*</span> margin</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>yy_down <span class="op">=</span> yy <span class="op">-</span> w[<span class="dv">0</span>] <span class="op">/</span> w[<span class="dv">1</span>] <span class="op">*</span> margin</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>ax.plot(xx, yy, <span class="st">"k-"</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>ax.plot(xx, yy_up, <span class="st">"k--"</span>, linewidth<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>ax.plot(xx, yy_down, <span class="st">"k--"</span>, linewidth<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">"$x_1$"</span>)</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">"$x_2$"</span>)</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">"Clasificador de margen máximo"</span>)</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>ax.legend()</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-svm-lineal" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-svm-lineal-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="10_svm_y_no_supervisado_files/figure-html/fig-svm-lineal-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-svm-lineal-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;1: Clasificador de margen máximo
</figcaption>
</figure>
</div>
</div>
</div>
<p>En la <a href="#fig-svm-lineal" class="quarto-xref">Figura&nbsp;1</a> se muestra el clasificador de margen máximo para un conjunto de datos sintéticos. Encerramos en círculos los puntos con la distancia mínima al hiperplano. Estos se llaman <strong>vectores de soporte</strong>. Los vectores soporte son las observaciones más cercanas al hiperplano y determinan su posición. Una particularidad de los vectores soporte es que si eliminamos todos los demás puntos, el hiperplano no cambia. Es decir, el hiperplano es invariante a la eliminación de puntos no soporte.</p>
<p>El clasificador de margen máximo tiene una gran varianza porque la frontera de decisión es muy sensible a pequeños cambios en los vectores de soporte.</p>
</section>
<section id="clasificador-de-vectores-soporte" class="level2">
<h2 class="anchored" data-anchor-id="clasificador-de-vectores-soporte">Clasificador de Vectores Soporte</h2>
<p>El clasificador de vectores soporte (clasificador de margen suave) permite algunas violaciones del margen. Para ello, se introduce un parámetro <span class="math inline">\(C\)</span> que controla la compensación entre el ancho del margen y las violaciones del margen. Se puede ver como un presupuesto para el número de violaciones del margen.</p>
<p><span class="math display">\[
\begin{align}
\text{maximizar } M \quad\text{sujeto a} &amp;\\
&amp;\sum_{j=1}^{p} \beta_j^2 = 1, \\
&amp;y_i(\beta_0 + \beta_1 x_{i1} + \dots + \beta_p x_{ip}) \geq M(1 - \varepsilon_i), \\
&amp;\varepsilon_i \geq 0,\quad \sum_{i=1}^{n} \varepsilon_i \leq C
\end{align}
\]</span></p>
<p>En la <a href="#fig-svm-soft-margin" class="quarto-xref">Figura&nbsp;2</a> se muestra el clasificador de margen suave para un conjunto de datos sintéticos. Vemos que el margen es más ancho y permite algunas violaciones del margen.</p>
<div id="cell-fig-svm-soft-margin" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> svm</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Datos sintéticos con solapamiento</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>X_pos <span class="op">=</span> np.random.randn(<span class="dv">20</span>, <span class="dv">2</span>) <span class="op">+</span> [<span class="dv">1</span>, <span class="dv">1</span>]     <span class="co"># clase +1</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>X_neg <span class="op">=</span> np.random.randn(<span class="dv">20</span>, <span class="dv">2</span>) <span class="op">+</span> [<span class="op">-</span><span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>]   <span class="co"># clase −1</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.vstack([X_pos, X_neg])</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.hstack([np.ones(<span class="dv">20</span>), <span class="op">-</span>np.ones(<span class="dv">20</span>)])</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Entrenamiento SVM con margen suave</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="co">#    (C pequeño permite más violaciones)</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="co">#    CUIDADO: El parámetro C de esta clase es el inverso del </span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="co">#    introducido en la ecuación (ver advertencia)</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> svm.SVC(kernel<span class="op">=</span><span class="st">"linear"</span>, C<span class="op">=</span><span class="fl">0.1</span>)  <span class="co"># C pequeño = margen suave</span></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>clf.fit(X, y)</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> clf.coef_[<span class="dv">0</span>]          <span class="co"># vector normal al hiperplano</span></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> clf.intercept_[<span class="dv">0</span>]     <span class="co"># término independiente</span></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>sv <span class="op">=</span> clf.support_vectors_ <span class="co"># vectores soporte</span></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------</span></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Gráfica</span></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------</span></span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">6</span>))</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Puntos</span></span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>ax.scatter(X_pos[:, <span class="dv">0</span>], X_pos[:, <span class="dv">1</span>], color<span class="op">=</span><span class="st">"steelblue"</span>, label<span class="op">=</span><span class="st">"Clase +1"</span>)</span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>ax.scatter(X_neg[:, <span class="dv">0</span>], X_neg[:, <span class="dv">1</span>], color<span class="op">=</span><span class="st">"darkorange"</span>, label<span class="op">=</span><span class="st">"Clase −1"</span>)</span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Vectores soporte</span></span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>ax.scatter(sv[:, <span class="dv">0</span>], sv[:, <span class="dv">1</span>], s<span class="op">=</span><span class="dv">120</span>, facecolors<span class="op">=</span><span class="st">"none"</span>,</span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>           edgecolors<span class="op">=</span><span class="st">"black"</span>, linewidths<span class="op">=</span><span class="fl">1.5</span>, label<span class="op">=</span><span class="st">"Vectores soporte"</span>)</span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Recta de decisión y márgenes</span></span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>xx <span class="op">=</span> np.linspace(<span class="op">*</span>ax.get_xlim(), <span class="dv">400</span>)</span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a>yy <span class="op">=</span> <span class="op">-</span>(w[<span class="dv">0</span>] <span class="op">*</span> xx <span class="op">+</span> b) <span class="op">/</span> w[<span class="dv">1</span>]</span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a>margin <span class="op">=</span> <span class="dv">1</span> <span class="op">/</span> np.linalg.norm(w)</span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a>yy_up   <span class="op">=</span> yy <span class="op">+</span> w[<span class="dv">0</span>] <span class="op">/</span> w[<span class="dv">1</span>] <span class="op">*</span> margin</span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a>yy_down <span class="op">=</span> yy <span class="op">-</span> w[<span class="dv">0</span>] <span class="op">/</span> w[<span class="dv">1</span>] <span class="op">*</span> margin</span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-47"><a href="#cb2-47" aria-hidden="true" tabindex="-1"></a>ax.plot(xx, yy, <span class="st">"k-"</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb2-48"><a href="#cb2-48" aria-hidden="true" tabindex="-1"></a>ax.plot(xx, yy_up, <span class="st">"k--"</span>, linewidth<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb2-49"><a href="#cb2-49" aria-hidden="true" tabindex="-1"></a>ax.plot(xx, yy_down, <span class="st">"k--"</span>, linewidth<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb2-50"><a href="#cb2-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-51"><a href="#cb2-51" aria-hidden="true" tabindex="-1"></a><span class="co"># Resaltar puntos que violan el margen</span></span>
<span id="cb2-52"><a href="#cb2-52" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(X)):</span>
<span id="cb2-53"><a href="#cb2-53" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> clf.decision_function([X[i]])[<span class="dv">0</span>] <span class="op">*</span> y[i] <span class="op">&lt;</span> <span class="dv">1</span>:</span>
<span id="cb2-54"><a href="#cb2-54" aria-hidden="true" tabindex="-1"></a>        ax.scatter(X[i, <span class="dv">0</span>], X[i, <span class="dv">1</span>], s<span class="op">=</span><span class="dv">100</span>, facecolors<span class="op">=</span><span class="st">"none"</span>,</span>
<span id="cb2-55"><a href="#cb2-55" aria-hidden="true" tabindex="-1"></a>                  edgecolors<span class="op">=</span><span class="st">"red"</span>, linewidths<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb2-56"><a href="#cb2-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-57"><a href="#cb2-57" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">"$x_1$"</span>)</span>
<span id="cb2-58"><a href="#cb2-58" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">"$x_2$"</span>)</span>
<span id="cb2-59"><a href="#cb2-59" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">"Clasificador de margen suave (C=0.1)"</span>)</span>
<span id="cb2-60"><a href="#cb2-60" aria-hidden="true" tabindex="-1"></a>ax.legend()</span>
<span id="cb2-61"><a href="#cb2-61" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-svm-soft-margin" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-svm-soft-margin-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="10_svm_y_no_supervisado_files/figure-html/fig-svm-soft-margin-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-svm-soft-margin-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;2: Clasificador de margen suave con violaciones
</figcaption>
</figure>
</div>
</div>
</div>
<p>El parámetro <span class="math inline">\(C\)</span> controla la compensación entre sesgo y varianza del modelo.</p>
<ul>
<li><p>Si <span class="math inline">\(C\)</span> es <strong>pequeño</strong>, cada vez que un punto se mete en la calle (o queda mal clasificado) el costo en la función objetivo es alto; el algoritmo prefiere reducir el margen y mover la recta para sacar a todos los puntos de la calle. El modelo se ajusta muy bien a los datos de entrenamiento (bajo <strong>sesgo</strong>) pero pequeños cambios en los datos alteran mucho la frontera (alta <strong>varianza</strong>).</p></li>
<li><p>Si <span class="math inline">\(C\)</span> es <strong>grande</strong>, las violaciones casi no “cuentan”: el optimizador puede aceptar que algunos puntos queden dentro o incluso al otro lado de la calle con tal de ensanchar el margen. Esto actúa como regularización: la frontera depende menos de detalles locales (menor <strong>varianza</strong>), pero al ser más rígida puede no capturar complejidades reales del dato (mayor <strong>sesgo</strong>).</p></li>
</ul>
<p>En otras palabras, <span class="math inline">\(C\)</span> controla cuán caro es equivocarse: caro = modelo flexible que busca cero errores; barato = modelo moderado que sacrifica exactitud para ganar robustez.</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Advertencia
</div>
</div>
<div class="callout-body-container callout-body">
<p>En scikit-learn, el parámetro <code>C</code> está definido de manera inversa a como lo hemos definido en estas notas. En scikit-learn, un valor grande de <code>C</code> corresponde a un margen más estrecho y menos violaciones, mientras que un valor pequeño de <code>C</code> corresponde a un margen más ancho y más violaciones. Es decir, el <code>C</code> de scikit-learn es aproximadamente inversamente proporcional al <span class="math inline">\(C\)</span> definido en estas notas.</p>
</div>
</div>
</section>
<section id="máquinas-de-vectores-de-soporte-svm-no-lineales" class="level2">
<h2 class="anchored" data-anchor-id="máquinas-de-vectores-de-soporte-svm-no-lineales">Máquinas de Vectores de Soporte (SVM) no lineales</h2>
<p>Las Máquinas de Vectores de Soporte (SVM) extienden el clasificador de vectores soporte usando núcleos (kernels) para manejar problemas de clasificación no lineales.</p>
<p>Para límites no lineales, el espacio de características se amplía con funciones de los predictores (por ejemplo, términos cuadráticos).</p>
<div id="cell-fig-svm-no-lineal" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_moons</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> PolynomialFeatures</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> make_pipeline</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> LinearSVC</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib.colors <span class="im">import</span> ListedColormap</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>X, y  <span class="op">=</span> make_moons(n_samples<span class="op">=</span><span class="dv">100</span>, noise<span class="op">=</span><span class="fl">0.15</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>polynomial_svm_clf <span class="op">=</span> make_pipeline(</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    PolynomialFeatures(degree<span class="op">=</span><span class="dv">3</span>),</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    StandardScaler(),</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    LinearSVC(C<span class="op">=</span><span class="dv">10</span>, max_iter<span class="op">=</span><span class="dv">10_000</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>polynomial_svm_clf.fit(X, y)</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[y<span class="op">==</span><span class="dv">0</span>,<span class="dv">0</span>], X[y<span class="op">==</span><span class="dv">0</span>,<span class="dv">1</span>])</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[y<span class="op">==</span><span class="dv">1</span>,<span class="dv">0</span>], X[y<span class="op">==</span><span class="dv">1</span>,<span class="dv">1</span>])</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a mesh grid for plotting the decision boundary</span></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>x_min, x_max <span class="op">=</span> X[:, <span class="dv">0</span>].<span class="bu">min</span>() <span class="op">-</span> <span class="fl">0.5</span>, X[:, <span class="dv">0</span>].<span class="bu">max</span>() <span class="op">+</span> <span class="fl">0.5</span></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>y_min, y_max <span class="op">=</span> X[:, <span class="dv">1</span>].<span class="bu">min</span>() <span class="op">-</span> <span class="fl">0.5</span>, X[:, <span class="dv">1</span>].<span class="bu">max</span>() <span class="op">+</span> <span class="fl">0.5</span></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>xx, yy <span class="op">=</span> np.meshgrid(np.arange(x_min, x_max, <span class="fl">0.01</span>),</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>                     np.arange(y_min, y_max, <span class="fl">0.01</span>))</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict the class of each point on the mesh grid</span></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>Z <span class="op">=</span> polynomial_svm_clf.predict(np.c_[xx.ravel(), yy.ravel()])</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Reshape Z to a 2D array</span></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>Z <span class="op">=</span> Z.reshape(xx.shape)</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a colormap for plotting the decision boundary</span></span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>cmap <span class="op">=</span> ListedColormap([<span class="st">'red'</span>, <span class="st">'green'</span>])</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the decision boundary</span></span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>plt.contourf(xx, yy, Z, cmap<span class="op">=</span>cmap, alpha<span class="op">=</span><span class="fl">0.2</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-svm-no-lineal" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-svm-no-lineal-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="10_svm_y_no_supervisado_files/figure-html/fig-svm-no-lineal-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-svm-no-lineal-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;3: SVM no lineal
</figcaption>
</figure>
</div>
</div>
</div>
<p>En la <a href="#fig-svm-no-lineal" class="quarto-xref">Figura&nbsp;3</a> se muestra el límite de decisión de una SVM con un núcleo polinomial de grado 3. Esto agrega términos cuadráticos y cúbicos a la frontera de decisión. En dos dimensiones, esto funciona bien, pero en dimensiones más altas el número de términos polinomiales crece muy rápidamente. Por ejemplo, en 10 dimensiones, hay <span class="math inline">\(\binom{10}{2} = 45\)</span> términos cuadráticos y <span class="math inline">\(\binom{10}{3} = 240\)</span> términos cúbicos.</p>
<section id="truco-del-núcleo-kernel-trick" class="level3">
<h3 class="anchored" data-anchor-id="truco-del-núcleo-kernel-trick">Truco del núcleo (kernel trick)</h3>
<p>El truco del núcleo es una técnica matemática que permite a las Máquinas de Vectores de Soporte trabajar eficientemente en espacios de alta dimensión sin tener que calcular explícitamente las transformaciones de los datos. En lugar de transformar los datos a un espacio de mayor dimensión y luego calcular el producto punto (lo cual sería computacionalmente costoso), el truco del núcleo permite calcular directamente el producto punto en el espacio transformado.</p>
<p>La idea clave es que las Máquinas de Vectores de Soporte solo necesitan calcular productos punto entre los datos. El truco del núcleo permite calcular estos productos punto en el espacio transformado sin tener que conocer la transformación explícita.</p>
<p>Por ejemplo, consideremos el núcleo polinómico de grado 2:</p>
<p><span class="math display">\[
K(x, z) = (1 + x^T z)^2
\]</span></p>
<p>Para datos en <span class="math inline">\(\mathbb{R}^2\)</span>, este núcleo corresponde a una transformación <span class="math inline">\(\phi\)</span> que mapea los datos a un espacio de 6 dimensiones:</p>
<p><span class="math display">\[
\phi(x) = (1, \sqrt{2}x_1, \sqrt{2}x_2, x_1^2, x_2^2, \sqrt{2}x_1x_2)
\]</span></p>
<p>El truco del núcleo permite calcular <span class="math inline">\(K(x, z) = \phi(x)^T \phi(z)\)</span> sin tener que calcular explícitamente <span class="math inline">\(\phi(x)\)</span> y <span class="math inline">\(\phi(z)\)</span>. Esto es especialmente útil cuando la dimensión del espacio transformado es muy grande o incluso infinita.</p>
<p>Los núcleos más comunes son:</p>
<ul>
<li><p>Núcleo lineal:</p>
<p><span class="math display">\[
K(x_i, x_{i'}) = \sum_{j=1}^{p} x_{ij} x_{i'j}
\]</span></p></li>
<li><p>Núcleo polinómico (grado <span class="math inline">\(d\)</span>):</p>
<p><span class="math display">\[
K(x_i, x_{i'}) = \left(1 + \sum_{j=1}^{p} x_{ij} x_{i'j}\right)^d
\]</span></p></li>
<li><p>Núcleo radial (RBF): <span class="math display">\[
K(x_i, x_{i'}) = \exp\left(-\gamma \sum_{j=1}^{p}(x_{ij}-x_{i'j})^2\right)
\]</span></p></li>
</ul>
<p>El núcleo radial es particularmente interesante porque corresponde a una transformación a un espacio de dimensión infinita, lo que sería imposible de calcular explícitamente. Sin embargo, gracias al truco del núcleo, podemos trabajar con este espacio de manera eficiente. Tiene la forma de una Gaussiana, donde <span class="math inline">\(\gamma\)</span> controla la varianza de la Gaussiana. Es decir, para <span class="math inline">\(\gamma\)</span> grande la campana es estrecha y para <span class="math inline">\(\gamma\)</span> pequeño la campana es más amplia. Cuando la campana es estrecha, cada punto es afectado por puntos cercanos, tal que la influencia de cada punto se vuelve más local. Esto hace que la frontera de decisión sea más ondulada y el modelo sea más flexible pero también más susceptible a sobreajuste. Por el contrario, cuando la campana es más amplia, cada punto es afectado por más puntos, lo que hace que la frontera de decisión sea más rígida y menos susceptible a sobreajuste pero con un mayor sesgo.</p>
<p>La función de decisión de las Máquinas de Vectores de Soporte con núcleo <span class="math inline">\(K\)</span> es:</p>
<p><span class="math display">\[
f(x) = \beta_0 + \sum_{i \in S} \alpha_i K(x, x_i)
\]</span></p>
<p>Esto es equivalente al hiperplano <span class="math inline">\(\beta_0 + \sum_{j=1}^{p} \beta_j \phi_j(x) = 0\)</span> en el espacio de características transformado.</p>
<p>Como antes, solo los vectores soporte (observaciones cercanas al margen o que lo violan) afectan el límite de decisión.</p>
<p>En pocas palabras, el núcleo o kernel es equivalente a calcular el producto punto en un espacio de dimensión elevada. Este producto se usa en lugar de calcular la transformación explícita. No lo demostramos aquí por falta de tiempo, pero el producto punto es lo único que se necesita para calcular el límite de decisión.</p>
<div id="cell-fig-svm-rbf" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVC</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_regions_rbf_example(gamma, C, ax):</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Train the classifier</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    rbf_kernel_svm_clf <span class="op">=</span> make_pipeline(StandardScaler(),</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    SVC(kernel<span class="op">=</span><span class="st">"rbf"</span>, gamma<span class="op">=</span>gamma, C<span class="op">=</span>C))</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    rbf_kernel_svm_clf.fit(X, y)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    ax.scatter(X[y<span class="op">==</span><span class="dv">0</span>,<span class="dv">0</span>], X[y<span class="op">==</span><span class="dv">0</span>,<span class="dv">1</span>])</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    ax.scatter(X[y<span class="op">==</span><span class="dv">1</span>,<span class="dv">0</span>], X[y<span class="op">==</span><span class="dv">1</span>,<span class="dv">1</span>])</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a mesh grid for plotting the decision boundary</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    x_min, x_max <span class="op">=</span> X[:, <span class="dv">0</span>].<span class="bu">min</span>() <span class="op">-</span> <span class="fl">0.5</span>, X[:, <span class="dv">0</span>].<span class="bu">max</span>() <span class="op">+</span> <span class="fl">0.5</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>    y_min, y_max <span class="op">=</span> X[:, <span class="dv">1</span>].<span class="bu">min</span>() <span class="op">-</span> <span class="fl">0.5</span>, X[:, <span class="dv">1</span>].<span class="bu">max</span>() <span class="op">+</span> <span class="fl">0.5</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>    xx, yy <span class="op">=</span> np.meshgrid(np.arange(x_min, x_max, <span class="fl">0.01</span>),</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>                         np.arange(y_min, y_max, <span class="fl">0.01</span>))</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Predict the class of each point on the mesh grid</span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>    Z <span class="op">=</span> rbf_kernel_svm_clf.predict(np.c_[xx.ravel(), yy.ravel()])</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Reshape Z to a 2D array</span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>    Z <span class="op">=</span> Z.reshape(xx.shape)</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a colormap for plotting the decision boundary</span></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>    cmap <span class="op">=</span> ListedColormap([<span class="st">'red'</span>, <span class="st">'green'</span>])</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot the decision boundary</span></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>    ax.contourf(xx, yy, Z, cmap<span class="op">=</span>cmap, alpha<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="ss">f'gamma=</span><span class="sc">{</span>gamma<span class="sc">}</span><span class="ss">, C=</span><span class="sc">{</span>C<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a 2x2 grid of plots</span></span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">6</span>))</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the parameter combinations</span></span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> [</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>    (<span class="fl">0.1</span>, <span class="fl">0.001</span>),</span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>    (<span class="fl">0.1</span>, <span class="dv">1000</span>),</span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>    (<span class="dv">5</span>, <span class="fl">0.001</span>),</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>    (<span class="dv">5</span>, <span class="dv">1000</span>)</span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot each combination</span></span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (gamma, C), ax <span class="kw">in</span> <span class="bu">zip</span>(params, axes.ravel()):</span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a>    plot_regions_rbf_example(gamma, C, ax)</span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-svm-rbf" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-svm-rbf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="10_svm_y_no_supervisado_files/figure-html/fig-svm-rbf-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-svm-rbf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;4: SVM con núcleo radial
</figcaption>
</figure>
</div>
</div>
</div>
<p>En la <a href="#fig-svm-rbf" class="quarto-xref">Figura&nbsp;4</a> se muestra el límite de decisión de un SVM con núcleo radial para diferentes valores de <span class="math inline">\(C\)</span> y <span class="math inline">\(\gamma\)</span>. Para valores pequeños de <span class="math inline">\(C\)</span> se permiten muchas violaciones del margen. Para valores grandes de <span class="math inline">\(C\)</span> se permiten pocas violaciones del margen pero se puede terminar en sobreajuste. Al aumentar <span class="math inline">\(\gamma\)</span> la campana Gaussiana se hace más estrecha. La influencia de cada instancia se vuelve más local, lo que lleva a una frontera más ondulada. Si el modelo sobreajusta, reduce <span class="math inline">\(\gamma\)</span> y viceversa.</p>
</section>
<section id="svm-multiclase" class="level3">
<h3 class="anchored" data-anchor-id="svm-multiclase">SVM multiclase</h3>
<p>Las SVM definen una frontera de decisión para separar dos clases. Cuando tenemos más de dos clases, podemos intentar las siguientes estrategias:</p>
<ul>
<li><strong>Uno contra uno</strong>: Para cada pareja de clases se construye una SVM. En total se construyen <span class="math inline">\(\binom{K}{2}\)</span> SVM para clasificación con <span class="math inline">\(K\)</span> clases. Cada punto se asigna a la clase que ocurre más veces en esas comparaciones. Cada SVM usa pocos puntos ya que solo se usan las observaciones de las dos clases que se están separando. Sin embargo, el número de SVMs crece rápidamente con <span class="math inline">\(K\)</span>, lo que puede llevar a predicciones lentas (necesita clasificar muchas veces y tomar la más frecuente).</li>
<li><strong>Uno contra todos</strong>: Para cada clase, se construye una SVM que determina la frontera entre esa clase y todas las demás. Se construyen <span class="math inline">\(K\)</span> SVM, cada una frente a todas las demás. Cada punto se asigna a la clase que ocurre más veces en esas comparaciones. Sin embargo puede tener problemas cuando alguna clase se solapa con otras varias.</li>
</ul>
</section>
</section>
</section>
<section id="aprendizaje-no-supervisado" class="level1">
<h1>Aprendizaje no supervisado</h1>
<p>El aprendizaje no supervisado es una técnica de aprendizaje automático que busca encontrar patrones en los datos sin tener una respuesta previa. Estudiaremos dos de los algoritmos más populares de aprendizaje no supervisado: el clustering y el reducción de dimensionalidad. En cada uno introduciremos los algoritmos más básicos. Motivamos al estudiante a explorar por su cuenta más a fondo el aprendizaje no supervisado, que es una rama de investigación muy activa.</p>
<section id="análisis-de-componentes-principales-pca" class="level2">
<h2 class="anchored" data-anchor-id="análisis-de-componentes-principales-pca">Análisis de componentes principales (PCA)</h2>
<p>El análisis de componentes principales (PCA) es una técnica de aprendizaje no supervisado utilizada para simplificar conjuntos de datos correlacionados de alta dimensión, reduciendo su dimensionalidad mientras se conserva la mayor cantidad posible de varianza. PCA identifica las direcciones (componentes principales) a lo largo de las cuales los datos varían más y proyecta los datos originales sobre estas direcciones.</p>
<section id="definición-de-los-componentes-principales" class="level3">
<h3 class="anchored" data-anchor-id="definición-de-los-componentes-principales">Definición de los Componentes Principales</h3>
<p>La intuición es la siguiente: La matriz de covarianza contiene la varianza de cada variable y su correlación con otras variables. Es una matriz simétrica, es decir, <span class="math inline">\(\boldsymbol{\Sigma}_{ij} = \boldsymbol{\Sigma}_{ji}\)</span>. Por lo tanto, siempre es posible diagonalizarla. Esto quiere decir que podemos encontrar autovectores y autovalores de la matriz de covarianza. Estos autovectores son ortogonales entre ellos, en otras palabras, si cambianos la lista de variables <span class="math inline">\(\{x_1, ..., x_q\}\)</span> por una lista de autovectores <span class="math inline">\(\{\phi_1, ..., \phi_q\}\)</span>, la matriz de covarianza de estos será diagonal. Esto es equivalente a cambiar de variables en el espacio de parámetros para obtener nuevas variables no correlacionadas.</p>
<p>Los componentes principales se definen a través de los autovectores de la matriz de covarianza. En los datos esta es <span class="math inline">\(\mathbf{X}^T\mathbf{X}\)</span>, donde la componente <span class="math inline">\(X_{ij}\)</span> como siempre se refiere a la medición <span class="math inline">\(i\)</span>, variable <span class="math inline">\(j\)</span> (cada fila es una medición y cada columna es una variable).</p>
<p>El primer vector de componentes principales, <span class="math inline">\(\boldsymbol{\phi}_1\)</span>, es el autovector de <span class="math inline">\(\mathbf{X}^T\mathbf{X}\)</span> asociado al mayor autovalor. Representa la dirección en el espacio de características a lo largo de la cual los datos varían más. Es decir, la dirección en la que hay más información.</p>
<p>Formalmente, el primer componente principal se expresa como:</p>
<p><span class="math display">\[
Z_1 = \mathbf{X}\boldsymbol{\phi}_1
\]</span></p>
<p>donde <span class="math inline">\(\boldsymbol{\phi}_1\)</span> satisface:</p>
<p><span class="math display">\[
\mathbf{X}^T\mathbf{X}\boldsymbol{\phi}_1 = \lambda_1\boldsymbol{\phi}_1
\]</span></p>
<p>siendo <span class="math inline">\(\lambda_1\)</span> el mayor autovalor. Al ser un autovector, <span class="math inline">\(\boldsymbol{\phi}_1\)</span> está definido salvo una constante multiplicativa.</p>
<p>El siguiente componente principal <span class="math inline">\(\boldsymbol{\phi}_2\)</span> es el autovector asociado al siguiente autovalor más grande, y así sucesivamente. El autovalor de la matriz de covarianza representa la varianza de los datos en esa dirección. Escogemos los <span class="math inline">\(m\)</span> autovectores de mayor autovalor para que los componentes principales expliquen la mayor variabilidad posible de los datos.</p>
<p>Los autovectores de una matriz simétrica son ortogonales entre sí, es decir, <span class="math inline">\(\boldsymbol{\phi}_i^T\boldsymbol{\phi}_j = 0\)</span> para <span class="math inline">\(i \neq j\)</span>. Por lo tanto, los componentes principales no están correlacionados entre sí.</p>
<p>En este sentido, el PCA con <span class="math inline">\(m\)</span> componentes busca las <span class="math inline">\(m\)</span> direcciones no correlacionadas que explican la mayor variabilidad posible de los datos.</p>
</section>
<section id="proporción-de-varianza-explicada-pve" class="level3">
<h3 class="anchored" data-anchor-id="proporción-de-varianza-explicada-pve">Proporción de Varianza Explicada (PVE)</h3>
<p>La proporción de varianza explicada por cada componente principal está dada por:</p>
<p><span class="math display">\[
\text{PVE}_m = \frac{\sum_{i=1}^{n} z_{im}^2}{\sum_{j=1}^{p}\sum_{i=1}^{n} x_{ij}^2}
\]</span></p>
<p>La PVE ayuda a determinar cuántos componentes representan suficientemente los datos. Típicamente, se seleccionan componentes hasta que se observa un “codo” en el gráfico de scree.</p>
</section>
<section id="consideraciones-prácticas" class="level3">
<h3 class="anchored" data-anchor-id="consideraciones-prácticas">Consideraciones Prácticas</h3>
<section id="escalado-de-las-variables" class="level4">
<h4 class="anchored" data-anchor-id="escalado-de-las-variables">Escalado de las Variables</h4>
<p>Generalmente, las variables requieren ser escaladas a varianza unitaria, especialmente si están medidas en distintas escalas, para asegurar que ninguna variable influya desproporcionadamente en el PCA.</p>
</section>
<section id="unicidad" class="level4">
<h4 class="anchored" data-anchor-id="unicidad">Unicidad</h4>
<p>Los componentes principales son únicos salvo un cambio de signo. Por lo tanto, los resultados de diferentes paquetes de software pueden diferir en los signos pero representarán las mismas direcciones en el espacio de características.</p>
</section>
</section>
<section id="selección-del-número-de-componentes" class="level3">
<h3 class="anchored" data-anchor-id="selección-del-número-de-componentes">Selección del Número de Componentes</h3>
<p>Determinar el número de componentes principales es generalmente subjetivo. Prácticas comunes incluyen:</p>
<ul>
<li>Inspeccionar gráficos de scree para encontrar un “codo”. Es decir, graficamos <span class="math inline">\(\text{PVE}_i\)</span> para <span class="math inline">\(i=1,\dots,q\)</span>. La cantidad de varianza explicada subirá a medida que agregamos más componentes, pero llegará un punto donde ganaremos poco al agregar el siguiente. A esto se lo llama el “codo”.</li>
<li>Elegir suficientes componentes para capturar una proporción acumulada significativa de varianza. Por ejemplo, si queremos capturar el 95% de la varianza, usamos <span class="math inline">\(\sum_{i=1}^{m} \text{PVE}_i \geq 0.95\)</span>.</li>
</ul>
<p>En contextos supervisados, el número de componentes puede seleccionarse mediante validación cruzada.</p>
</section>
<section id="usos-adicionales-del-pca" class="level3">
<h3 class="anchored" data-anchor-id="usos-adicionales-del-pca">Usos Adicionales del PCA</h3>
<p>Más allá de la visualización y la reducción de dimensionalidad, PCA puede utilizarse para:</p>
<ul>
<li>Preprocesamiento de datos para regresión o clasificación.</li>
<li>Imputación de datos faltantes, es decir, completar valores faltantes en la matrix de datos <span class="math inline">\(\mathbf{X}\)</span>.</li>
<li>Mejorar la estabilidad y reducir el ruido en varios métodos analíticos.</li>
</ul>
</section>
<section id="ejemplo-de-pca-para-compresión-de-imágenes" class="level3">
<h3 class="anchored" data-anchor-id="ejemplo-de-pca-para-compresión-de-imágenes">Ejemplo de PCA para compresión de imágenes</h3>
<p>En este ejemplo, usamos PCA para comprimir una imagen de un dígito escrito a mano. Usamos los datos de dígitos del paquete <code>sklearn</code>.</p>
<div id="cell-fig-digitos" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> fetch_openml</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>mnist <span class="op">=</span> fetch_openml(<span class="st">'mnist_784'</span>, as_frame<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>X_train, y_train <span class="op">=</span> mnist.data[:<span class="dv">60_000</span>], mnist.target[:<span class="dv">60_000</span>]</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>X_test, y_test <span class="op">=</span> mnist.data[<span class="dv">60_000</span>:], mnist.target[<span class="dv">60_000</span>:]</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>indexes <span class="op">=</span> np.random.random_integers(<span class="dv">0</span>, <span class="bu">len</span>(X_train), <span class="dv">9</span>)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>sample <span class="op">=</span> X_train[indexes].reshape(<span class="dv">3</span>,<span class="dv">3</span>,<span class="dv">28</span>,<span class="dv">28</span>)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>plt.imshow(np.block([[sample[i,j] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>)] <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>)]), cmap<span class="op">=</span><span class="st">'gray_r'</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>/tmp/ipykernel_113981/122722974.py:7: DeprecationWarning: This function is deprecated. Please call randint(0, 60000 + 1) instead
  indexes = np.random.random_integers(0, len(X_train), 9)</code></pre>
</div>
<div class="cell-output cell-output-display">
<div id="fig-digitos" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-digitos-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="10_svm_y_no_supervisado_files/figure-html/fig-digitos-output-2.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-digitos-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;5: Dígitos de MNIST
</figcaption>
</figure>
</div>
</div>
</div>
<p>En scikit-learn, el PCA se puede aplicar con la clase <code>PCA</code> del módulo <code>decomposition</code>. Podemos especificar que el número de componentes principales explique una proporción de la varianza. Pediremos el 95% de la varianza.</p>
<div id="cell-fig-pca-digitos" class="cell" data-execution_count="7">
<details class="code-fold">
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="fl">0.95</span>)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>X_reduced <span class="op">=</span> pca.fit_transform(X_train)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>X_recovered <span class="op">=</span> pca.inverse_transform(X_reduced)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>sample <span class="op">=</span> X_recovered[indexes].reshape(<span class="dv">3</span>,<span class="dv">3</span>,<span class="dv">28</span>,<span class="dv">28</span>)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>plt.imshow(np.block([[sample[i,j] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>)] <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>)]), cmap<span class="op">=</span><span class="st">'gray_r'</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-pca-digitos" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-pca-digitos-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="10_svm_y_no_supervisado_files/figure-html/fig-pca-digitos-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-pca-digitos-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;6: PCA para compresión de imágenes
</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="métodos-de-clustering" class="level2">
<h2 class="anchored" data-anchor-id="métodos-de-clustering">Métodos de Clustering</h2>
<section id="introducción" class="level3">
<h3 class="anchored" data-anchor-id="introducción">Introducción</h3>
<p>El clustering es un conjunto amplio de técnicas para encontrar subgrupos (clusters) en un conjunto de datos. El objetivo es dividir las observaciones en grupos distintos de tal manera que las observaciones dentro de un mismo grupo sean similares entre sí y diferentes a las de otros grupos. La definición de similitud o diferencia depende del contexto y del tipo específico de datos.</p>
<p>Aunque tanto el clustering como PCA buscan simplificar datos, sus mecanismos son diferentes:</p>
<ul>
<li><strong>PCA</strong> busca una representación de baja dimensión que explique gran parte de la varianza.</li>
<li><strong>Clustering</strong> busca subgrupos homogéneos entre las observaciones.</li>
</ul>
</section>
<section id="clustering-k-means" class="level3">
<h3 class="anchored" data-anchor-id="clustering-k-means">Clustering K-means</h3>
<p>El clustering K-means es un método sencillo para particionar un conjunto de datos en <span class="math inline">\(K\)</span> clusters distintos y no superpuestos. Es necesario especificar previamente el número <span class="math inline">\(K\)</span> de clusters.</p>
<p>Dado un conjunto de observaciones $ x_{ij} $, se busca minimizar la variación intra-cluster:</p>
<p><span class="math display">\[
\min_{C_1, \dots, C_K} \sum_{k=1}^{K} \frac{1}{|C_k|}\sum_{i,i' \in C_k}\sum_{j=1}^{p}(x_{ij}-x_{i'j})^2
\]</span></p>
<p>donde <span class="math inline">\(C_k\)</span> representa el conjunto de índices de las observaciones en el cluster <span class="math inline">\(k\)</span>.</p>
<section id="algoritmo-k-means" class="level4">
<h4 class="anchored" data-anchor-id="algoritmo-k-means">Algoritmo K-means</h4>
<ol type="1">
<li>Asignar aleatoriamente cada observación a uno de los <span class="math inline">\(K\)</span> clusters.</li>
<li>Iterar hasta que las asignaciones no cambien:
<ul>
<li>Calcular el centroide de cada cluster (vector promedio).</li>
<li>Reasignar cada observación al cluster cuyo centroide esté más cerca (en términos de distancia euclidiana).</li>
</ul></li>
</ol>
<p>El resultado es una solución óptima local (puede no encontrar la solución óptima global), por lo que conviene repetir el algoritmo múltiples veces desde diferentes inicializaciones aleatorias.</p>
<p>El paso 1 es crucial para el resultado final. Si se elige mal, el algoritmo puede converger a un resultado subóptimo. Existen varias estrategias que mejoran la elección inicial. Por ejemplo, se puede elegir el centroide inicial como el punto más alejado de los centroides de los clusters ya existentes, que es lo que hace el algoritmo <code>KMeans++</code> implementado en <code>sklearn</code> por defecto cuando se usa el método <code>KMeans</code>.</p>
</section>
</section>
<section id="elección-de-la-medida-de-disimilitud" class="level3">
<h3 class="anchored" data-anchor-id="elección-de-la-medida-de-disimilitud">Elección de la medida de disimilitud</h3>
<p>La distancia euclidiana es común, pero pueden preferirse otras medidas como la basada en correlación, que considera similares aquellas observaciones con perfiles correlacionados, independientemente de sus magnitudes absolutas.</p>
</section>
<section id="cuestiones-prácticas" class="level3">
<h3 class="anchored" data-anchor-id="cuestiones-prácticas">Cuestiones prácticas</h3>
<ul>
<li><strong>Escalado</strong>: Se recomienda escalar las variables a desviación estándar uno, especialmente cuando están medidas en escalas distintas. Esto es porque la distancia es sensible a la escala de las variables.</li>
<li><strong>Robustez</strong>: Los resultados del clustering pueden ser sensibles a decisiones como tipo de vínculo, escalado y selección del número de clusters. Por lo tanto, es recomendable evaluar la robustez del clustering mediante diferentes configuraciones y subconjuntos del conjunto de datos.</li>
</ul>
</section>
<section id="ejemplo-de-clustering-k-means" class="level3">
<h3 class="anchored" data-anchor-id="ejemplo-de-clustering-k-means">Ejemplo de clustering K-means</h3>
<div id="cell-fig-clustering-kmeans-blobs" class="cell" data-execution_count="8">
<details class="code-fold">
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_blobs</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>k <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> make_blobs(n_samples<span class="op">=</span><span class="dv">500</span>, centers<span class="op">=</span>k, n_features<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="co"># make the blobs: y contains the cluster IDs, but we</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="co"># will not use them; that's what we want to predict</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>k, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> kmeans.fit_predict(X)</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[y<span class="op">==</span><span class="dv">0</span>,<span class="dv">0</span>], X[y<span class="op">==</span><span class="dv">0</span>,<span class="dv">1</span>])</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[y<span class="op">==</span><span class="dv">1</span>,<span class="dv">0</span>], X[y<span class="op">==</span><span class="dv">1</span>,<span class="dv">1</span>])</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[y<span class="op">==</span><span class="dv">2</span>,<span class="dv">0</span>], X[y<span class="op">==</span><span class="dv">2</span>,<span class="dv">1</span>])</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[y<span class="op">==</span><span class="dv">3</span>,<span class="dv">0</span>], X[y<span class="op">==</span><span class="dv">3</span>,<span class="dv">1</span>])</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[y<span class="op">==</span><span class="dv">4</span>,<span class="dv">0</span>], X[y<span class="op">==</span><span class="dv">4</span>,<span class="dv">1</span>])</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a mesh grid for plotting the decision boundary</span></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>x_min, x_max <span class="op">=</span> X[:, <span class="dv">0</span>].<span class="bu">min</span>() <span class="op">-</span> <span class="fl">0.5</span>, X[:, <span class="dv">0</span>].<span class="bu">max</span>() <span class="op">+</span> <span class="fl">0.5</span></span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>y_min, y_max <span class="op">=</span> X[:, <span class="dv">1</span>].<span class="bu">min</span>() <span class="op">-</span> <span class="fl">0.5</span>, X[:, <span class="dv">1</span>].<span class="bu">max</span>() <span class="op">+</span> <span class="fl">0.5</span></span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>xx, yy <span class="op">=</span> np.meshgrid(np.arange(x_min, x_max, <span class="fl">0.01</span>),</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>                     np.arange(y_min, y_max, <span class="fl">0.01</span>))</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict the class of each point on the mesh grid</span></span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>Z <span class="op">=</span> kmeans.predict(np.c_[xx.ravel(), yy.ravel()])</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Reshape Z to a 2D array</span></span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>Z <span class="op">=</span> Z.reshape(xx.shape)</span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a colormap for plotting the decision boundary</span></span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a><span class="co">#cmap = ListedColormap(['red', 'green', 'blue', 'yellow', 'gray'])</span></span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the decision boundary</span></span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a>plt.contourf(xx, yy, Z, cmap<span class="op">=</span><span class="st">'jet'</span>, alpha<span class="op">=</span><span class="fl">0.2</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-clustering-kmeans-blobs" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-clustering-kmeans-blobs-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="10_svm_y_no_supervisado_files/figure-html/fig-clustering-kmeans-blobs-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-clustering-kmeans-blobs-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;7: Clustering K-means para datos ficticios
</figcaption>
</figure>
</div>
</div>
</div>
<p>En la figura <a href="#fig-clustering-kmeans-blobs" class="quarto-xref">Figura&nbsp;7</a> se muestra el resultado del clustering K-means para datos ficticios. Vemos que funciona bien para este caso.</p>
</section>
<section id="ejemplo-de-clustering-para-segmentación-de-imágenes" class="level3">
<h3 class="anchored" data-anchor-id="ejemplo-de-clustering-para-segmentación-de-imágenes">Ejemplo de clustering para segmentación de imágenes</h3>
<p>Ahora queremos segmentar imágenes. Es decir, queremos agrupar píxeles similares entre sí. Esto ocurre frecuentemente en física, donde podemos tener imágenes de un experimento y nos gustaría identificar objetos o regiones. Nuestro ejemplo será reducir los colores de una imagen. Cada píxel tiene un color, que es un vector de tres componentes (rojo, verde, azul). Queremos agrupar píxeles similares entre sí en el espacio de colores.</p>
<div id="cell-fig-ladybug" class="cell" data-execution_count="9">
<details class="code-fold">
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>IMAGES_PATH <span class="op">=</span> Path(<span class="st">'data'</span>)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>filename <span class="op">=</span> <span class="st">'ladybug.png'</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>filepath <span class="op">=</span> IMAGES_PATH <span class="op">/</span> filename</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>image <span class="op">=</span> np.asarray(Image.<span class="bu">open</span>(filepath))</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>plt.imshow(image)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-ladybug" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ladybug-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="10_svm_y_no_supervisado_files/figure-html/fig-ladybug-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ladybug-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;8: Imagen de muestra que queremos segmentar
</figcaption>
</figure>
</div>
</div>
</div>
<p>En la figura <a href="#fig-ladybug" class="quarto-xref">Figura&nbsp;8</a> se muestra una imagen de muestra que queremos segmentar.</p>
<div id="cell-fig-ladybug-segmented-10" class="cell" data-execution_count="10">
<details class="code-fold">
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> cluster_image(n_clusters):</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> image.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">3</span>) <span class="co"># Convertir en tres matrices, una por color</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>n_clusters, random_state<span class="op">=</span><span class="dv">42</span>).fit(X) <span class="co"># entrenar un clustering k-medias</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    img_segmentada <span class="op">=</span> kmeans.cluster_centers_[kmeans.labels_] <span class="co"># reemplazar cada píxel por su etiqueta de cluster</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    img_segmentada <span class="op">=</span> img_segmentada.reshape(image.shape).astype(<span class="bu">int</span>) <span class="co"># convertir de nuevo en una imagen</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    plt.imshow(img_segmentada)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>cluster_image(<span class="dv">10</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-ladybug-segmented-10" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ladybug-segmented-10-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="10_svm_y_no_supervisado_files/figure-html/fig-ladybug-segmented-10-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ladybug-segmented-10-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;9: Imagen segmentada en 10 clusters, coloreada con los centroides de los clusters
</figcaption>
</figure>
</div>
</div>
</div>
<p>En la figura <a href="#fig-ladybug-segmented-10" class="quarto-xref">Figura&nbsp;9</a> se muestra el resultado del clustering K-means para la imagen de la figura <a href="#fig-ladybug" class="quarto-xref">Figura&nbsp;8</a>. Cada cluster se colorea con el color del centroide, es decir, con el color del punto central del cluster. Hagámoslo para menos clusters</p>
<div id="cell-fig-ladybug-segmented-5" class="cell" data-execution_count="11">
<details class="code-fold">
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>cluster_image(<span class="dv">5</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-ladybug-segmented-5" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ladybug-segmented-5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="10_svm_y_no_supervisado_files/figure-html/fig-ladybug-segmented-5-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ladybug-segmented-5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;10: Imagen segmentada en 5 clusters, coloreada con los centroides de los clusters
</figcaption>
</figure>
</div>
</div>
</div>
<p>En la figura <a href="#fig-ladybug-segmented-5" class="quarto-xref">Figura&nbsp;10</a> se muestra el resultado del clustering K-means para la imagen de la figura <a href="#fig-ladybug" class="quarto-xref">Figura&nbsp;8</a> con 5 clusters.</p>
</section>
</section>
</section>
<section id="ejercicios-sugeridos-para-la-prueba" class="level1">
<h1>Ejercicios Sugeridos Para la Prueba</h1>
<p>9.2, 9.3, 12.3</p>
<ul>
<li>Suponga que ajustamos un conjunto de datos con un modelo SVM y obtenemos un sobreajuste. ¿Qué puede hacer para reducir el sobreajuste?</li>
<li>Suponga que realizamos un PCA de un conjunto de datos y obtenemos que el primer componente principal explica el 95% de la varianza. ¿Qué significa esto?</li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiado");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiado");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/jorgenorena\.github\.io\/machine_learning_course\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>
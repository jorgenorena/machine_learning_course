<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="es" xml:lang="es"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Árboles, Bosques, Boosting – Aprendizaje Automático para Físicos</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-e13f217ceb0135cb77e1494052e28e8a.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Sin resultados",
    "search-matching-documents-text": "documentos encontrados",
    "search-copy-link-title": "Copiar el enlace en la búsqueda",
    "search-hide-matches-text": "Ocultar resultados adicionales",
    "search-more-match-text": "resultado adicional en este documento",
    "search-more-matches-text": "resultados adicionales en este documento",
    "search-clear-button-title": "Borrar",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar",
    "search-label": "Buscar"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar docked nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Aprendizaje Automático para Físicos</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Buscar"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Navegación de palanca" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-clases" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Clases</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-clases">    
        <li class="dropdown-header">Probabilidad y Estadística</li>
        <li>
    <a class="dropdown-item" href="./1_probabilidad.html">
 <span class="dropdown-text">1. Probabilidad</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./2_distribuciones_y_estimacion.html">
 <span class="dropdown-text">2. Distribuciones y Estimación</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./3_verosimilitud.html">
 <span class="dropdown-text">3. Verosimilitud</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./4_minimos_cuadrados_intervalos.html">
 <span class="dropdown-text">4. Mínimos Cuadrados e Intervalos</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./5_testeo_de_hipotesis_entropia.html">
 <span class="dropdown-text">5. Testeo de Hipótesis y Entropía</span></a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li class="dropdown-header">Aprendizaje Automático</li>
        <li>
    <a class="dropdown-item" href="./6_aprendizaje_automatico_regresion_lineal.html">
 <span class="dropdown-text">6. Aprendizaje Automático y Regresión Lineal</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./7_clasificacion.html">
 <span class="dropdown-text">7. Clasificación</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./8_seleccion_de_modelos.html">
 <span class="dropdown-text">8. Selección de Modelos</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./9_arboles_bosques_boosting.html">
 <span class="dropdown-text">9. Árboles, Bosques y Boosting</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./10_svm_y_no_supervisado.html">
 <span class="dropdown-text">10. SVM y Aprendizaje No Supervisado</span></a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li class="dropdown-header">Redes Neuronales</li>
        <li>
    <a class="dropdown-item" href="./11_perceptron_y_redes_conexas.html">
 <span class="dropdown-text">11. Perceptrón y Redes Conexas y Pérdidas</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./12_gradient_descent_and_autodiff.html">
 <span class="dropdown-text">12. Descenso de Gradiente y Auto-diferenciación</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./13_evaluacion_y_regularizacion_de_nn.html">
 <span class="dropdown-text">13. Evaluación y Regularización de redes neuronales</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./14_redes_convolucionales.html">
 <span class="dropdown-text">14. Redes Convolucionales</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./15_redes_residuales.html">
 <span class="dropdown-text">15. Redes Residuales</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./16_transformadores.html">
 <span class="dropdown-text">16. Transformadores y el mecanismo de atención</span></a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li class="dropdown-header">Algunas aplicaciones</li>
        <li>
    <a class="dropdown-item" href="./17_flujos_normalizantes.html">
 <span class="dropdown-text">17. Flujos Normalizantes</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./18_PINNs.html">
 <span class="dropdown-text">18. Redes Neuronales Informadas por la Física (PINNs)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./19_Operador_Neural.html">
 <span class="dropdown-text">19. Operadores Neuronales</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="./about.html"> 
<span class="menu-text">Acerca de</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./6_aprendizaje_automatico_regresion_lineal.html">Aprendizaje Automático</a></li><li class="breadcrumb-item"><a href="./9_arboles_bosques_boosting.html">9. Árboles, Bosques y Boosting</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Probabilidad y Estadística</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Alternar sección">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1_probabilidad.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1. Probabilidad</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2_distribuciones_y_estimacion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2. Distribuciones y Estimación</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3_verosimilitud.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3. Verosimilitud</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./4_minimos_cuadrados_intervalos.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4. Mínimos Cuadrados e Intervalos</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./5_testeo_de_hipotesis_entropia.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5. Testeo de Hipótesis y Entropía</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Aprendizaje Automático</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Alternar sección">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./6_aprendizaje_automatico_regresion_lineal.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">6. Aprendizaje Automático y Regresión Lineal</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./7_clasificacion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">7. Clasificación</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./8_seleccion_de_modelos.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">8. Selección de Modelos</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./9_arboles_bosques_boosting.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">9. Árboles, Bosques y Boosting</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10_svm_y_no_supervisado.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">10. SVM y Aprendizaje No Supervisado</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Redes Neuronales</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Alternar sección">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11_perceptron_y_redes_conexas.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">11. Perceptrón, Redes Conexas y Pérdidas</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12_gradient_descent_and_autodiff.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">12. Descenso de Gradiente y Auto-diferenciación</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13_evaluacion_y_regularizacion_de_nn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">13. Evaluación y Regularización de redes neuronales</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14_redes_convolucionales.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">14. Redes Convolucionales</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./15_redes_residuales.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">15. Redes Residuales</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./16_transformadores.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">16. Transformadores y el mecanismo de atención</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Algunas aplicaciones</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Alternar sección">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./17_flujos_normalizantes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">17. Flujos Normalizantes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./18_PINNs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">18. Redes Neuronales Informadas por la Física (PINNs)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./19_Operador_Neural.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">19. Operadores Neuronales</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">En esta página</h2>
   
  <ul>
  <li><a href="#árboles-de-decisión" id="toc-árboles-de-decisión" class="nav-link active" data-scroll-target="#árboles-de-decisión">Árboles de Decisión</a>
  <ul class="collapse">
  <li><a href="#árboles-de-clasificación" id="toc-árboles-de-clasificación" class="nav-link" data-scroll-target="#árboles-de-clasificación">Árboles de Clasificación</a></li>
  </ul></li>
  <li><a href="#métodos-de-ensamble" id="toc-métodos-de-ensamble" class="nav-link" data-scroll-target="#métodos-de-ensamble">Métodos de Ensamble</a>
  <ul class="collapse">
  <li><a href="#bagging-y-bosques-aleatorios" id="toc-bagging-y-bosques-aleatorios" class="nav-link" data-scroll-target="#bagging-y-bosques-aleatorios">Bagging y Bosques Aleatorios</a>
  <ul class="collapse">
  <li><a href="#bosques-aleatorios" id="toc-bosques-aleatorios" class="nav-link" data-scroll-target="#bosques-aleatorios">Bosques Aleatorios</a></li>
  </ul></li>
  <li><a href="#boosting" id="toc-boosting" class="nav-link" data-scroll-target="#boosting">Boosting</a></li>
  </ul></li>
  <li><a href="#importancia-de-cada-variable-en-métodos-basados-en-árboles" id="toc-importancia-de-cada-variable-en-métodos-basados-en-árboles" class="nav-link" data-scroll-target="#importancia-de-cada-variable-en-métodos-basados-en-árboles">Importancia de Cada Variable en Métodos Basados en Árboles</a></li>
  <li><a href="#comparación-de-métodos" id="toc-comparación-de-métodos" class="nav-link" data-scroll-target="#comparación-de-métodos">Comparación de Métodos</a>
  <ul class="collapse">
  <li><a href="#árboles-de-decisión-1" id="toc-árboles-de-decisión-1" class="nav-link" data-scroll-target="#árboles-de-decisión-1">Árboles de Decisión</a></li>
  <li><a href="#bagging" id="toc-bagging" class="nav-link" data-scroll-target="#bagging">Bagging</a></li>
  <li><a href="#bosques-aleatorios-1" id="toc-bosques-aleatorios-1" class="nav-link" data-scroll-target="#bosques-aleatorios-1">Bosques Aleatorios</a></li>
  <li><a href="#boosting-1" id="toc-boosting-1" class="nav-link" data-scroll-target="#boosting-1">Boosting</a></li>
  </ul></li>
  <li><a href="#ejercicios-sugeridos-para-la-prueba" id="toc-ejercicios-sugeridos-para-la-prueba" class="nav-link" data-scroll-target="#ejercicios-sugeridos-para-la-prueba">Ejercicios sugeridos para la prueba</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./6_aprendizaje_automatico_regresion_lineal.html">Aprendizaje Automático</a></li><li class="breadcrumb-item"><a href="./9_arboles_bosques_boosting.html">9. Árboles, Bosques y Boosting</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">Árboles, Bosques, Boosting</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Ahora estamos listos para estudiar algunos de los algoritmos más sofisticados. Empezaremos por un par que son sorprendentemente podersosos cuando la cantidad de datos es limitada y estos tienen una estructura bien definida (por ejemplo tenemos una tabla de datos). Estos son los bosques aleatorios y el boosting.</p>
<p>Pero antes, debemos empezar por un método bastante sencillo (y muy interpretable).</p>
<p>Trabajaremos con el siguiente ejemplo artificial</p>
<div id="3c2add4a" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Fijar la semilla de aleatoriedad para reproducibilidad</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># ---- Parámetros ----</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">500</span>         <span class="co"># Número de puntos de datos</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> <span class="dv">6</span>           <span class="co"># Dimensionalidad del espacio de entrada</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Parámetros de la señal:</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>sigma_senal <span class="op">=</span> <span class="fl">0.1</span>  <span class="co"># Controla la agudeza del pico alrededor de radio = 2</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Parámetros del ruido:</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>sigma_ruido <span class="op">=</span> <span class="fl">0.05</span>  <span class="co"># Amplitud del ruido (ruido blanco)</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="co"># ---- Generar el conjunto de datos ----</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Generar N puntos distribuidos uniformemente en el hiper-cubo [-1.5, 1.5]^6.</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>datos <span class="op">=</span> np.random.uniform(<span class="op">-</span><span class="fl">1.5</span>, <span class="fl">1.5</span>, size<span class="op">=</span>(N, d))</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Calcular la norma euclidiana (radio) para cada punto.</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>radio <span class="op">=</span> np.linalg.norm(datos, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Calcular la señal base como una función gaussiana del radio.</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="co">#    Esta función tiene un máximo (valor 1) cuando radio = 2.</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>senal <span class="op">=</span> np.exp(<span class="op">-</span>((radio <span class="op">-</span> <span class="dv">2</span>)<span class="op">**</span><span class="dv">2</span>) <span class="op">/</span> (<span class="dv">2</span> <span class="op">*</span> sigma_senal<span class="op">**</span><span class="dv">2</span>))</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Generar ruido gaussiano no correlacionado (ruido blanco).</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>ruido <span class="op">=</span> np.random.normal(loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span>sigma_ruido, size<span class="op">=</span>N)</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. Definir la variable objetivo (target) sumando la señal y el ruido.</span></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>objetivo <span class="op">=</span> senal <span class="op">+</span> ruido </span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a><span class="co"># ---- Visualización ----</span></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Puesto que la función subyacente depende solo del radio, se grafica la variable objetivo y la señal verdadera en función del radio.</span></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">5</span>))</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>plt.scatter(radio, objetivo, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">'Objetivo ruidoso (y)'</span>)</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>plt.scatter(radio, senal, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">'Señal verdadera (senal)'</span>, color<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Radio (||x||)"</span>)</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Valor de la variable objetivo"</span>)</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Variable Objetivo en Función del Radio en 6D"</span>)</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a><span class="co"># ---- Salida Resumida ----</span></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Dimensiones del conjunto de datos:"</span>)</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Forma de datos:"</span>, datos.shape)</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Forma de objetivo:"</span>, objetivo.shape)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="9_arboles_bosques_boosting_files/figure-html/cell-2-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Dimensiones del conjunto de datos:
Forma de datos: (500, 6)
Forma de objetivo: (500,)</code></pre>
</div>
</div>
<p>Generamos datos en una hiperesfera de seis dimensiones. Los datos verdaderos dependen sólo del radio de la hiperesfera, pero tenemos los valores de cada una de las seis variables. Este es un caso muy no-lineal, por lo que no es fácil de aproximar con un modelo lineal como la mayoría de los vistos hasta ahora.</p>
<section id="árboles-de-decisión" class="level1">
<h1>Árboles de Decisión</h1>
<p>Los árboles de decisión consisten en hacer una regresión o una clasificación basada en una serie de decisiones.</p>
<p>Cada decisión consiste en mirar una variable. Si el valor de la variable es mayor que un valor de corte nos vamos por una rama, si es menor nos vamos por otra rama. Vemos un ejemplo en la <a href="#fig-ejemplo1" class="quarto-xref">Figura&nbsp;1</a>.</p>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div id="fig-ejemplo1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ejemplo1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div>
<svg width="672" height="480" viewbox="0.00 0.00 231.62 188.00" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="; max-width: none; max-height: none">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 184)">
<title>G</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-184 227.62,-184 227.62,4 -4,4"></polygon>
<!-- Antigüedad &lt; 4.5? -->
<g id="node1" class="node">
<title>Antigüedad &lt; 4.5?</title>
<ellipse fill="none" stroke="black" cx="87.94" cy="-162" rx="82.95" ry="18"></ellipse>
<text text-anchor="middle" x="87.94" y="-157.8" font-family="Times,serif" font-size="14.00">Antigüedad &lt; 4.5?</text>
</g>
<!-- 5.11 -->
<g id="node2" class="node">
<title>5.11</title>
<ellipse fill="none" stroke="black" cx="27.94" cy="-90" rx="27.87" ry="18"></ellipse>
<text text-anchor="middle" x="27.94" y="-85.8" font-family="Times,serif" font-size="14.00">5.11</text>
</g>
<!-- Antigüedad &lt; 4.5?&#45;&gt;5.11 -->
<g id="edge1" class="edge">
<title>Antigüedad &lt; 4.5?-&gt;5.11</title>
<path fill="none" stroke="black" d="M73.41,-144.05C65.72,-135.08 56.15,-123.92 47.78,-114.15"></path>
<polygon fill="black" stroke="black" points="50.26,-111.67 41.1,-106.36 44.95,-116.23 50.26,-111.67"></polygon>
</g>
<!-- Golpes &lt; 117.5? -->
<g id="node3" class="node">
<title>Golpes &lt; 117.5?</title>
<ellipse fill="none" stroke="black" cx="148.94" cy="-90" rx="74.87" ry="18"></ellipse>
<text text-anchor="middle" x="148.94" y="-85.8" font-family="Times,serif" font-size="14.00">Golpes &lt; 117.5?</text>
</g>
<!-- Antigüedad &lt; 4.5?&#45;&gt;Golpes &lt; 117.5? -->
<g id="edge2" class="edge">
<title>Antigüedad &lt; 4.5?-&gt;Golpes &lt; 117.5?</title>
<path fill="none" stroke="black" d="M102.7,-144.05C110.2,-135.46 119.43,-124.86 127.68,-115.4"></path>
<polygon fill="black" stroke="black" points="130.37,-117.63 134.31,-107.79 125.1,-113.03 130.37,-117.63"></polygon>
</g>
<!-- 6.00 -->
<g id="node4" class="node">
<title>6.00</title>
<ellipse fill="none" stroke="black" cx="111.94" cy="-18" rx="27.87" ry="18"></ellipse>
<text text-anchor="middle" x="111.94" y="-13.8" font-family="Times,serif" font-size="14.00">6.00</text>
</g>
<!-- Golpes &lt; 117.5?&#45;&gt;6.00 -->
<g id="edge3" class="edge">
<title>Golpes &lt; 117.5?-&gt;6.00</title>
<path fill="none" stroke="black" d="M139.98,-72.05C135.6,-63.77 130.23,-53.62 125.37,-44.42"></path>
<polygon fill="black" stroke="black" points="128.32,-42.51 120.56,-35.31 122.13,-45.78 128.32,-42.51"></polygon>
</g>
<!-- 6.74 -->
<g id="node5" class="node">
<title>6.74</title>
<ellipse fill="none" stroke="black" cx="185.94" cy="-18" rx="27.87" ry="18"></ellipse>
<text text-anchor="middle" x="185.94" y="-13.8" font-family="Times,serif" font-size="14.00">6.74</text>
</g>
<!-- Golpes &lt; 117.5?&#45;&gt;6.74 -->
<g id="edge4" class="edge">
<title>Golpes &lt; 117.5?-&gt;6.74</title>
<path fill="none" stroke="black" d="M157.89,-72.05C162.27,-63.77 167.64,-53.62 172.5,-44.42"></path>
<polygon fill="black" stroke="black" points="175.74,-45.78 177.32,-35.31 169.55,-42.51 175.74,-45.78"></polygon>
</g>
</g>
</svg>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ejemplo1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;1: Ejemplo de árbol de decisión para predecir el salario de un jugador de baseball. Tomado del libro.
</figcaption>
</figure>
</div>
</div>
</div>
<p>A cada decisión la llamamos un <strong>nodo</strong>, y a cada punto final lo llamamos una <strong>hoja</strong>.</p>
<div id="386d861c" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeRegressor, _tree</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co"># ==============================</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Generación del conjunto de datos 2D (caso independiente)</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co"># ==============================</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>N2d <span class="op">=</span> <span class="dv">1000</span>  <span class="co"># Número de puntos en 2D</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Generar puntos en 2D distribuidos uniformemente en el cuadrado [-3, 3] x [-3, 3]</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>datos_2d <span class="op">=</span> np.random.uniform(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, size<span class="op">=</span>(N2d, <span class="dv">2</span>))</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcular el radio (distancia al origen) para cada punto</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>radio_2d <span class="op">=</span> np.linalg.norm(datos_2d, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Parámetros para la señal</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>sigma_senal_2d <span class="op">=</span> <span class="fl">0.1</span>   <span class="co"># Controla la agudeza del pico en radio = 2</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Definir la señal como una función gaussiana con pico en radio = 2</span></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>senal_2d <span class="op">=</span> np.exp(<span class="op">-</span>((radio_2d <span class="op">-</span> <span class="dv">2</span>)<span class="op">**</span><span class="dv">2</span>) <span class="op">/</span> (<span class="dv">2</span> <span class="op">*</span> sigma_senal_2d<span class="op">**</span><span class="dv">2</span>))</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Generar ruido gaussiano independiente (ruido blanco)</span></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>sigma_ruido_2d <span class="op">=</span> <span class="fl">0.05</span></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>ruido_2d <span class="op">=</span> np.random.normal(loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span>sigma_ruido_2d, size<span class="op">=</span>N2d)</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Variable objetivo: suma de la señal y el ruido</span></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>objetivo_2d <span class="op">=</span> senal_2d <span class="op">+</span> ruido_2d</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a><span class="co"># ==============================</span></span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Entrenamiento del Árbol de Regresión poco profundo para 2D</span></span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a><span class="co"># ==============================</span></span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Se entrena un árbol de regresión con profundidad máxima de 3</span></span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>arbol_2d <span class="op">=</span> DecisionTreeRegressor(max_depth<span class="op">=</span><span class="dv">3</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>arbol_2d.fit(datos_2d, objetivo_2d)</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a><span class="co"># ==============================</span></span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Función para graficar los cortes del árbol en 2D</span></span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a><span class="co"># ==============================</span></span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> graficar_divisiones_2d(nodo, x_min, x_max, y_min, y_max, arbol):</span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a><span class="co">    Función recursiva para graficar las líneas de división del árbol.</span></span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a><span class="co">    Recibe el índice del nodo y los límites actuales de la región, junto con el árbol entrenado.</span></span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Verificar si el nodo actual no es una hoja</span></span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> arbol.tree_.feature[nodo] <span class="op">!=</span> _tree.TREE_UNDEFINED:</span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Obtener la característica de división y el umbral</span></span>
<span id="cb3-50"><a href="#cb3-50" aria-hidden="true" tabindex="-1"></a>        feature <span class="op">=</span> arbol.tree_.feature[nodo]</span>
<span id="cb3-51"><a href="#cb3-51" aria-hidden="true" tabindex="-1"></a>        umbral <span class="op">=</span> arbol.tree_.threshold[nodo]</span>
<span id="cb3-52"><a href="#cb3-52" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb3-53"><a href="#cb3-53" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> feature <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb3-54"><a href="#cb3-54" aria-hidden="true" tabindex="-1"></a>            <span class="co"># División vertical: se divide la característica 0 (eje X)</span></span>
<span id="cb3-55"><a href="#cb3-55" aria-hidden="true" tabindex="-1"></a>            plt.plot([umbral, umbral], [y_min, y_max],</span>
<span id="cb3-56"><a href="#cb3-56" aria-hidden="true" tabindex="-1"></a>                     color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb3-57"><a href="#cb3-57" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Llamadas recursivas para los subnodos:</span></span>
<span id="cb3-58"><a href="#cb3-58" aria-hidden="true" tabindex="-1"></a>            graficar_divisiones_2d(arbol.tree_.children_left[nodo], x_min, umbral, y_min, y_max, arbol)</span>
<span id="cb3-59"><a href="#cb3-59" aria-hidden="true" tabindex="-1"></a>            graficar_divisiones_2d(arbol.tree_.children_right[nodo], umbral, x_max, y_min, y_max, arbol)</span>
<span id="cb3-60"><a href="#cb3-60" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb3-61"><a href="#cb3-61" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> feature <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb3-62"><a href="#cb3-62" aria-hidden="true" tabindex="-1"></a>            <span class="co"># División horizontal: se divide la característica 1 (eje Y)</span></span>
<span id="cb3-63"><a href="#cb3-63" aria-hidden="true" tabindex="-1"></a>            plt.plot([x_min, x_max], [umbral, umbral],</span>
<span id="cb3-64"><a href="#cb3-64" aria-hidden="true" tabindex="-1"></a>                     color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb3-65"><a href="#cb3-65" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Llamadas recursivas para los subnodos:</span></span>
<span id="cb3-66"><a href="#cb3-66" aria-hidden="true" tabindex="-1"></a>            graficar_divisiones_2d(arbol.tree_.children_left[nodo], x_min, x_max, y_min, umbral, arbol)</span>
<span id="cb3-67"><a href="#cb3-67" aria-hidden="true" tabindex="-1"></a>            graficar_divisiones_2d(arbol.tree_.children_right[nodo], x_min, x_max, umbral, y_max, arbol)</span>
<span id="cb3-68"><a href="#cb3-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-69"><a href="#cb3-69" aria-hidden="true" tabindex="-1"></a><span class="co"># Definir los límites iniciales de la región según los datos 2D</span></span>
<span id="cb3-70"><a href="#cb3-70" aria-hidden="true" tabindex="-1"></a>x_min_2d, x_max_2d <span class="op">=</span> datos_2d[:, <span class="dv">0</span>].<span class="bu">min</span>(), datos_2d[:, <span class="dv">0</span>].<span class="bu">max</span>()</span>
<span id="cb3-71"><a href="#cb3-71" aria-hidden="true" tabindex="-1"></a>y_min_2d, y_max_2d <span class="op">=</span> datos_2d[:, <span class="dv">1</span>].<span class="bu">min</span>(), datos_2d[:, <span class="dv">1</span>].<span class="bu">max</span>()</span>
<span id="cb3-72"><a href="#cb3-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-73"><a href="#cb3-73" aria-hidden="true" tabindex="-1"></a><span class="co"># ==============================</span></span>
<span id="cb3-74"><a href="#cb3-74" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualización de los datos y las divisiones</span></span>
<span id="cb3-75"><a href="#cb3-75" aria-hidden="true" tabindex="-1"></a><span class="co"># ==============================</span></span>
<span id="cb3-76"><a href="#cb3-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-77"><a href="#cb3-77" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">6</span>))</span>
<span id="cb3-78"><a href="#cb3-78" aria-hidden="true" tabindex="-1"></a><span class="co"># Graficar los puntos con un color que depende del valor objetivo</span></span>
<span id="cb3-79"><a href="#cb3-79" aria-hidden="true" tabindex="-1"></a>scatter <span class="op">=</span> plt.scatter(datos_2d[:, <span class="dv">0</span>], datos_2d[:, <span class="dv">1</span>], c<span class="op">=</span>objetivo_2d,</span>
<span id="cb3-80"><a href="#cb3-80" aria-hidden="true" tabindex="-1"></a>                      cmap<span class="op">=</span><span class="st">'viridis'</span>, edgecolor<span class="op">=</span><span class="st">'k'</span>, s<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb3-81"><a href="#cb3-81" aria-hidden="true" tabindex="-1"></a>plt.colorbar(scatter, label<span class="op">=</span><span class="st">"Valor objetivo"</span>)</span>
<span id="cb3-82"><a href="#cb3-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-83"><a href="#cb3-83" aria-hidden="true" tabindex="-1"></a><span class="co"># Graficar los cortes del árbol (divisiones) usando la función recursiva</span></span>
<span id="cb3-84"><a href="#cb3-84" aria-hidden="true" tabindex="-1"></a>graficar_divisiones_2d(<span class="dv">0</span>, x_min_2d, x_max_2d, y_min_2d, y_max_2d, arbol_2d)</span>
<span id="cb3-85"><a href="#cb3-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-86"><a href="#cb3-86" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Característica 1 (X1)"</span>)</span>
<span id="cb3-87"><a href="#cb3-87" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Característica 2 (X2)"</span>)</span>
<span id="cb3-88"><a href="#cb3-88" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Árbol de Regresión (max_depth = 3) y cortes en 2D"</span>)</span>
<span id="cb3-89"><a href="#cb3-89" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="9_arboles_bosques_boosting_files/figure-html/cell-3-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Para calcular el error cometido por el árbol, todo depende de si es un problema de regresión o de clasificación. Para regresión podemos usar simplemente el error cuadrático medio entre la predicción y los datos. El caso de clasificación lo discutimos más abajo.</p>
<div id="8793285b" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeRegressor</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co"># ==============================</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Entrenamiento del Árbol de Regresión</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co"># ==============================</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Crear y entrenar el árbol de regresión.</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="co"># El parámetro min_samples_leaf=4 fuerza al árbol a profundizar hasta que cada hoja</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="co"># contenga al menos 4 puntos.</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>arbol_regresion <span class="op">=</span> DecisionTreeRegressor(min_samples_leaf<span class="op">=</span><span class="dv">4</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>arbol_regresion.fit(datos, objetivo)</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Realizar predicciones en el conjunto de entrenamiento.</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>predicciones <span class="op">=</span> arbol_regresion.predict(datos)</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcular el desempeño del árbol en el conjunto de entrenamiento (coeficiente de determinación R^2).</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> arbol_regresion.score(datos, objetivo) </span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Obtener información sobre el árbol: número de hojas y profundidad máxima</span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>n_hojas <span class="op">=</span> arbol_regresion.get_n_leaves()</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>profundidad <span class="op">=</span> arbol_regresion.get_depth()</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Desempeño del árbol (R^2):"</span>, score)</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Número de hojas:"</span>, n_hojas)</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Profundidad del árbol:"</span>, profundidad)</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> mean_squared_error(objetivo, predicciones)</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Error cuadrático medio (MSE):"</span>, mse)</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a><span class="co"># ==============================</span></span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualización</span></span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a><span class="co"># ==============================</span></span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Para visualizar, aprovechamos que la función subyacente depende del radio.</span></span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Se grafican tanto los datos observados (objetivo con ruido) como las predicciones del árbol.</span></span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">5</span>))</span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>plt.scatter(radio, objetivo, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">'Datos observados (objetivo)'</span>)</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>plt.scatter(radio, predicciones, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">'Predicciones del árbol'</span>, color<span class="op">=</span><span class="st">'green'</span>)</span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Radio (||x||)"</span>)</span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Valor de la variable objetivo"</span>)</span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Predicciones de Árbol de Regresión vs. Radio en 6D"</span>)</span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Desempeño del árbol (R^2): 0.6368963848809426
Número de hojas: 101
Profundidad del árbol: 16
Error cuadrático medio (MSE): 0.03703362614401399</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="9_arboles_bosques_boosting_files/figure-html/cell-4-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Para entrenar un árbol, sería computacionalmente demasiado costoso intentar todas las posibles combinaciones de todos los posibles cortes en todas las variables. Lo que se hace es agregar un nodo a la vez. Se comparan todos los posibles cortes a cada paso y se toma el que reduce más el error.</p>
<p>El número total de nodos es un hiperparámetro. Sin embargo, podemos usar regularización en vez de escogerlo. Es decir, intentamos minimizar <span class="math display">\[
\mathcal{L} = \sum_i (y_i - \hat{y}_i)^2 + \alpha T\,,
\]</span></p>
<p>donde <span class="math inline">\(T\)</span> es el número de hojas en el árbol. El hiperpárametro <span class="math inline">\(\alpha\)</span> corresponde al costo de agregarle más complejidad al árbol. Su valor se puede escoger usando validación cruzada:</p>
<ol type="1">
<li>Crecemos un árbol muy grande. Hasta que cada hoja tenga pocos puntos de datos.</li>
<li>Calculamos la función de pérdida como función de <span class="math inline">\(\alpha\)</span>, cortando hojas para obtener el mejor subárbol para cada valord e <span class="math inline">\(\alpha\)</span>.</li>
<li>Usamos validación cruzada, repitiendo los pasos 1 y 2 en cada pliegue. El menor error nos da el mejor valor de <span class="math inline">\(\alpha\)</span>.</li>
<li>Se escoge el subárbol correspondiente a ese valor de <span class="math inline">\(\alpha\)</span> que se había guardado en el paso 2.</li>
</ol>
<div id="ca444408" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> KFold, cross_val_score</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ==============================</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Validación Cruzada para Árboles de Regresión</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co"># ==============================</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Definir los valores de alpha a probar</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>alphas <span class="op">=</span> [<span class="dv">0</span>, <span class="fl">0.001</span>, <span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="dv">1</span>, <span class="dv">10</span>]</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Crear el objeto KFold para validación cruzada</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>kf <span class="op">=</span> KFold(n_splits<span class="op">=</span><span class="dv">5</span>, shuffle<span class="op">=</span><span class="va">True</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Lista para almacenar los scores de validación cruzada</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>cv_scores <span class="op">=</span> []</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Realizar validación cruzada para cada valor de alpha</span></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> alpha <span class="kw">in</span> alphas:</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Crear y entrenar el árbol con el valor actual de alpha</span></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>    arbol <span class="op">=</span> DecisionTreeRegressor(ccp_alpha<span class="op">=</span>alpha, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>    scores <span class="op">=</span> cross_val_score(arbol, datos, objetivo, cv<span class="op">=</span>kf, scoring<span class="op">=</span><span class="st">'neg_mean_squared_error'</span>)</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>    cv_scores.append(<span class="op">-</span>scores.mean())  <span class="co"># Convertir a MSE positivo</span></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Encontrar el mejor valor de alpha</span></span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>mejor_alpha <span class="op">=</span> alphas[np.argmin(cv_scores)]</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Mejor valor de alpha:"</span>, mejor_alpha)</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Graficar los resultados</span></span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">5</span>))</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>plt.plot(alphas, cv_scores, <span class="st">'o-'</span>)</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>plt.xscale(<span class="st">'log'</span>)</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Alpha'</span>)</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Error Cuadrático Medio (MSE)'</span>)</span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Validación Cruzada para Selección de Alpha'</span>)</span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Entrenar el árbol final con el mejor alpha</span></span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a>arbol_final <span class="op">=</span> DecisionTreeRegressor(ccp_alpha<span class="op">=</span>mejor_alpha, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a>arbol_final.fit(datos, objetivo)</span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluar el árbol final</span></span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a>predicciones_final <span class="op">=</span> arbol_final.predict(datos)</span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a>mse_final <span class="op">=</span> mean_squared_error(objetivo, predicciones_final)</span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"MSE del árbol final:"</span>, mse_final)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Mejor valor de alpha: 0.01</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="9_arboles_bosques_boosting_files/figure-html/cell-5-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>MSE del árbol final: 0.10199189598228345</code></pre>
</div>
</div>
<section id="árboles-de-clasificación" class="level2">
<h2 class="anchored" data-anchor-id="árboles-de-clasificación">Árboles de Clasificación</h2>
<p>Los árboles también se pueden usar para clasificación. En este caso, en lugar de minimizar el error cuadrático medio, se busca minimizar una medida de impureza como la entropía:</p>
<p><span class="math display">\[
H(p) = -\sum_{i=1}^N \sum_{k=1}^K p_{ik} \log_2 p_{ik}
\]</span></p>
<p>donde <span class="math inline">\(p_{ik}\)</span> es la proporción de observaciones de la clase <span class="math inline">\(k\)</span> en el nodo <span class="math inline">\(i\)</span>. La entropía mide la incertidumbre en la clasificación: es máxima cuando todas las clases son igualmente probables y es cero cuando la probabilidad de una clase es 1 y las otras son cero para cada observación. Es decir, es cero cuando cada clase es “pura” en el sentido de que todos los puntos en el nodo pertenecen a la misma clase.</p>
<p>Al dividir un nodo, se busca la característica y el punto de corte que maximicen la reducción en la entropía. Esta reducción se conoce como ganancia de información:</p>
<p><span class="math display">\[
IG = H(p) - \left( \frac{N_{\text{izq}}}{N} H(p_{\text{izq}}) + \frac{N_{\text{der}}}{N} H(p_{\text{der}}) \right)
\]</span></p>
<p>donde <span class="math inline">\(N\)</span> es el número total de observaciones en el nodo, y <span class="math inline">\(N_{\text{izq}}\)</span> y <span class="math inline">\(N_{\text{der}}\)</span> son los números de observaciones en los nodos hijos izquierdo y derecho respectivamente.</p>
</section>
</section>
<section id="métodos-de-ensamble" class="level1">
<h1>Métodos de Ensamble</h1>
<p>Los métodos de ensamble combinan múltiples árboles para mejorar el rendimiento. La idea principal es que cada árbol es débil por sí solo, pero combinados dan un resultado mucho mejor.</p>
<section id="bagging-y-bosques-aleatorios" class="level2">
<h2 class="anchored" data-anchor-id="bagging-y-bosques-aleatorios">Bagging y Bosques Aleatorios</h2>
<p>Los árboles de decisión tienen una alta varianza. Es decir, un árbol de decisión entrenado con un conjunto de datos puede dar resultados muy diferentes si se entrena con otro conjunto de datos. Una forma de reducir la varianza en general es promediar sobre muchas realizaciones entrenadas sobre múltiples conjuntos de datos. Sin embargo, no tenemos múltiples conjuntos de datos. Por esto podemos usar muestreo con reemplazo para obtener múltiples conjuntos de datos. Es decir, procedemos de la siguiente manera:</p>
<ol type="1">
<li>Tomamos un subconjunto aleatorio con reemplazo de los datos de tamaño <span class="math inline">\(N\)</span>.</li>
<li>Entrenamos un árbol de decisión con ese subconjunto.</li>
<li>Repetimos el proceso <span class="math inline">\(B\)</span> veces.</li>
<li>Obtenemos <span class="math inline">\(B\)</span> árboles de decisión.</li>
<li>La predicción final es el promedio de las predicciones de los <span class="math inline">\(B\)</span> árboles.</li>
</ol>
<p>A esto se le llama <strong>bagging</strong> (Bootstrap Aggregating).</p>
<div id="e2cb1491" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> BaggingRegressor</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeRegressor</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Crear el estimador base (árbol de decisión)</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>arbol_base <span class="op">=</span> DecisionTreeRegressor(max_depth<span class="op">=</span><span class="dv">3</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Crear el modelo de bagging</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>bagging <span class="op">=</span> BaggingRegressor(</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    n_estimators<span class="op">=</span><span class="dv">100</span>,  <span class="co"># Número de árboles</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    max_samples<span class="op">=</span><span class="fl">0.8</span>,   <span class="co"># Fracción de datos a usar en cada árbol</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Entrenar el modelo</span></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>bagging.fit(datos, objetivo)</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Realizar predicciones</span></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>predicciones_bagging <span class="op">=</span> bagging.predict(datos)</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluar el rendimiento</span></span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>mse_bagging <span class="op">=</span> mean_squared_error(objetivo, predicciones_bagging)</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"MSE del bagging:"</span>, mse_bagging)</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualizar las predicciones</span></span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">5</span>))</span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>plt.scatter(radio, objetivo, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">'Datos observados'</span>)</span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>plt.scatter(radio, predicciones_bagging, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">'Predicciones del bagging'</span>, color<span class="op">=</span><span class="st">'green'</span>)</span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Radio (||x||)"</span>)</span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Valor de la variable objetivo"</span>)</span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Predicciones de Bagging vs. Radio en 6D"</span>)</span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>MSE del bagging: 0.020796358419776385</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="9_arboles_bosques_boosting_files/figure-html/cell-6-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Aunque esto reduce la varianza, los árboles de decisión tienen todavía una alta correlación entre ellos. Es decir, si un árbol predice que un punto es de una clase, los otros árboles tenderán a predecir lo mismo. Para reducir esta correlación, podemos introducir una fuente adicional de aleatoriedad. La idea es permitir que cada árbol pueda usar un subconjunto de características para hacer las divisiones.</p>
<section id="bosques-aleatorios" class="level3">
<h3 class="anchored" data-anchor-id="bosques-aleatorios">Bosques Aleatorios</h3>
<p>Los bosques aleatorios son una modificación del bagging que introduce una fuente adicional de aleatoriedad. La idea principal es:</p>
<ol type="1">
<li>Entrenar múltiples árboles de decisión</li>
<li>Cada árbol se entrena con un subconjunto aleatorio de los datos (muestreo con reemplazo)</li>
<li>En cada nodo, solo se considera un SUBCONJUNTO ALEATORIO de las características (típicamente <span class="math inline">\(\sqrt{p}\)</span> características en clasificación o <span class="math inline">\(p/3\)</span> en regresión, donde <span class="math inline">\(p\)</span> es el número total de características)</li>
<li>La predicción final es el promedio (regresión) o la mayoría de votos (clasificación) de todos los árboles</li>
</ol>
<p>La diferencia clave con el bagging es la restricción en las características disponibles en cada nodo. Esta restricción reduce la correlación entre los árboles del ensamble, lo que típicamente resulta en un mejor rendimiento que el bagging simple. En bagging, si hay características muy predictivas, todos los árboles tenderán a usar esas mismas características, lo que aumenta la correlación entre ellos. Al restringir aleatoriamente las características disponibles en cada nodo, los bosques aleatorios evitan este problema y producen árboles más diversos y menos correlacionados.</p>
<div id="10663b0b" class="cell" data-execution_count="7">
<details class="code-fold">
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestRegressor</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Crear y entrenar el bosque aleatorio</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>bosque <span class="op">=</span> RandomForestRegressor(n_estimators<span class="op">=</span><span class="dv">100</span>, max_features<span class="op">=</span><span class="st">'sqrt'</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>bosque.fit(datos, objetivo)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Realizar predicciones</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>predicciones_bosque <span class="op">=</span> bosque.predict(datos)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluar el rendimiento</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>mse_bosque <span class="op">=</span> mean_squared_error(objetivo, predicciones_bosque)</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"MSE del bosque aleatorio:"</span>, mse_bosque)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualizar las predicciones</span></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">5</span>))</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>plt.scatter(radio, objetivo, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">'Datos observados'</span>)</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>plt.scatter(radio, predicciones_bosque, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">'Predicciones del bosque'</span>, color<span class="op">=</span><span class="st">'green'</span>)</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Radio (||x||)"</span>)</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Valor de la variable objetivo"</span>)</span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Predicciones de Bosque Aleatorio vs. Radio en 6D"</span>)</span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>MSE del bosque aleatorio: 0.01404837750553461</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="9_arboles_bosques_boosting_files/figure-html/cell-7-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="boosting" class="level2">
<h2 class="anchored" data-anchor-id="boosting">Boosting</h2>
<p>El boosting es otra técnica de ensamblaje que construye modelos secuencialmente, donde cada nuevo modelo intenta corregir los errores del anterior. El algoritmo más popular es Gradient Boosting:</p>
<ol type="1">
<li>Inicializar con una predicción constante (por ejemplo, el promedio de los valores objetivo)</li>
<li>Para cada iteración:
<ul>
<li>Calcular los residuos (diferencia entre predicción actual y valores reales)</li>
<li>Entrenar un nuevo árbol para predecir los residuos</li>
<li>Actualizar las predicciones sumando una fracción de la predicción del nuevo árbol</li>
</ul></li>
<li>La predicción final es la suma de todas las predicciones de los árboles</li>
</ol>
<div id="79fea619" class="cell" data-execution_count="8">
<details class="code-fold">
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> xgboost <span class="im">as</span> xgb</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Crear y entrenar el modelo XGBoost</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>xgb_model <span class="op">=</span> xgb.XGBRegressor(</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>    n_estimators<span class="op">=</span><span class="dv">2000</span>,        </span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    learning_rate<span class="op">=</span><span class="fl">0.005</span>,      </span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    max_depth<span class="op">=</span><span class="dv">6</span>,              </span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>    objective<span class="op">=</span><span class="st">'reg:squarederror'</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>xgb_model.fit(datos, objetivo)</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Realizar predicciones</span></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>predicciones_xgb <span class="op">=</span> xgb_model.predict(datos)</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluar el rendimiento</span></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>mse_xgb <span class="op">=</span> mean_squared_error(objetivo, predicciones_xgb)</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"MSE de boosted trees:"</span>, mse_xgb)</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualizar las predicciones</span></span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">5</span>))</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>plt.scatter(radio, objetivo, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">'Datos observados'</span>)</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>plt.scatter(radio, predicciones_xgb, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">'Predicciones de XGBoost'</span>, color<span class="op">=</span><span class="st">'green'</span>)</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Radio (||x||)"</span>)</span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Valor de la variable objetivo"</span>)</span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Predicciones de XGBoost vs. Radio en 6D"</span>)</span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>MSE de boosted trees: 0.007198678032281405</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="9_arboles_bosques_boosting_files/figure-html/cell-8-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>En este caso yo escogí unos hiperparámetros que dan un error pequeño sobre el conjunto de entrenamiento. En general, esto no es lo que se hace ya que el error sobre el conjunto de entrenamiento no es una buena estimación del error sobre datos nuevos. Lo que se hace es usar validación cruzada para escoger los hiperparámetros.</p>
</section>
</section>
<section id="importancia-de-cada-variable-en-métodos-basados-en-árboles" class="level1">
<h1>Importancia de Cada Variable en Métodos Basados en Árboles</h1>
<p>En los métodos basados en árboles de regresión, la importancia de una característica se mide por su contribución a la reducción del error cuadrático medio. Para un árbol individual, la importancia de la característica <span class="math inline">\(j\)</span> se calcula como:</p>
<p><span class="math display">\[
I_j = \sum_{t=1}^{T-1} \Delta MSE(t) \cdot \mathbb{I}(v(t) = j)
\]</span></p>
<p>donde <span class="math inline">\(T-1\)</span> es el número de nodos internos, <span class="math inline">\(v(t)\)</span> es la característica usada para dividir en el nodo <span class="math inline">\(t\)</span>, y <span class="math inline">\(\Delta MSE(t)\)</span> es la reducción en el error cuadrático medio que resulta de la división. La función indicadora <span class="math inline">\(\mathbb{I}(v(t) = j)\)</span> cuenta cuántas veces se usa la característica <span class="math inline">\(j\)</span> para dividir.</p>
<p>En otras palabras, la importancia de una característica es la reducción en el error cuadrático medio que resulta de usar esa característica para hacer las divisiones.</p>
<p>En el caso de bosques aleatorios y boosting, la importancia de cada característica se <em>promedia</em> sobre todos los árboles. Esto proporciona una medida más robusta, ya que: 1. Reduce la varianza de la estimación 2. Es menos sensible a correlaciones entre características 3. Puede capturar interacciones entre características</p>
<p>Es importante notar que estas medidas de importancia son relativas y no absolutas. Una característica con importancia cero no significa necesariamente que sea irrelevante para la predicción, sino que podría estar correlacionada con otras características más importantes. Además, estas medidas tienden a favorecer características con más valores únicos o rangos más amplios.</p>
<p>En nuestro ejemplo con datos en 6D, donde la función objetivo depende solo del radio, esperaríamos que todas las características tengan una importancia similar, ya que cada una contribuye igualmente al cálculo del radio.</p>
</section>
<section id="comparación-de-métodos" class="level1">
<h1>Comparación de Métodos</h1>
<p>Cada uno de los métodos discutidos tiene sus ventajas y desventajas. Aquí presentamos una comparación detallada:</p>
<section id="árboles-de-decisión-1" class="level2">
<h2 class="anchored" data-anchor-id="árboles-de-decisión-1">Árboles de Decisión</h2>
<ul>
<li><strong>Sobreajuste</strong>: Muy propensos a sobreajuste, especialmente si no se controla la profundidad</li>
<li><strong>Costo computacional</strong>: Muy eficiente en entrenamiento y predicción</li>
<li><strong>Interpretabilidad</strong>: Excelente - se pueden visualizar y entender fácilmente</li>
<li><strong>Hiperparámetros</strong>: Pocos y fáciles de interpretar (profundidad máxima, número mínimo de muestras por hoja)</li>
<li><strong>Rendimiento</strong>: Regresores débiles con alta varianza - predicciones escalonadas y poco suaves</li>
<li><strong>Uso recomendado</strong>: Cuando la interpretabilidad es crucial y el conjunto de datos es pequeño. No recomendado como regresor único en problemas donde se necesita precisión.</li>
</ul>
</section>
<section id="bagging" class="level2">
<h2 class="anchored" data-anchor-id="bagging">Bagging</h2>
<ul>
<li><strong>Sobreajuste</strong>: Menos propenso que árboles individuales, pero puede sobreajustar si los árboles base son muy complejos</li>
<li><strong>Costo computacional</strong>: Lineal con el número de árboles, paralelizable</li>
<li><strong>Interpretabilidad</strong>: Baja - el ensamble es difícil de interpretar</li>
<li><strong>Hiperparámetros</strong>: Número de árboles, tamaño del subconjunto de datos</li>
<li><strong>Uso recomendado</strong>: Cuando se necesita reducir la varianza de árboles individuales</li>
</ul>
</section>
<section id="bosques-aleatorios-1" class="level2">
<h2 class="anchored" data-anchor-id="bosques-aleatorios-1">Bosques Aleatorios</h2>
<ul>
<li><strong>Sobreajuste</strong>: Menos propenso que bagging debido a la aleatorización adicional</li>
<li><strong>Costo computacional</strong>: Similar a bagging, pero ligeramente más costoso por la selección aleatoria de características</li>
<li><strong>Interpretabilidad</strong>: Baja, pero permite medir la importancia de características</li>
<li><strong>Hiperparámetros</strong>: Número de árboles, número de características a considerar en cada división</li>
<li><strong>Uso recomendado</strong>: Problemas generales de regresión y clasificación donde la interpretabilidad no es crucial</li>
</ul>
</section>
<section id="boosting-1" class="level2">
<h2 class="anchored" data-anchor-id="boosting-1">Boosting</h2>
<ul>
<li><strong>Sobreajuste</strong>: Muy propenso si no se controla adecuadamente con regularización</li>
<li><strong>Costo computacional</strong>: Alto, especialmente con muchos árboles y datos grandes</li>
<li><strong>Interpretabilidad</strong>: Baja, pero permite medir la importancia de características</li>
<li><strong>Hiperparámetros</strong>: Múltiples e importantes (tasa de aprendizaje, número de árboles, profundidad, regularización)</li>
<li><strong>Uso recomendado</strong>: Cuando se necesita el mejor rendimiento posible y se tienen recursos computacionales suficientes</li>
</ul>
</section>
</section>
<section id="ejercicios-sugeridos-para-la-prueba" class="level1">
<h1>Ejercicios sugeridos para la prueba</h1>
<p>8.4, 8.5</p>
<ul>
<li>Discuta una situación en la que un árbol de decisión podría ser mejor que un bosque aleatorio.</li>
<li>Discuta por qué el bosque aleatorio es menos propenso al sobreajuste que el árbol de decisión. Tome en cuenta el equilibrio entre sesgo y varianza.</li>
<li>Discuta por qué el bosque aleatorio es menos propenso al sobreajuste que el bagging. Tome en cuenta el equilibrio entre sesgo y varianza.</li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiado");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiado");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/jorgenorena\.github\.io\/machine_learning_course\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>
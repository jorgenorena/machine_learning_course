<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="es" xml:lang="es"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Selección de Modelos y Regularización – Aprendizaje Automático para Físicos</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-e13f217ceb0135cb77e1494052e28e8a.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Sin resultados",
    "search-matching-documents-text": "documentos encontrados",
    "search-copy-link-title": "Copiar el enlace en la búsqueda",
    "search-hide-matches-text": "Ocultar resultados adicionales",
    "search-more-match-text": "resultado adicional en este documento",
    "search-more-matches-text": "resultados adicionales en este documento",
    "search-clear-button-title": "Borrar",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar",
    "search-label": "Buscar"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar docked nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Aprendizaje Automático para Físicos</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Buscar"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Navegación de palanca" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-clases" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Clases</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-clases">    
        <li class="dropdown-header">Probabilidad y Estadística</li>
        <li>
    <a class="dropdown-item" href="./1_probabilidad.html">
 <span class="dropdown-text">1. Probabilidad</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./2_distribuciones_y_estimacion.html">
 <span class="dropdown-text">2. Distribuciones y Estimación</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./3_verosimilitud.html">
 <span class="dropdown-text">3. Verosimilitud</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./4_minimos_cuadrados_intervalos.html">
 <span class="dropdown-text">4. Mínimos Cuadrados e Intervalos</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./5_testeo_de_hipotesis_entropia.html">
 <span class="dropdown-text">5. Testeo de Hipótesis y Entropía</span></a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li class="dropdown-header">Aprendizaje Automático</li>
        <li>
    <a class="dropdown-item" href="./6_aprendizaje_automatico_regresion_lineal.html">
 <span class="dropdown-text">6. Aprendizaje Automático y Regresión Lineal</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./7_clasificacion.html">
 <span class="dropdown-text">7. Clasificación</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./8_seleccion_de_modelos.html">
 <span class="dropdown-text">8. Selección de Modelos</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./9_arboles_bosques_boosting.html">
 <span class="dropdown-text">9. Árboles, Bosques y Boosting</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./10_svm_y_no_supervisado.html">
 <span class="dropdown-text">10. SVM y Aprendizaje No Supervisado</span></a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li class="dropdown-header">Redes Neuronales</li>
        <li>
    <a class="dropdown-item" href="./11_perceptron_y_redes_conexas.html">
 <span class="dropdown-text">11. Perceptrón y Redes Conexas y Pérdidas</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./12_gradient_descent_and_autodiff.html">
 <span class="dropdown-text">12. Descenso de Gradiente y Auto-diferenciación</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./13_evaluacion_y_regularizacion_de_nn.html">
 <span class="dropdown-text">13. Evaluación y Regularización de redes neuronales</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./14_redes_convolucionales.html">
 <span class="dropdown-text">14. Redes Convolucionales</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./15_redes_residuales.html">
 <span class="dropdown-text">15. Redes Residuales</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./16_transformadores.html">
 <span class="dropdown-text">16. Transformadores y el mecanismo de atención</span></a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li class="dropdown-header">Algunas aplicaciones</li>
        <li>
    <a class="dropdown-item" href="./17_flujos_normalizantes.html">
 <span class="dropdown-text">17. Flujos Normalizantes</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./18_PINNs.html">
 <span class="dropdown-text">18. Redes Neuronales Informadas por la Física (PINNs)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./19_Operador_Neural.html">
 <span class="dropdown-text">19. Operadores Neuronales</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="./about.html"> 
<span class="menu-text">Acerca de</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./6_aprendizaje_automatico_regresion_lineal.html">Aprendizaje Automático</a></li><li class="breadcrumb-item"><a href="./8_seleccion_de_modelos.html">8. Selección de Modelos</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Probabilidad y Estadística</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Alternar sección">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1_probabilidad.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1. Probabilidad</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2_distribuciones_y_estimacion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2. Distribuciones y Estimación</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3_verosimilitud.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3. Verosimilitud</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./4_minimos_cuadrados_intervalos.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4. Mínimos Cuadrados e Intervalos</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./5_testeo_de_hipotesis_entropia.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5. Testeo de Hipótesis y Entropía</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Aprendizaje Automático</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Alternar sección">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./6_aprendizaje_automatico_regresion_lineal.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">6. Aprendizaje Automático y Regresión Lineal</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./7_clasificacion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">7. Clasificación</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./8_seleccion_de_modelos.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">8. Selección de Modelos</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./9_arboles_bosques_boosting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">9. Árboles, Bosques y Boosting</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10_svm_y_no_supervisado.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">10. SVM y Aprendizaje No Supervisado</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Redes Neuronales</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Alternar sección">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11_perceptron_y_redes_conexas.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">11. Perceptrón, Redes Conexas y Pérdidas</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12_gradient_descent_and_autodiff.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">12. Descenso de Gradiente y Auto-diferenciación</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13_evaluacion_y_regularizacion_de_nn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">13. Evaluación y Regularización de redes neuronales</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14_redes_convolucionales.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">14. Redes Convolucionales</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./15_redes_residuales.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">15. Redes Residuales</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./16_transformadores.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">16. Transformadores y el mecanismo de atención</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Algunas aplicaciones</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Alternar sección">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./17_flujos_normalizantes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">17. Flujos Normalizantes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./18_PINNs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">18. Redes Neuronales Informadas por la Física (PINNs)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./19_Operador_Neural.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">19. Operadores Neuronales</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">En esta página</h2>
   
  <ul>
  <li><a href="#métodos-de-evaluación-de-modelos" id="toc-métodos-de-evaluación-de-modelos" class="nav-link active" data-scroll-target="#métodos-de-evaluación-de-modelos">Métodos de Evaluación de Modelos</a>
  <ul class="collapse">
  <li><a href="#criterios-de-información-para-penalizar-modelos-complejos" id="toc-criterios-de-información-para-penalizar-modelos-complejos" class="nav-link" data-scroll-target="#criterios-de-información-para-penalizar-modelos-complejos">Criterios de información para penalizar modelos complejos</a>
  <ul class="collapse">
  <li><a href="#criterio-de-información-de-akaike" id="toc-criterio-de-información-de-akaike" class="nav-link" data-scroll-target="#criterio-de-información-de-akaike">Criterio de información de Akaike</a></li>
  <li><a href="#criterio-de-información-de-bayes" id="toc-criterio-de-información-de-bayes" class="nav-link" data-scroll-target="#criterio-de-información-de-bayes">Criterio de información de Bayes</a></li>
  </ul></li>
  <li><a href="#evaluación-de-modelos-usando-subconjuntos-aleatorios" id="toc-evaluación-de-modelos-usando-subconjuntos-aleatorios" class="nav-link" data-scroll-target="#evaluación-de-modelos-usando-subconjuntos-aleatorios">Evaluación de modelos usando subconjuntos aleatorios</a>
  <ul class="collapse">
  <li><a href="#el-conjunto-de-validación" id="toc-el-conjunto-de-validación" class="nav-link" data-scroll-target="#el-conjunto-de-validación">El conjunto de validación</a></li>
  <li><a href="#validación-cruzada" id="toc-validación-cruzada" class="nav-link" data-scroll-target="#validación-cruzada">Validación cruzada</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#métodos-para-explorar-modelos" id="toc-métodos-para-explorar-modelos" class="nav-link" data-scroll-target="#métodos-para-explorar-modelos">Métodos para Explorar Modelos</a>
  <ul class="collapse">
  <li><a href="#búsqueda-hacia-adelante-y-hacia-atrás" id="toc-búsqueda-hacia-adelante-y-hacia-atrás" class="nav-link" data-scroll-target="#búsqueda-hacia-adelante-y-hacia-atrás">Búsqueda hacia adelante y hacia atrás</a></li>
  <li><a href="#búsqueda-aleatoria" id="toc-búsqueda-aleatoria" class="nav-link" data-scroll-target="#búsqueda-aleatoria">Búsqueda aleatoria</a></li>
  <li><a href="#conjunto-de-prueba" id="toc-conjunto-de-prueba" class="nav-link" data-scroll-target="#conjunto-de-prueba">Conjunto de prueba</a></li>
  </ul></li>
  <li><a href="#regularización" id="toc-regularización" class="nav-link" data-scroll-target="#regularización">Regularización</a>
  <ul class="collapse">
  <li><a href="#regresión-con-regularización-l2-ridge-regression" id="toc-regresión-con-regularización-l2-ridge-regression" class="nav-link" data-scroll-target="#regresión-con-regularización-l2-ridge-regression">Regresión con regularización L2 (ridge regression)</a></li>
  <li><a href="#lazo-o-regularización-l1" id="toc-lazo-o-regularización-l1" class="nav-link" data-scroll-target="#lazo-o-regularización-l1">Lazo o regularización L1</a></li>
  </ul></li>
  <li><a href="#ejercicios-recomendados-para-la-prueba" id="toc-ejercicios-recomendados-para-la-prueba" class="nav-link" data-scroll-target="#ejercicios-recomendados-para-la-prueba">Ejercicios Recomendados Para la Prueba</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./6_aprendizaje_automatico_regresion_lineal.html">Aprendizaje Automático</a></li><li class="breadcrumb-item"><a href="./8_seleccion_de_modelos.html">8. Selección de Modelos</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">Selección de Modelos y Regularización</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Ahora discutiremos cómo evaluar un modelo. Vimos que puede haber varias formas de ajustar los datos. Por ejemplo, podemos usar todos los predictores <span class="math inline">\(X_i\)</span> o sólo algunos de ellos que consideramos más relevantes. El problema es que en general mientars más parámetros tenga un modelo, mejor será el ajuste a los datos usados para entrenarlo: Si el modelo tiene más libertad, la usa para ajustarse mejor. Sin embargo cuando tiene demasiada libertad se ajustará también a las fluctuaciones aleatorias en los datos, tal que al tratar de hacer predicciones a partir de datos no vistos cometerá errores (gran varianza). Al error cometido sobre datos no vistos se lo llama <strong>error de generalización</strong>. Un modelo que se ajusta muy bien a los datos usados para entrenarlo, pero que tiene un gran error de generalización se dice que no generaliza bien.</p>
<p>Por otro lado si tiene poca libertad no logrará capturar los patrones en los datos, lo que se llama <strong>poca expresividad</strong> del modelo, y cometerá un error grande al predecir (gran sesgo).</p>
<p>En esta clase veremos cómo hacer para evaluar modelos buscando el equilibrio entre la complejidad del modelo y el error de generalización. En otras palabras el equilibrio entre sesgo y varianza.</p>
<p>Cuando el número de parámetros es grande (dada una cantidad de datos), podemos intenar reducir su varianza. Esto se llama <strong>regularización</strong> que será muy importante cuando estudiemos redes neuronales. Introduciremos por ahora un par de métodos de regularización.</p>
<div id="cell-fig-mse" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Semilla para reproducibilidad</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">0</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Parámetros</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>n_muestras <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>n_total_variables <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>variables_reales <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>]  <span class="co"># Solo las dos primeras variables influyen en la respuesta</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Generar una matriz de covarianza para producir predictores correlacionados.</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>rho <span class="op">=</span> <span class="fl">0.1</span>  <span class="co"># alto grado de correlación entre predictores</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>cov <span class="op">=</span> np.full((n_total_variables, n_total_variables), rho)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>np.fill_diagonal(cov, <span class="fl">1.2</span>)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Generar predictores correlacionados a partir de una distribución normal multivariada.</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.random.multivariate_normal(mean<span class="op">=</span>np.zeros(n_total_variables), cov<span class="op">=</span>cov, size<span class="op">=</span>n_muestras)</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Generar variable dependiente con solo dos predictores reales</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>coeficientes_reales <span class="op">=</span> np.zeros(n_total_variables)</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>coeficientes_reales[variables_reales] <span class="op">=</span> [<span class="fl">3.0</span>, <span class="op">-</span><span class="fl">0.8</span>, <span class="fl">0.5</span>, <span class="fl">1.0</span>]</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> X <span class="op">@</span> coeficientes_reales <span class="op">+</span> np.random.randn(n_muestras) <span class="op">*</span> <span class="fl">0.5</span>  <span class="co"># Agregar ruido</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcular el error cuadrático medio (ECM) al incluir más predictores</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>lista_ecm <span class="op">=</span> []</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> n_vars <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, n_total_variables <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>    modelo <span class="op">=</span> LinearRegression()</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>    modelo.fit(X[:, :n_vars], y)</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> modelo.predict(X[:, :n_vars])</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>    ecm <span class="op">=</span> mean_squared_error(y, y_pred)</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>    lista_ecm.append(ecm)</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Graficar los resultados</span></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">5</span>))</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(<span class="dv">1</span>, n_total_variables <span class="op">+</span> <span class="dv">1</span>), lista_ecm, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>plt.yscale(<span class="st">"log"</span>)</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>plt.axvline(x<span class="op">=</span><span class="bu">len</span>(variables_reales), color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="st">'Complejidad real del modelo'</span>)</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Número de predictores incluidos'</span>)</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Error cuadrático medio (ECM)'</span>)</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'ECM vs. Número de predictores en regresión lineal'</span>)</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-mse" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-mse-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="8_seleccion_de_modelos_files/figure-html/fig-mse-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-mse-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;1: Error cuadrático medio para la regresión lineal cuando la señal real depende solo de dos predictores.
</figcaption>
</figure>
</div>
</div>
</div>
<p>En la <a href="#fig-mse" class="quarto-xref">Figura&nbsp;1</a> graficamos el error cuadrático medio para una regresión lineal <span class="math inline">\(\sum_{i=1}^p \beta_i X_i\)</span> a partir de datos ficticios. Los datos reales fueron producidos por sólo tres predictores. Sin embargo, vemos que al incluir más y más variables el error cuadrático medio sigue decreciendo.</p>
<section id="métodos-de-evaluación-de-modelos" class="level1">
<h1>Métodos de Evaluación de Modelos</h1>
<p>Hay globalmente dos formas de evaluar el error que cometerá el modelo cuando se usa en datos no usados para entrenarlo. Uno consiste en intentar penalizar modelos más complejos basándose en principios estadísticos, y otro consiste en usar los mismos datos para la evaluación.</p>
<section id="criterios-de-información-para-penalizar-modelos-complejos" class="level2">
<h2 class="anchored" data-anchor-id="criterios-de-información-para-penalizar-modelos-complejos">Criterios de información para penalizar modelos complejos</h2>
<p>Existen varios criterios apra evaluar modelos basados en la teoría de probabilidad.</p>
<section id="criterio-de-información-de-akaike" class="level3">
<h3 class="anchored" data-anchor-id="criterio-de-información-de-akaike">Criterio de información de Akaike</h3>
<p>Supongamos que los datos subyacentes tienen una distribución de probabilidad <span class="math inline">\(f(y)\)</span> y nosotros la aproximamos con una verosimilitud <span class="math inline">\(L(y|\theta)\)</span>. Una manera de cuantificar la diferencia entre las dos distribuciones es medir la entropía. Esto se hace mediante la <strong>divergencia de Kullback Liebler</strong> <span class="math display">\[
\begin{multline}
D_{KL}(f || p) = \int dy\,f(y)\log\left(\frac{f(y)}{L(y|\theta)}\right) \\ = \int dy\,f(y)\log f(y) - \int dy\,f(y)\log L(y|\theta) = -\langle L(y|\theta)\rangle + const.\,.
\end{multline}
\]</span> Se puede demostrar que <span class="math inline">\(D_{KL}(f || p) &gt; 0\)</span> y es cero sólo cuando <span class="math inline">\(f = p\)</span>. Además tiene la interpretación de ser igual a la entropía de <span class="math inline">\(f\)</span> más el costo asociado con usar <span class="math inline">\(p(y)\)</span> al analizar los datos.</p>
<p>Ahora bien, supongamos que estimamos los parámetros maximizando la verosimilitud. Sea <span class="math inline">\(\log\hat{L}\)</span> el máximo valor de la verosimilitud. Akaike demostró que este es un estimador sesgado de <span class="math inline">\(\langle \ln L\rangle\)</span>. Tal que un estimador no sesgado de la divergencia de Kullback Liebler (a parte constantes) es <span class="math display">\[
AIC = 2p -2\log\hat{L}\,.
\]</span> Un menor <span class="math inline">\(AIC\)</span> representa un mejor ajuste en el sentido que la distribución de probabilidad es más cercana a la subyacente.</p>
<p>El valor de <span class="math inline">\(AIC\)</span> no es importante, lo importante es la diferencia de valores entre modelos. En general una diferencia de <span class="math inline">\(AIC\)</span> de <span class="math inline">\(2\)</span> o menos indica que los modelos son equivalentes. Una diferencia entre 4 y 7 es una evidencia moderada de que el modelo con el <span class="math inline">\(AIC\)</span> más alto no describe los datos. Una diferencia mayor a <span class="math inline">\(10\)</span> suele indicar una evidencia más fuerte. En general <span class="math inline">\(\exp((AIC_{min} - AIC)/2)\)</span> es proporcional a la probabilidad de que el modelo minimice la pérdida de información.</p>
<div id="cell-fig-aic" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Lista para guardar los valores de AIC</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>lista_aic <span class="op">=</span> []</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Número de muestras</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> n_muestras</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcular AIC para cada modelo con distinto número de predictores</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> n_vars <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, n_total_variables <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    X_sub <span class="op">=</span> X[:, :n_vars]</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    X_con_bias <span class="op">=</span> np.hstack([np.ones((n_muestras, <span class="dv">1</span>)), X_sub])  <span class="co"># Agregar término independiente</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Ajuste por mínimos cuadrados</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>    beta <span class="op">=</span> np.linalg.pinv(X_con_bias.T <span class="op">@</span> X_con_bias) <span class="op">@</span> X_con_bias.T <span class="op">@</span> y</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> X_con_bias <span class="op">@</span> beta</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Log-verosimilitud bajo supuestos normales con varianza constante</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>    residuo <span class="op">=</span> y <span class="op">-</span> y_pred</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>    sigma2 <span class="op">=</span> np.mean(residuo<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>    log_verosimilitud <span class="op">=</span> <span class="op">-</span>n <span class="op">/</span> <span class="dv">2</span> <span class="op">*</span> (np.log(<span class="dv">2</span> <span class="op">*</span> np.pi <span class="op">*</span> sigma2) <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Número de parámetros (incluye término independiente)</span></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>    k <span class="op">=</span> n_vars <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># AIC</span></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>    aic <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> k <span class="op">-</span> <span class="dv">2</span> <span class="op">*</span> log_verosimilitud</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>    lista_aic.append(aic)</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Graficar AIC</span></span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">5</span>))</span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(<span class="dv">1</span>, n_total_variables <span class="op">+</span> <span class="dv">1</span>), lista_aic, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>plt.axvline(x<span class="op">=</span><span class="dv">4</span>, color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="st">'Complejidad real del modelo'</span>)</span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Número de predictores incluidos'</span>)</span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Criterio de Información de Akaike (AIC)'</span>)</span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'AIC vs. Número de predictores en regresión lineal'</span>)</span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-aic" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-aic-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="8_seleccion_de_modelos_files/figure-html/fig-aic-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-aic-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;2: AIC para datos sintéticos generados a partir de tres predictores.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Si aplicamos este criterio a nuestro modelo de juquete, vemos que la cantidad <span class="math inline">\(AIC\)</span> tiene un mínimo justo en <span class="math inline">\(3\)</span> predictores.</p>
</section>
<section id="criterio-de-información-de-bayes" class="level3">
<h3 class="anchored" data-anchor-id="criterio-de-información-de-bayes">Criterio de información de Bayes</h3>
<p>En la visión bayesiana podemos asignarle una probabilidad a cada modelo dados los datos. En esa óptica podemos escoger el modelo más probable. Aplicando el teorema de Bayes tenemos <span class="math display">\[
\frac{P(M_1|D)}{P(M_2|D)} = \frac{P(D|M_1)}{P(D|M_2)}\frac{P(M_1)}{P(M_2)} \equiv \frac{E_1}{E_2} \frac{P(M_1)}{P(M_2)}\,.
\]</span> La probabilidad previa <span class="math inline">\(P(M)\)</span> está dada por información anterior al momento en que realizamos el experimento. En muchos casos no tenemos una preferencia por un modelo específico tal que <span class="math inline">\(P(M_2)/P(M_1) = 1\)</span>. La <strong>evidencia bayesiana</strong> <span class="math inline">\(E \equiv P(D|M)\)</span> es la probabilidad de los datos dado el modelo <em>integrada sobre los parámetros del modelo</em> <span class="math display">\[
P(D|M) = \int d^p\beta\,P(D|M, \boldsymbol{\beta}) = \int d^p\beta\,L(\boldsymbol{\beta})\,.
\]</span> Existen códigos que pueden calcular la integral de la verosimilitud sobre todos los posibles valores de los parámetros.</p>
<p>Esto suele ser algo costoso computacionalmente, tal que en muchos casos (sobre todo por fuera de la física) se usa una expresión aproximada válida para un número grande de mediciones i.i.d., escogiendo el modelo que minimiza el <strong>criterio de información de Bayes</strong> <span class="math display">\[
BIC = -2\ln\hat{L} + p\ln n\,.
\]</span> Comparado con el AIC, el BIC penaliza más fuertemente los modelos con más parámetros.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Demostración
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Primero asumimos que las mediciones son i.i.d., tal que <span class="math inline">\(L = \prod_i p(x_i)\)</span> y entonces <span class="math inline">\(\ln L = \sum_i \ln p(x_i)\)</span>. Para <span class="math inline">\(n\)</span> grande podemos aproximar <span class="math inline">\(\sum_i \ln p(x_i) \approx n \langle\ln p\rangle \equiv n f(\boldsymbol{\beta})\)</span>.</p>
<p>Usando eso, aproximamos la integral cerca del máximo. Esta aproximación es buena para <span class="math inline">\(n\)</span> grande <span class="math display">\[
\begin{multline}
P(D|M) \approx \int d^p\beta\,e^{\ln L(\boldsymbol{\beta})} \approx \int d^p\beta\,e^{n\ln f(\boldsymbol{\beta})} \\ \approx \int d^p\beta\,e^{n\ln f(\hat{\boldsymbol{\beta}}) + n\frac{\partial \ln f(\hat{\boldsymbol{\beta}})}{\partial \beta^i \partial \beta^j} (\boldsymbol{\beta}^i - \hat{\boldsymbol{\beta}}^i)(\boldsymbol{\beta}^j - \hat{\boldsymbol{\beta}}^j)} = e^{n\ln f(\hat{\boldsymbol{\beta}})}\left(\frac{|\partial^2 \ln f /\partial\beta^2|^{-1/2}}{n^{p/2}(2\pi)^{p/2}}\right)\,.
\end{multline}
\]</span> Tomando el logaritmo obtenemos <span class="math display">\[
\ln P(D|M) \approx \ln\hat{L} - \frac{k}{2}\ln n + const.
\]</span> de donde se obtiene el BIC.</p>
</div>
</div>
</div>
<div id="cell-fig-bic" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Lista para guardar los valores de AIC</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>lista_aic <span class="op">=</span> []</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Número de muestras</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> n_muestras</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcular AIC para cada modelo con distinto número de predictores</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> n_vars <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, n_total_variables <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    X_sub <span class="op">=</span> X[:, :n_vars]</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    X_con_bias <span class="op">=</span> np.hstack([np.ones((n_muestras, <span class="dv">1</span>)), X_sub])  <span class="co"># Agregar término independiente</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Ajuste por mínimos cuadrados</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    beta <span class="op">=</span> np.linalg.pinv(X_con_bias.T <span class="op">@</span> X_con_bias) <span class="op">@</span> X_con_bias.T <span class="op">@</span> y</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> X_con_bias <span class="op">@</span> beta</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Log-verosimilitud bajo supuestos normales con varianza constante</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>    residuo <span class="op">=</span> y <span class="op">-</span> y_pred</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>    sigma2 <span class="op">=</span> np.mean(residuo<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>    log_verosimilitud <span class="op">=</span> <span class="op">-</span>n <span class="op">/</span> <span class="dv">2</span> <span class="op">*</span> (np.log(<span class="dv">2</span> <span class="op">*</span> np.pi <span class="op">*</span> sigma2) <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Número de parámetros (incluye término independiente)</span></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>    k <span class="op">=</span> n_vars <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># BIC</span></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>    bic <span class="op">=</span> k<span class="op">*</span>np.log(n) <span class="op">-</span> <span class="dv">2</span> <span class="op">*</span> log_verosimilitud</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>    lista_aic.append(bic)</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Graficar AIC</span></span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">5</span>))</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(<span class="dv">1</span>, n_total_variables <span class="op">+</span> <span class="dv">1</span>), lista_aic, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>plt.axvline(x<span class="op">=</span><span class="dv">4</span>, color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="st">'Complejidad real del modelo'</span>)</span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Número de predictores incluidos'</span>)</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Criterio de Información de Bayes (BIC)'</span>)</span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'BIC vs. Número de predictores en regresión lineal'</span>)</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-bic" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-bic-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="8_seleccion_de_modelos_files/figure-html/fig-bic-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-bic-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;3: BIC para datos sintéticos generados a partir de tres predictores.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="evaluación-de-modelos-usando-subconjuntos-aleatorios" class="level2">
<h2 class="anchored" data-anchor-id="evaluación-de-modelos-usando-subconjuntos-aleatorios">Evaluación de modelos usando subconjuntos aleatorios</h2>
<p>En algunos casos no es fácil escribir una verosimilitud y entonces no podemos usar los criterios de la sección anterior. Esto ocurre con mucha frecuencia cuando se trabaja con modelos de redes neuronales.</p>
<p>Cuando es así, la práctica común es estimar la precisión del modelo sobre datos no vistos usando un subconjunto de los datos mismos.</p>
<section id="el-conjunto-de-validación" class="level3">
<h3 class="anchored" data-anchor-id="el-conjunto-de-validación">El conjunto de validación</h3>
<p>Una manera de lograrlo es separar una fracción de los datos para que sea un <strong>conjunto de validación</strong>. Los datos que no son parte de este forman el <strong>conjunto de entrenamiento</strong>. El modelo se ajusta o entrena con el conjunto de entrenamiento y el de validación se usa solo para evaluar su desempeño. Como el modelo no vio el conjunto de validación, el error cometido sobre él será una aproximación al error que cometerá cuando vea datos nuevos. Como sabemos los <span class="math inline">\(Y\)</span> del conjunto de validación, podemos calcular dicho error.</p>
<p>Es decir, procedemos en tres pasos:</p>
<ol type="1">
<li>Separar los datos en un conjunto de entrenamiento y un conjunto de validación. Con frecuencia se usa el 10% o 20% de los datos para el conjunto de validación.</li>
<li>Entrenar el modelo en el conjunto de entrenamiento.</li>
<li>Evaluar el modelo en el conjunto de validación.</li>
</ol>
<p>En general, la estima del error de generalización obtenida de esta manera tendrá un sesgo porque usamos sólo un subconjunto de datos para entrenar el modelo. Un modelo entrenado en más datos funcionará mejor con un error menor generalización. En este sentido es una estima pesimista. Además tendrá una varianza ya que el subconjunto de validación es aleatorio.</p>
<div id="cell-fig-val" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> val_error(X, y, random_state):</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Separar en conjunto de entrenamiento (80%) y validación (20%)</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>  X_entrenamiento, X_validacion, y_entrenamiento, y_validacion <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span>random_state)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Lista para almacenar errores de validación</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>  lista_ecm_validacion <span class="op">=</span> []</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Probar diferentes cantidades de predictores</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> n_vars <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, n_total_variables <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Seleccionar subconjunto de variables</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>      X_ent_sub <span class="op">=</span> X_entrenamiento[:, :n_vars]</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>      X_val_sub <span class="op">=</span> X_validacion[:, :n_vars]</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Agregar término independiente (bias)</span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>      X_ent_bias <span class="op">=</span> np.hstack([np.ones((X_ent_sub.shape[<span class="dv">0</span>], <span class="dv">1</span>)), X_ent_sub])</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>      X_val_bias <span class="op">=</span> np.hstack([np.ones((X_val_sub.shape[<span class="dv">0</span>], <span class="dv">1</span>)), X_val_sub])</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Ajustar modelo por mínimos cuadrados</span></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>      beta <span class="op">=</span> np.linalg.pinv(X_ent_bias.T <span class="op">@</span> X_ent_bias) <span class="op">@</span> X_ent_bias.T <span class="op">@</span> y_entrenamiento</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Predecir en conjunto de validación</span></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>      y_val_predicho <span class="op">=</span> X_val_bias <span class="op">@</span> beta</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Calcular error cuadrático medio en validación</span></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>      ecm_val <span class="op">=</span> np.mean((y_validacion <span class="op">-</span> y_val_predicho) <span class="op">**</span> <span class="dv">2</span>)</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>      lista_ecm_validacion.append(ecm_val)</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> lista_ecm_validacion</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>lista_ecm_validacion_1 <span class="op">=</span> val_error(X, y, <span class="dv">42</span>)</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>lista_ecm_validacion_2 <span class="op">=</span> val_error(X, y, <span class="dv">10</span>)</span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Graficar error de validación frente al número de predictores</span></span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">5</span>))</span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(<span class="dv">1</span>, n_total_variables <span class="op">+</span> <span class="dv">1</span>), lista_ecm_validacion_1, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(<span class="dv">1</span>, n_total_variables <span class="op">+</span> <span class="dv">1</span>), lista_ecm_validacion_2, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a>plt.axvline(x<span class="op">=</span><span class="dv">4</span>, color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="st">'Complejidad real del modelo'</span>)</span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Número de predictores incluidos'</span>)</span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Error cuadrático medio (ECM) en validación'</span>)</span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a>plt.yscale(<span class="st">"log"</span>)</span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'ECM de validación vs. número de predictores'</span>)</span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb4-49"><a href="#cb4-49" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-val" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-val-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="8_seleccion_de_modelos_files/figure-html/fig-val-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-val-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;4: Error con varios conjuntos de validación.
</figcaption>
</figure>
</div>
</div>
</div>
<p>En la <a href="#fig-val" class="quarto-xref">Figura&nbsp;4</a> graficamos el error de validación estimado con usando dos particiones distintas de los datos entre validación y entrenamiento. Vemos que la estimación del error de generalización tiene varianza (varía dependiendo de cuál es el conjunto de validación).</p>
</section>
<section id="validación-cruzada" class="level3">
<h3 class="anchored" data-anchor-id="validación-cruzada">Validación cruzada</h3>
<p>Si queremos reducir el sesgo y la varianza, podemos tomar el promedio de muchas validaciones diferentes. La manera de hacerlo es:</p>
<ol type="1">
<li>Dividir el conjunto de datos en <span class="math inline">\(k\)</span> partes.</li>
<li>Usar una parte como conjunto de validación.</li>
<li>Usar <span class="math inline">\(k - 1\)</span> partes para entrenar el modelo. Validar con la parte restante.</li>
<li>Repetir <span class="math inline">\(k\)</span> veces hasta usar todas las partes como validación.</li>
</ol>
<p>Esto nos permite promediar sobre los <span class="math inline">\(k\)</span> valores obtenidos para el error, esperando tener una varianza menor. A mayor <span class="math inline">\(k\)</span>, mayor será el conjunto de datos usado para entrenar y por lo tanto más cercano al modelo completo. Pero al aumentar <span class="math inline">\(k\)</span> los valores obtenidos para la estima del error estarán más correlacionados ya que los diferentes conjuntos usados para entrenar se parecerán más, lo que aumenta la varianza. En la práctica se usa <span class="math inline">\(k\)</span> entre <span class="math inline">\(3\)</span> y <span class="math inline">\(10\)</span>.</p>
<div id="cell-fig-cv" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Reimportar bibliotecas necesarias tras el reinicio</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> KFold</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Lista de valores de K para validación cruzada</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>valores_k <span class="op">=</span> [<span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">10</span>]</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Diccionario para almacenar los resultados</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>resultados_cv <span class="op">=</span> {}</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Realizar validación cruzada para cada valor de K</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> valores_k:</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>    kf <span class="op">=</span> KFold(n_splits<span class="op">=</span>k, shuffle<span class="op">=</span><span class="va">True</span>, random_state<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>    ecm_promedios <span class="op">=</span> []</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> n_vars <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, n_total_variables <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>        errores_fold <span class="op">=</span> []</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> train_index, val_index <span class="kw">in</span> kf.split(X):</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>            X_entrenamiento, X_validacion <span class="op">=</span> X[train_index, :n_vars], X[val_index, :n_vars]</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>            y_entrenamiento, y_validacion <span class="op">=</span> y[train_index], y[val_index]</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Agregar término independiente (bias)</span></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>            X_ent_bias <span class="op">=</span> np.hstack([np.ones((X_entrenamiento.shape[<span class="dv">0</span>], <span class="dv">1</span>)), X_entrenamiento])</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>            X_val_bias <span class="op">=</span> np.hstack([np.ones((X_validacion.shape[<span class="dv">0</span>], <span class="dv">1</span>)), X_validacion])</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Ajustar modelo</span></span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>            beta <span class="op">=</span> np.linalg.pinv(X_ent_bias.T <span class="op">@</span> X_ent_bias) <span class="op">@</span> X_ent_bias.T <span class="op">@</span> y_entrenamiento</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>            y_val_pred <span class="op">=</span> X_val_bias <span class="op">@</span> beta</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Calcular error cuadrático medio</span></span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>            ecm <span class="op">=</span> np.mean((y_validacion <span class="op">-</span> y_val_pred) <span class="op">**</span> <span class="dv">2</span>)</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>            errores_fold.append(ecm)</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>        ecm_promedios.append(np.mean(errores_fold))</span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>    resultados_cv[k] <span class="op">=</span> ecm_promedios</span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Graficar los resultados</span></span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">5</span>))</span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> valores_k:</span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a>    plt.plot(<span class="bu">range</span>(<span class="dv">1</span>, n_total_variables <span class="op">+</span> <span class="dv">1</span>), resultados_cv[k], marker<span class="op">=</span><span class="st">'o'</span>, label<span class="op">=</span><span class="ss">f'</span><span class="sc">{</span>k<span class="sc">}</span><span class="ss"> pliegues'</span>)</span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a>plt.axvline(x<span class="op">=</span><span class="dv">4</span>, color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="st">'Complejidad real del modelo'</span>)</span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Número de predictores incluidos'</span>)</span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'ECM promedio de validación cruzada'</span>)</span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'ECM de validación cruzada vs. número de predictores'</span>)</span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-cv" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cv-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="8_seleccion_de_modelos_files/figure-html/fig-cv-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cv-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;5: Error con validación cruzada para varios valores de <span class="math inline">\(k\)</span>.
</figcaption>
</figure>
</div>
</div>
</div>
<p>En la práctica se puede usar validación cruzada cuando el modelo es pequeño y barato de entrenar (tarda algunos minutos). Pero si el modelo es costoso de entrenar usualmente se usa un solo conjunto de validación.</p>
</section>
</section>
</section>
<section id="métodos-para-explorar-modelos" class="level1">
<h1>Métodos para Explorar Modelos</h1>
<p>Ya tenemos varias herramientas para evaluar el desempeño de los modelos. Esto nos puede servir para comparar varios modelos y escoger el mejor.</p>
<p>Consideremos el ejemplo del ajuste lineal con <span class="math inline">\(20\)</span> variables. Para escoger cuales variables predicen mejor el resultado podríamos evaluar todas las combinaciones posibles. Esto es muy costoso porque hay <span class="math inline">\(2^20 \approx 1\times 10^6\)</span> modelos. Ahora discutiremos algunas estrategias:</p>
<section id="búsqueda-hacia-adelante-y-hacia-atrás" class="level2">
<h2 class="anchored" data-anchor-id="búsqueda-hacia-adelante-y-hacia-atrás">Búsqueda hacia adelante y hacia atrás</h2>
<p>La búsqueda hacia adelante consiste en lo siguiente:</p>
<ol type="1">
<li>A partir de un modelo con <span class="math inline">\(\ell\)</span> variables, llamado <span class="math inline">\(\mathcal{M}_\ell\)</span>, le agregamos una de las <span class="math inline">\(q - \ell\)</span> variables faltantes.</li>
<li>Repetimos para cada una de las variables faltantes y escogemos el mejor de estos <span class="math inline">\(q - \ell\)</span> modelos en el sentido que sea el que obtiene el <span class="math inline">\(R^2\)</span> o más alto. Lo llamamos <span class="math inline">\(\mathcal{M}_{\ell + 1}\)</span>.</li>
<li>Repetimos 1 y 2 a partir de <span class="math inline">\(\mathcal{M}_{\ell + 1}\)</span> para obtener <span class="math inline">\(\mathcal{M}_{\ell + 2}\)</span>.</li>
<li>Para comparar los modelos <span class="math inline">\(\mathcal{M}_1, ..., \mathcal{M}_q\)</span> usamos validación cruzada, AIC o BIC.</li>
</ol>
<p>La búsqueda hacia atrás es similar pero empezamos por un modelo con todas las variables.</p>
<ol type="1">
<li>A partir de un modelo con <span class="math inline">\(\ell\)</span> variables, llamado <span class="math inline">\(\mathcal{M}_\ell\)</span>, quitamos una de esas variables.</li>
<li>Repetimos para cada una de las <span class="math inline">\(\ell\)</span> variables y escogemos el mejor de estos <span class="math inline">\(\ell\)</span> modelos en el sentido que sea el que obtiene el <span class="math inline">\(R^2\)</span> o más alto. Lo llamamos <span class="math inline">\(\mathcal{M}_{\ell - 1}\)</span>.</li>
<li>Repetimos 1 y 2 a partir de <span class="math inline">\(\mathcal{M}_{\ell - 1}\)</span> para obtener <span class="math inline">\(\mathcal{M}_{\ell - 2}\)</span>.</li>
<li>Para comparar los modelos <span class="math inline">\(\mathcal{M}_1, ..., \mathcal{M}_q\)</span> usamos validación cruzada, AIC o BIC.</li>
</ol>
</section>
<section id="búsqueda-aleatoria" class="level2">
<h2 class="anchored" data-anchor-id="búsqueda-aleatoria">Búsqueda aleatoria</h2>
<p>Cuando el número de modelos es grande, y cuando no hay claridad sobre los hiperparámetros a usar, uno puede explorar modelos de forma aleatoria. La idea es que habrán muchos modelos parecidos entre ellos, tal que la búsqueda aleatoria puede encontrar varias zonas en el espacio de hiperparámetros y escoger la mejor.</p>
<p>Estos métodos de búsqueda son aún muy costosos cuando el número de hiperparámetros es grande. Por eso se han desarrollado métodos más sofisticados como uno inspirado en métodos bayesianos para explorar el espacio de hiperparámetros de forma más eficiente.</p>
</section>
<section id="conjunto-de-prueba" class="level2">
<h2 class="anchored" data-anchor-id="conjunto-de-prueba">Conjunto de prueba</h2>
<p>Cuando se busca un modelo entre muchos, el modelo se puede ajustar al conjunto de validación. Es como si uno hiciera un entrenamiento adicional a mano. Por lo tanto, el error de validación o validación cruzada puede ser mucho menor que el error de generalización.</p>
<p>Para atacar este problema lo usual en aprendizaje automático es separar una fracción de los datos <em>antes de empezar cualquier análisis</em>, escogidos aleatoriamente para testear el modelo <em>al final del análisis</em>. Es decir, uno separa el <span class="math inline">\(10-20\%\)</span> de los datos en un <strong>conjunto de prueba</strong> y se usa sólo al final para evaluar el mejor modelo obtenido. De esta manera tendremos una idea de cómo se comportará ese modelo con datos no vistos nunca durante el entrenamiento ni la selección de modelos.</p>
</section>
</section>
<section id="regularización" class="level1">
<h1>Regularización</h1>
<p>Finalmente, en vez de escoger el modelo como mostramos arriba, podemos quedarnos con un modelo grande de muchos parámetros y variables e intentar reducir el impacto de las que no sean importantes. Siendo laxos, decimos que hacemos que el modelo aprenda cuáles variables son relevantes. Veremos dos métodos que nos permiten lograrlo con regresión lineal. También se pueden aplicar a la regresión logística que no es otra cosa que la regresión lineal para el logit.</p>
<p>Esto nos da un ejemplo de cómo podemos modificar la función de costo para guiar el aprendizaje. El método de regresión lineal minimiza la suma de diferencias al cuadrado, que llamamos nuestra función de costo en ese caso <span class="math display">\[
\mathcal{L} = \sum_{i = 1}^n(y_i - \hat{y}_i)^2 = \sum_{i=1}^n\left[y_i - \beta_0 - \sum_{j = 1}^q \beta_j x_{ij}\right]^2\,.
\]</span> Los métodos que veremos le agregan un término a esta función de costo para guiar el aprendizaje. La idea es que al modelo le “cueste” más ir en una dirección que no nos gusta.</p>
<section id="regresión-con-regularización-l2-ridge-regression" class="level3">
<h3 class="anchored" data-anchor-id="regresión-con-regularización-l2-ridge-regression">Regresión con regularización L2 (ridge regression)</h3>
<p>Lo primero que podemos intentar es hacer que el modelo pague por coeficientes grandes. De esa manera se atreverá a hacer apreciables sólo los <span class="math inline">\(\beta_i\)</span> que corresponden a variables verdaderamente importantes. Lo que hacemos es agregarle un término a la función de coste <span class="math display">\[
\mathcal{L} = \sum_{i=1}^n\left[y_i - \beta_0 - \sum_{j=1}^q\beta_j x_j\right]^2 + \alpha\sum_{j=0}^q\beta_j^2\,.
\]</span> Aquí <span class="math inline">\(\alpha\)</span> es un hiperparámetro que controla cuánto paga el modelo por encender coeficientes. Para <span class="math inline">\(\alpha\)</span> que tiende a infinito todos los coeficientes tenderán cero, para <span class="math inline">\(\alpha\)</span> cero regresamos al ajuste lineal de antes. Tomamos los cuadrados porque nos interesa que los coeficientes poco importantes sean cercanos a cero.</p>
<p>Para escoger <span class="math inline">\(\alpha\)</span> podemos usar validación cruzada.</p>
<div id="cell-fig-ridge" class="cell" data-execution_count="7">
<details class="code-fold">
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> KFold</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> Ridge</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Escalar los datos para que la regularización sea comparable entre variables</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>escalador <span class="op">=</span> StandardScaler()</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>X_escalado <span class="op">=</span> escalador.fit_transform(X)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Crear validación cruzada con 5 pliegues</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>kf <span class="op">=</span> KFold(n_splits<span class="op">=</span><span class="dv">5</span>, shuffle<span class="op">=</span><span class="va">True</span>, random_state<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Lista para guardar errores promedio de validación cruzada</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>lista_ecm_cv <span class="op">=</span> []</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Valores de alpha </span></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>valores_alpha_lineal <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dv">20</span>)</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcular ECM de validación cruzada para cada valor de alpha</span></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> alpha <span class="kw">in</span> valores_alpha_lineal:</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>    errores_fold <span class="op">=</span> []</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> train_index, val_index <span class="kw">in</span> kf.split(X_escalado):</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>        X_ent, X_val <span class="op">=</span> X_escalado[train_index], X_escalado[val_index]</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>        y_ent, y_val <span class="op">=</span> y[train_index], y[val_index]</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>        modelo_ridge <span class="op">=</span> Ridge(alpha<span class="op">=</span>alpha, fit_intercept<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>        modelo_ridge.fit(X_ent, y_ent)</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>        y_val_pred <span class="op">=</span> modelo_ridge.predict(X_val)</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>        ecm_val <span class="op">=</span> mean_squared_error(y_val, y_val_pred)</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>        errores_fold.append(ecm_val)</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a>    lista_ecm_cv.append(np.mean(errores_fold))</span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Graficar ECM de validación cruzada frente a alpha</span></span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">5</span>))</span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a>plt.plot(valores_alpha_lineal, lista_ecm_cv, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Valor de α (regularización Ridge)'</span>)</span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'ECM promedio de validación cruzada'</span>)</span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'ECM de validación cruzada (5 pliegues) vs. α en regresión Ridge'</span>)</span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-ridge" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ridge-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="8_seleccion_de_modelos_files/figure-html/fig-ridge-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ridge-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;6: Error de validación cruzada con <span class="math inline">\(k = 5\)</span> pliegues para regularización L2
</figcaption>
</figure>
</div>
</div>
</div>
<p>En la <a href="#fig-ridge" class="quarto-xref">Figura&nbsp;6</a> vemos que el error decrece inicialmente al aumentar <span class="math inline">\(\alpha\)</span> ya que los coeficientes de las variables poco importantes son suprimidos. Luego alcanza un valor mínimo a partir del cual vuelve a crecer porque el modelo pierde expresividad.</p>
<div id="cell-fig-ridge-coeffs" class="cell" data-execution_count="8">
<details class="code-fold">
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Nuevos valores de alpha en escala logarítmica, extendidos hasta valores grandes</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>valores_alpha_log <span class="op">=</span> np.logspace(<span class="op">-</span><span class="dv">4</span>, <span class="dv">3</span>, <span class="dv">100</span>)  <span class="co"># de 1e-4 a 1e3</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Guardar coeficientes para cada valor de alpha</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>coeficientes_ridge_log <span class="op">=</span> []</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> alpha <span class="kw">in</span> valores_alpha_log:</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    modelo <span class="op">=</span> Ridge(alpha<span class="op">=</span>alpha)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    modelo.fit(X_escalado, y)</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    coeficientes_ridge_log.append(modelo.coef_)</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>coeficientes_ridge_log <span class="op">=</span> np.array(coeficientes_ridge_log)</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Graficar los coeficientes en función de alpha (escala log en x)</span></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">5</span>))</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_total_variables):</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> i <span class="kw">in</span> variables_reales:</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>        plt.plot(valores_alpha_log, coeficientes_ridge_log[:, i], linewidth<span class="op">=</span><span class="fl">2.5</span>, label<span class="op">=</span><span class="ss">f'X</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span>, alpha<span class="op">=</span><span class="fl">0.9</span>)</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>        plt.plot(valores_alpha_log, coeficientes_ridge_log[:, i], color<span class="op">=</span><span class="st">'lightgray'</span>, linewidth<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>plt.xscale(<span class="st">'log'</span>)</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Valor de α (regularización Ridge, escala logarítmica)'</span>)</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Coeficientes del modelo'</span>)</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Evolución de los coeficientes de regresión Ridge según α (escala logarítmica)'</span>)</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>plt.legend(title<span class="op">=</span><span class="st">'Variables relevantes'</span>)</span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, which<span class="op">=</span><span class="st">'both'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-ridge-coeffs" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ridge-coeffs-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="8_seleccion_de_modelos_files/figure-html/fig-ridge-coeffs-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ridge-coeffs-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;7: Coeficientes en función de <span class="math inline">\(\alpha\)</span> para regularización L2
</figcaption>
</figure>
</div>
</div>
</div>
<p>En la <a href="#fig-ridge-coeffs" class="quarto-xref">Figura&nbsp;7</a> vemos cómo se comportan los coeficientes a medida que cambia <span class="math inline">\(\alpha\)</span>.</p>
</section>
<section id="lazo-o-regularización-l1" class="level2">
<h2 class="anchored" data-anchor-id="lazo-o-regularización-l1">Lazo o regularización L1</h2>
<p>Una alternativa es usar la suma de valores absolutos <span class="math display">\[
\mathcal{L} = \sum_{i=1}^n\left[y_i - \beta_0 - \sum_{j=1}^q\beta_j x_j\right]^2 + \alpha\sum_{j=0}^q|\beta_j|\,.
\]</span></p>
<div id="cell-fig-lasso" class="cell" data-execution_count="9">
<details class="code-fold">
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> Lasso</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Escalar los datos para que la regularización sea comparable entre variables</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>escalador <span class="op">=</span> StandardScaler()</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>X_escalado <span class="op">=</span> escalador.fit_transform(X)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Crear validación cruzada con 5 pliegues</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>kf <span class="op">=</span> KFold(n_splits<span class="op">=</span><span class="dv">5</span>, shuffle<span class="op">=</span><span class="va">True</span>, random_state<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Lista para guardar errores promedio de validación cruzada</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>lista_ecm_cv <span class="op">=</span> []</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Valores de alpha </span></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>valores_alpha_lineal <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="fl">0.5</span>, <span class="dv">40</span>)</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcular ECM de validación cruzada para cada valor de alpha</span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> alpha <span class="kw">in</span> valores_alpha_lineal:</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>    errores_fold <span class="op">=</span> []</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> train_index, val_index <span class="kw">in</span> kf.split(X_escalado):</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>        X_ent, X_val <span class="op">=</span> X_escalado[train_index], X_escalado[val_index]</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>        y_ent, y_val <span class="op">=</span> y[train_index], y[val_index]</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>        modelo_ridge <span class="op">=</span> Lasso(alpha<span class="op">=</span>alpha, fit_intercept<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>        modelo_ridge.fit(X_ent, y_ent)</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>        y_val_pred <span class="op">=</span> modelo_ridge.predict(X_val)</span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>        ecm_val <span class="op">=</span> mean_squared_error(y_val, y_val_pred)</span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>        errores_fold.append(ecm_val)</span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>    lista_ecm_cv.append(np.mean(errores_fold))</span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Graficar ECM de validación cruzada frente a alpha</span></span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">5</span>))</span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a>plt.plot(valores_alpha_lineal, lista_ecm_cv, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Valor de α (regularización Lazo)'</span>)</span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'ECM promedio de validación cruzada'</span>)</span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'ECM de validación cruzada (5 pliegues) vs. α en regresión Lazo'</span>)</span>
<span id="cb8-38"><a href="#cb8-38" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb8-39"><a href="#cb8-39" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb8-40"><a href="#cb8-40" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-lasso" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-lasso-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="8_seleccion_de_modelos_files/figure-html/fig-lasso-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-lasso-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;8: Error de validación cruzada con <span class="math inline">\(k = 5\)</span> pliegues para la regresión lineal con regularización L1.
</figcaption>
</figure>
</div>
</div>
</div>
<div id="cell-fig-lasso-coeffs" class="cell" data-execution_count="10">
<details class="code-fold">
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Nuevos valores de alpha en escala logarítmica, extendidos hasta valores grandes</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>valores_alpha_log <span class="op">=</span> np.logspace(<span class="op">-</span><span class="dv">4</span>, <span class="dv">1</span>, <span class="dv">100</span>)  <span class="co"># de 1e-4 a 1e3</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Guardar coeficientes para cada valor de alpha</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>coeficientes_ridge_log <span class="op">=</span> []</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> alpha <span class="kw">in</span> valores_alpha_log:</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    modelo <span class="op">=</span> Lasso(alpha<span class="op">=</span>alpha)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    modelo.fit(X_escalado, y)</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    coeficientes_ridge_log.append(modelo.coef_)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>coeficientes_ridge_log <span class="op">=</span> np.array(coeficientes_ridge_log)</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Graficar los coeficientes en función de alpha (escala log en x)</span></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">5</span>))</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_total_variables):</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> i <span class="kw">in</span> variables_reales:</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>        plt.plot(valores_alpha_log, coeficientes_ridge_log[:, i], linewidth<span class="op">=</span><span class="fl">2.5</span>, label<span class="op">=</span><span class="ss">f'X</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span>, alpha<span class="op">=</span><span class="fl">0.9</span>)</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>        plt.plot(valores_alpha_log, coeficientes_ridge_log[:, i], color<span class="op">=</span><span class="st">'lightgray'</span>, linewidth<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>plt.xscale(<span class="st">'log'</span>)</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Valor de α (regularización Lazo, escala logarítmica)'</span>)</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Coeficientes del modelo'</span>)</span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Evolución de los coeficientes de regresión Lazo según α (escala logarítmica)'</span>)</span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>plt.legend(title<span class="op">=</span><span class="st">'Variables relevantes'</span>)</span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, which<span class="op">=</span><span class="st">'both'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-lasso-coeffs" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-lasso-coeffs-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="8_seleccion_de_modelos_files/figure-html/fig-lasso-coeffs-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-lasso-coeffs-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;9: Comportamiento de los coeficientes para la regresión lineal con regularización L1.
</figcaption>
</figure>
</div>
</div>
</div>
<p>En la <a href="#fig-lasso-coeffs" class="quarto-xref">Figura&nbsp;9</a> vemos que esta regularización hace tender los coeficientes poco importantes exactamente a cero. Por este motivo funciona mejor cuando la variable que se quiere predecir depende pocos regresores (como en este ejemplo).</p>
<p>Para entender por qué pasa esto podemos ver la <a href="#fig-lasso-vs-ridge" class="quarto-xref">Figura&nbsp;10</a> (sacada del libro). Las elipses representan diferentes niveles de la suma de errores al cuadrado. Siendo una ecuación cuadrática en los coeficientes nos podemos convencer que sus curvas de nivel deben ser cónicas que resultan ser elipses. La región llena es una curva de nivel de el término adicional agregado a la función de pérdida: Un círculo para L2 y un rombo para L1. La primera curva de nivel que intersecta el rombo tiende a hacerlo en uno de los ejes.</p>
<div id="fig-lasso-vs-ridge" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-lasso-vs-ridge-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/lasso_vs_ridge.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-lasso-vs-ridge-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;10: Regresión L1 vs L2, sacada del libro “Introduction to Statistical Learning”.
</figcaption>
</figure>
</div>
</section>
</section>
<section id="ejercicios-recomendados-para-la-prueba" class="level1">
<h1>Ejercicios Recomendados Para la Prueba</h1>
<p>6.1, 6.2, 6.4</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiado");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiado");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/jorgenorena\.github\.io\/machine_learning_course\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>
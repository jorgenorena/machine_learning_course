---
title: "Probabilidad"
---

## El dato

Para nosotros en este curso, un dato será una medición de algún sistema. Los datos pueden ser números reales, en cuyo caso los reportamos con una barra de error. Por ejemplo
$$
9.1300 \pm 0.0001\,.
$$
Note que reportamos el resultado con un número de cifras decimales compatibles con el error.

¿Pero qué es el error? En realidad al número reportado arriba también le falta información. Necesitamos especificar la confianza a la cual corresponde ese error. Por ejemplo podemos decir que tiene una confianza del $95\%$. Eso quiere decir que hay una probabilidad del $95\%$ asociada con ese error. El sentido de esto lo haremos más preciso cuando hablemos de probabilidad.

También son importantes los datos que se representan como números enteros o categorías. Por ejemplo, cada pixel de una imagen son tres números enteros que representan los colores rojo, verde y azul.

Para su descripción, decimos que los posibles resultados residen en un conjunto $S$. Un subconjunto de $S$ lo llamamos un *evento*. 

## Visualización de los datos

Cuando la medición nos da un solo número real, una manera útil de graficarla es mediante un *histograma*. Es decir, dividimos el intervalo de valores de la variable en un cierto número de subintervalos. El histograma nos dice cuántas veces obtuvimos una medición en el intervalo

``` {python}
import numpy as np
import matplotlib.pyplot as plt

mediciones = np.random.normal(loc=5, scale=1, size=1000)

plt.hist(mediciones)
plt.show()
```

En este gráfico cada barra es el número de datos que cae en el subintervalo. El gráfico nos da una idea de cómo se distribuyen los datos.

Veamos qué pasa si variamos la cantidad de subintervalos

``` {python}
# Número de subintervalos para el histograma 
bin_counts = [2, 5, 20, 50]

# Crear subfiguras
fig, axes = plt.subplots(2, 2, figsize=(6, 6))

# Graficar cada histograma 
for ax, bins in zip(axes.flatten(), bin_counts):
    ax.hist(mediciones, bins=bins)
    ax.set_title(f'Histograma con {bins} subintervalos')
    ax.set_xlabel('$x$')
    ax.set_ylabel('Frequencia')

plt.tight_layout()
plt.show()
```

Si aumentamos la cantidad de subintervalos usados, el gráfico se hace ruidoso, varía mucho el valor de cada intervalo. Si tenemos pocos subintervalos, es difícil intuir la distribución.

En varias dimensiones, es común describir los datos mediante gráficos de dispersión (scatterplots). Estos nos pueden decir dónde se concentran los resultados y si hay correlación entre variables.

``` {python}
import numpy as np
import matplotlib.pyplot as plt

# Gaussiana 2d con correlacion
x1_pure = np.random.normal(loc=0, scale=1, size=1000)
x2_pure = np.random.normal(loc=0, scale=1, size=1000)
x3 = np.random.normal(loc=0, scale=1, size=1000)
x1 = 0.3 * x1_pure + 0.7 * x2_pure
x2 = 0.5 * x1_pure + 0.5 * x2_pure

fig, axes = plt.subplots(2, 2, figsize=(6, 3))
axes[0,0].scatter(x1, x2)
axes[0,0].set_xlabel('$x_1$')
axes[0,0].set_ylabel('$x_2$')
axes[0,1].scatter(x1, x3)
axes[0,1].set_xlabel('$x_1$')
axes[0,1].set_ylabel('$x_3$')
axes[1,0].scatter(x2, x3)
axes[1,0].set_xlabel('$x_2$')
axes[1,0].set_ylabel('$x_3$')
plt.tight_layout()
plt.show()
```

## Estadísticas sencillas

Si queremos tener una idea del valor típico de lis datos, podemis tomar el *promedio* o *media aritmética* que denotamos con una barra sobre la cantidad

$$
\bar{x} = \frac{1}{N}\sum_{i=1}^N x_i\,,
$$

donde $N$ es el número de puntos de datos.

Si en cambio queremos saber cuánto están dispersos respecto a este valor, calculamos la varianza

$$
\sigma^2 = \frac{1}{N}\sum_{i=1}^N (x_i - \bar{x})^2\,.
$$

la *desviación estándar* $\sigma$ es la raíz cuadrada de la varianza, y como lo dice su nombre nos dice cuánto se desvía típicamente un dato. 

A veces cada dato contiene más de una variable. Por ejemplo cuando medimos temperatura y presión de un sistema termodinámico. Una manera de medir la relación entre las variables es mediante su *covarianza*

$$
\text{cov}\,(x,y) = \frac{1}{N}\sum_{i=1}^N(x_i - \bar{x})(y_i - \bar{y})\,.
$$

Ilustremos esto mediante una figura

```{python}
import numpy as np
import matplotlib.pyplot as plt

rng = np.random.default_rng(0)
N = 3000

def scatter_with_cov(x, y, title):
    cov = np.cov(x, y, ddof=1)[0, 1]
    fig, ax = plt.subplots(figsize=(5, 5))
    ax.scatter(x, y, s=6, alpha=0.35)
    ax.set_title(f"{title}\nSample cov(x,y) = {cov:.3f}")
    ax.set_xlabel("x")
    ax.set_ylabel("y")
    ax.set_aspect("equal", adjustable="box")
    ax.grid(True, alpha=0.2)
    plt.show()

# 1) Zero covariance (independent Gaussian)
x1 = rng.normal(size=N)
y1 = rng.normal(size=N)
scatter_with_cov(x1, y1, "1) Zero covariance (independent)")

# 2) Positive covariance (correlated Gaussian)
mean = [0, 0]
Sigma_pos = np.array([[1.0, 0.8],
                      [0.8, 1.0]])
xy2 = rng.multivariate_normal(mean, Sigma_pos, size=N)
scatter_with_cov(xy2[:, 0], xy2[:, 1], "2) Positive covariance")

# 3) Negative covariance (anti-correlated Gaussian)
Sigma_neg = np.array([[1.0, -0.8],
                      [-0.8, 1.0]])
xy3 = rng.multivariate_normal(mean, Sigma_neg, size=N)
scatter_with_cov(xy3[:, 0], xy3[:, 1], "3) Negative covariance")

# 4) ~Zero covariance despite strong non-linear relation (noisy ring)
t = rng.uniform(0, 2*np.pi, size=N)
r = 1.0 + 0.07 * rng.normal(size=N)  # small radial noise
x4 = r * np.cos(t)
y4 = r * np.sin(t)
scatter_with_cov(x4, y4, "4) ~Zero covariance, but non-linear dependence (ring)")
```

<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Distribuciones de Probabilidad y Estimación – Aprendizaje Automático para Físicos</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-e13f217ceb0135cb77e1494052e28e8a.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar docked nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Aprendizaje Automático para Físicos</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-clases" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Clases</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-clases">    
        <li class="dropdown-header">Probabilidad y Estadística</li>
        <li>
    <a class="dropdown-item" href="./1_probabilidad.html">
 <span class="dropdown-text">1. Probabilidad</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./2_distribuciones_y_estimacion.html">
 <span class="dropdown-text">2. Distribuciones y Estimación</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./3_verosimilitud.html">
 <span class="dropdown-text">3. Verosimilitud</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./4_minimos_cuadrados_intervalos.html">
 <span class="dropdown-text">4. Mínimos Cuadrados e Intervalos</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./5_testeo_de_hipotesis_entropia.html">
 <span class="dropdown-text">5. Testeo de Hipótesis y Entropía</span></a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li class="dropdown-header">Aprendizaje Automático</li>
        <li>
    <a class="dropdown-item" href="./6_aprendizaje_automatico_regresion_lineal.html">
 <span class="dropdown-text">6. Aprendizaje Automático y Regresión Lineal</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./7_clasificacion.html">
 <span class="dropdown-text">7. Clasificación</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./8_seleccion_de_modelos.html">
 <span class="dropdown-text">8. Selección de Modelos</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./9_arboles_bosques_boosting.html">
 <span class="dropdown-text">9. Árboles, Bosques y Boosting</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./10_svm_y_no_supervisado.html">
 <span class="dropdown-text">10. SVM y Aprendizaje No Supervisado</span></a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li class="dropdown-header">Redes Neuronales</li>
        <li>
    <a class="dropdown-item" href="./11_perceptron_y_redes_conexas.html">
 <span class="dropdown-text">11. Perceptrón y Redes Conexas y Pérdidas</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./12_gradient_descent_and_autodiff.html">
 <span class="dropdown-text">12. Descenso de Gradiente y Auto-diferenciación</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./13_evaluacion_y_regularizacion_de_nn.html">
 <span class="dropdown-text">13. Evaluación y Regularización de redes neuronales</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./14_redes_convolucionales.html">
 <span class="dropdown-text">14. Redes Convolucionales</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./15_redes_residuales.html">
 <span class="dropdown-text">15. Redes Residuales</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./16_transformadores.html">
 <span class="dropdown-text">16. Transformadores y el mecanismo de atención</span></a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li class="dropdown-header">Algunas aplicaciones</li>
        <li>
    <a class="dropdown-item" href="./17_flujos_normalizantes.html">
 <span class="dropdown-text">17. Flujos Normalizantes</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./18_PINNs.html">
 <span class="dropdown-text">18. Redes Neuronales Informadas por la Física (PINNs)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./19_Operador_Neural.html">
 <span class="dropdown-text">19. Operadores Neuronales</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="./about.html"> 
<span class="menu-text">Acerca de</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./1_probabilidad.html">Probabilidad y Estadística</a></li><li class="breadcrumb-item"><a href="./2_distribuciones_y_estimacion.html">2. Distribuciones y Estimación</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Probabilidad y Estadística</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1_probabilidad.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1. Probabilidad</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2_distribuciones_y_estimacion.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">2. Distribuciones y Estimación</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3_verosimilitud.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3. Verosimilitud</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./4_minimos_cuadrados_intervalos.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4. Mínimos Cuadrados e Intervalos</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./5_testeo_de_hipotesis_entropia.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5. Testeo de Hipótesis y Entropía</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Aprendizaje Automático</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./6_aprendizaje_automatico_regresion_lineal.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">6. Aprendizaje Automático y Regresión Lineal</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./7_clasificacion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">7. Clasificación</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./8_seleccion_de_modelos.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">8. Selección de Modelos</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./9_arboles_bosques_boosting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">9. Árboles, Bosques y Boosting</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10_svm_y_no_supervisado.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">10. SVM y Aprendizaje No Supervisado</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Redes Neuronales</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11_perceptron_y_redes_conexas.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">11. Perceptrón, Redes Conexas y Pérdidas</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12_gradient_descent_and_autodiff.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">12. Descenso de Gradiente y Auto-diferenciación</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13_evaluacion_y_regularizacion_de_nn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">13. Evaluación y Regularización de redes neuronales</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14_redes_convolucionales.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">14. Redes Convolucionales</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./15_redes_residuales.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">15. Redes Residuales</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./16_transformadores.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">16. Transformadores y el mecanismo de atención</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Algunas aplicaciones</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./17_flujos_normalizantes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">17. Flujos Normalizantes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./18_PINNs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">18. Redes Neuronales Informadas por la Física (PINNs)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./19_Operador_Neural.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">19. Operadores Neuronales</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#distribuciones-de-probabilidad" id="toc-distribuciones-de-probabilidad" class="nav-link active" data-scroll-target="#distribuciones-de-probabilidad">Distribuciones de Probabilidad</a>
  <ul class="collapse">
  <li><a href="#una-variable-aleatoria" id="toc-una-variable-aleatoria" class="nav-link" data-scroll-target="#una-variable-aleatoria">Una variable aleatoria</a>
  <ul class="collapse">
  <li><a href="#distribuciones-de-probabilidad-1" id="toc-distribuciones-de-probabilidad-1" class="nav-link" data-scroll-target="#distribuciones-de-probabilidad-1">Distribuciones de probabilidad</a></li>
  <li><a href="#valores-esperados" id="toc-valores-esperados" class="nav-link" data-scroll-target="#valores-esperados">Valores esperados</a></li>
  <li><a href="#función-generatriz-y-característica" id="toc-función-generatriz-y-característica" class="nav-link" data-scroll-target="#función-generatriz-y-característica">Función generatriz y característica</a></li>
  </ul></li>
  <li><a href="#varias-variables" id="toc-varias-variables" class="nav-link" data-scroll-target="#varias-variables">Varias variables</a>
  <ul class="collapse">
  <li><a href="#distribución-de-probabilidad-conjunta" id="toc-distribución-de-probabilidad-conjunta" class="nav-link" data-scroll-target="#distribución-de-probabilidad-conjunta">Distribución de probabilidad conjunta</a></li>
  <li><a href="#distribución-marginal-y-condicional" id="toc-distribución-marginal-y-condicional" class="nav-link" data-scroll-target="#distribución-marginal-y-condicional">Distribución marginal y condicional</a></li>
  <li><a href="#momentos-y-valores-esperados" id="toc-momentos-y-valores-esperados" class="nav-link" data-scroll-target="#momentos-y-valores-esperados">Momentos y valores esperados</a></li>
  </ul></li>
  <li><a href="#funciones-de-una-variable-aleatoria" id="toc-funciones-de-una-variable-aleatoria" class="nav-link" data-scroll-target="#funciones-de-una-variable-aleatoria">Funciones de una variable aleatoria</a></li>
  </ul></li>
  <li><a href="#algunas-distribuciones-de-probabilidad" id="toc-algunas-distribuciones-de-probabilidad" class="nav-link" data-scroll-target="#algunas-distribuciones-de-probabilidad">Algunas distribuciones de probabilidad</a>
  <ul class="collapse">
  <li><a href="#uniforme" id="toc-uniforme" class="nav-link" data-scroll-target="#uniforme">Uniforme</a></li>
  <li><a href="#normal-gaussiana" id="toc-normal-gaussiana" class="nav-link" data-scroll-target="#normal-gaussiana">Normal (Gaussiana)</a></li>
  <li><a href="#binomial" id="toc-binomial" class="nav-link" data-scroll-target="#binomial">Binomial</a></li>
  <li><a href="#poisson" id="toc-poisson" class="nav-link" data-scroll-target="#poisson">Poisson</a></li>
  </ul></li>
  <li><a href="#estimación-y-muestreo" id="toc-estimación-y-muestreo" class="nav-link" data-scroll-target="#estimación-y-muestreo">Estimación y Muestreo</a>
  <ul class="collapse">
  <li><a href="#muestras-aleatorias-y-estimadores" id="toc-muestras-aleatorias-y-estimadores" class="nav-link" data-scroll-target="#muestras-aleatorias-y-estimadores">Muestras aleatorias y estimadores</a></li>
  <li><a href="#propiedades-de-estimadores" id="toc-propiedades-de-estimadores" class="nav-link" data-scroll-target="#propiedades-de-estimadores">Propiedades de estimadores</a></li>
  <li><a href="#estimadores-de-la-media-y-la-varianza" id="toc-estimadores-de-la-media-y-la-varianza" class="nav-link" data-scroll-target="#estimadores-de-la-media-y-la-varianza">Estimadores de la media y la varianza</a></li>
  </ul></li>
  <li><a href="#ejercicios-sugeridos-para-estudiar-para-la-prueba" id="toc-ejercicios-sugeridos-para-estudiar-para-la-prueba" class="nav-link" data-scroll-target="#ejercicios-sugeridos-para-estudiar-para-la-prueba">Ejercicios sugeridos para estudiar para la prueba</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./1_probabilidad.html">Probabilidad y Estadística</a></li><li class="breadcrumb-item"><a href="./2_distribuciones_y_estimacion.html">2. Distribuciones y Estimación</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">Distribuciones de Probabilidad y Estimación</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="distribuciones-de-probabilidad" class="level1">
<h1>Distribuciones de Probabilidad</h1>
<p>Hablamos de <strong>variables aleatorias</strong> como variables que pueden tomar un valor aleatorio dentro de un cierto conjunto. Cada valor prosible tiene una cierta probabilidad. Esto lo haremos más preciso en esta sección.</p>
<section id="una-variable-aleatoria" class="level2">
<h2 class="anchored" data-anchor-id="una-variable-aleatoria">Una variable aleatoria</h2>
<section id="distribuciones-de-probabilidad-1" class="level3">
<h3 class="anchored" data-anchor-id="distribuciones-de-probabilidad-1">Distribuciones de probabilidad</h3>
<p>Consideremos primero una variable discreta. Decimos que la variable <span class="math inline">\(x\)</span> tiene una probabilidad <span class="math inline">\(P[x_k]\)</span> de tomar el valor <span class="math inline">\(x_k\)</span>. Este valor está dado por una <strong>distribución de probabilidad</strong>. Es decir una función <span class="math inline">\(f\)</span> tal que <span class="math display">\[
P[x_k] = f(x_k)\,.
\]</span> Esta cumple</p>
<ul>
<li><span class="math inline">\(f\)</span> es univaluada y <span class="math inline">\(f(x) \geq 0\)</span>.</li>
<li>La probabilidad total es <span class="math inline">\(1\)</span>, es decir <span class="math inline">\(\sum_i f(x_i) = 1\)</span>.</li>
</ul>
<p>Definimos también la <strong>distribución cumulativa de probabilidad</strong> <span class="math display">\[
F(x) = \sum_{x_k \leq x} f(x_k)\,.
\]</span> Es decir, es la probabilidad de obtener un valor menor a <span class="math inline">\(x\)</span>.</p>
<p>Para variables que toman valores continuos, la probabilidad de un valor dado tiende a cero (como hay infinitos valores, la probabilidad de cada uno debe ser minúscula para que su suma sea <span class="math inline">\(1\)</span>). Por ese motivo no hablamos de una distribución de probabilidad sino de una <strong>función de densidad de probabilidad</strong> <span class="math inline">\(f(x)\)</span> tal que la probabilidad de obtener un resultado en el intervalo <span class="math inline">\([a,b]\)</span> es <span class="math display">\[
P[a \leq x \leq b] = \int_a^bdx\,f(x)\,.
\]</span> Esta cumple</p>
<ul>
<li><span class="math inline">\(f\)</span> es univaluada y <span class="math inline">\(f(x) \geq 0\)</span>.</li>
<li>La probabilidad total es <span class="math inline">\(1\)</span>, es decir <span class="math inline">\(\int_{-\infty}^\infty dx\,f(x) = 1\)</span>.</li>
</ul>
<p>Análogamente definimos la distribución cumulativa de probabilidad <span class="math display">\[
F(x) = \int_{-\infty}^x dx'\,f(x')\,.
\]</span></p>
</section>
<section id="valores-esperados" class="level3">
<h3 class="anchored" data-anchor-id="valores-esperados">Valores esperados</h3>
<p>Definimos el <strong>valor esperado</strong> de una variable discreta como <span class="math display">\[
\langle x\rangle \equiv \sum_x xf(x)\,.
\]</span> Para una variable continua <span class="math display">\[
\langle x\rangle \equiv \int_{-\infty}^\infty dx\,xf(x)\,.
\]</span></p>
<p>De esta manera los <strong>momentos</strong> son <span class="math display">\[
\mu'_n \equiv \langle x^n \rangle\,,
\]</span> y los <strong>momentos centrales</strong> <span class="math display">\[
\mu_n \equiv \left\langle (x - \langle x\rangle)^n\right\rangle\,.
\]</span></p>
<p>De la definición de valor esperado se puede demostrar para una constante <span class="math inline">\(c\)</span> <span class="math display">\[
\langle cx\rangle = c\langle x\rangle\,,\quad \langle x_1 + x_2 + ... + x_n\rangle = \langle x_1\rangle + \langle x_2 \rangle + ... + \langle x_n\rangle\,.
\]</span> Además si las variables <span class="math inline">\(x_1, ..., x_n\)</span> son independientes <span class="math display">\[
\langle x_1 ... x_n\rangle = \langle x_1\rangle ...\langle x_n\rangle\,.
\]</span></p>
</section>
<section id="función-generatriz-y-característica" class="level3">
<h3 class="anchored" data-anchor-id="función-generatriz-y-característica">Función generatriz y característica</h3>
<p>Definimos la <strong>función generatriz</strong> <span class="math display">\[
M_x(t) \equiv \langle e^{xt} \rangle\,.
\]</span> Expandiendo en Taylor tenemos que <span class="math display">\[
M_x(t) = \left\langle1 + xt + \frac{1}{2}(xt)^2 + ...\right\rangle = \sum_{n=0}^\infty \frac{1}{n!}\mu'_n t^n\,.
\]</span> De esta expresión vemos que <span class="math display">\[
\mu'_n = \left.\frac{\partial^n}{\partial t^n}M_x(t)\right|_{t=0}\,.
\]</span> Entonces decimos que podemos <em>generar los momentos</em> de la distribución.</p>
<p>En la mayoría de los casos, si dos distribuciones tienen la misma función generatriz, entonces son la misma distribución. Para algunas distribuciones la suma no converge, tal que se usa en cambio la <strong>función característica</strong> <span class="math display">\[
\phi_x(t) \equiv \langle e^{itx}\rangle\,.
\]</span></p>
<p>También es útil definir la <strong>función generatriz conexa</strong> <span class="math display">\[
\ln M_x(t) \equiv \kappa_1 t + \frac{1}{2}\kappa_2 t^2 + ...\,,
\]</span> donde <span class="math inline">\(\kappa\)</span> son los <strong>cumulantes</strong>. Cuando dos distribuciones tienen los mismos cumulantes son iguales (si estos existen para ambas). El primer cumulante corresponde a la media <span class="math inline">\(\kappa_1 = \mu\)</span> y el segundo a la varianza <span class="math inline">\(\kappa_2 = \sigma^2\)</span>.</p>
</section>
</section>
<section id="varias-variables" class="level2">
<h2 class="anchored" data-anchor-id="varias-variables">Varias variables</h2>
<section id="distribución-de-probabilidad-conjunta" class="level3">
<h3 class="anchored" data-anchor-id="distribución-de-probabilidad-conjunta">Distribución de probabilidad conjunta</h3>
<p>Si tenemos varias variables aleatorias, las definiciones son muy análogas. Por ejemplo, la <strong>distribución de probabilidad conjunta</strong> <span class="math display">\[
P[a_1\leq x_1 \leq b_1, ..., a_n \leq x_n \leq b_n] \equiv \int_{a_n}^{b_n}...\int_{a_1}^{b_1}\prod_{i=1}^n dx_i\, f(x_1, ..., x_n)\,.
\]</span></p>
</section>
<section id="distribución-marginal-y-condicional" class="level3">
<h3 class="anchored" data-anchor-id="distribución-marginal-y-condicional">Distribución marginal y condicional</h3>
<p>Si nos preguntamos cuál es el valor de una variable, independientemente del valor que tomen todas las demás, sólo tenemos que sumar sobre todos los valores de las demás variables. Esta se llama la <strong>distribución marginal</strong> <span class="math display">\[
f^M(x_1) = \int_{-\infty}^\infty...\int_{-\infty}^\infty \prod_{i=2}^n dx_i\,f(x_1, x_2, ..., x_n)\,.
\]</span> Análogamente, si queremos la probabilidad conjunta para algunas variables, marginalizamos sobre todas las demás <span class="math display">\[
f^M(x_1, ..., x_m) = \int_{-\infty}^\infty...\int_{-\infty}^\infty \prod_{i=m+1}^n dx_i\,f(x_1, x_2, ..., x_n)\,.
\]</span></p>
<p>Una pregunta distinta, es si <em>fijamos</em> el valor de las demás variables y nos preguntamos por la probabilidad de las restantes. Esta es la <strong>distribución condicional</strong> <span class="math display">\[
f^C(x_1, ..., x_m| x_{m+1}, ..., x_n) \equiv \frac{f(x_1, ..., x_n)}{f^M(x_{m+1}, ..., x_n)}\,.
\]</span></p>
<p>Esto nos permite escribir por ejemplo la siguiente relación <span class="math display">\[
f^C(x|y) = \frac{f^C(y|x)f^M(x)}{f^M(y)}\,,
\]</span> o también <span class="math display">\[
f(x, y) = f^C(x|y)f^M(y)\,.
\]</span> Decimos que dos variables son <strong>independientes</strong> si <span class="math display">\[
f(x, y) = f^M(x)f^M(y)\,.
\]</span></p>
</section>
<section id="momentos-y-valores-esperados" class="level3">
<h3 class="anchored" data-anchor-id="momentos-y-valores-esperados">Momentos y valores esperados</h3>
<p>Se definen de forma análoga a una variable. Por ejemplo, definimos la covarianza como el segundo momento central <span class="math display">\[
\text{cov}(x_i, x_j) \equiv \sigma_{ij} \equiv \int_{-\infty}^\infty...\int_{-\infty}^\infty \prod_{i=1}^n dx_i\, (x_i - \mu_i)(x_j - \mu_j) f(x_1, ..., x_n)\,.
\]</span> La condición <span class="math inline">\(\sigma_{ij} = 0\)</span> es necesaria (pero no suficiente) para que dos variables sean independientes.</p>
</section>
</section>
<section id="funciones-de-una-variable-aleatoria" class="level2">
<h2 class="anchored" data-anchor-id="funciones-de-una-variable-aleatoria">Funciones de una variable aleatoria</h2>
<p>Supongamos que la cantidad <span class="math inline">\(y\)</span> es una función de la variable aleatoria <span class="math inline">\(x\)</span>. Podemos calcular su distribución de probabilidad haciendo un simple cambio de variable <span class="math display">\[
f(y) = \sum_{x}f(x)\left|\frac{dx}{dy}\right|\,.
\]</span> Donde la suma es sobre todos los puntos tal que <span class="math inline">\(y = y(x)\)</span>.</p>
<p>Cuando hay varias variables, usamos el Jacobiano.</p>
</section>
</section>
<section id="algunas-distribuciones-de-probabilidad" class="level1">
<h1>Algunas distribuciones de probabilidad</h1>
<section id="uniforme" class="level2">
<h2 class="anchored" data-anchor-id="uniforme">Uniforme</h2>
<p>Si la probabilidad es la misma en todas partes dentro de un intervalo <span class="math display">\[
f(x) \equiv u(x; a, b) = \begin{cases}
\frac{1}{b - a}\quad a\leq x \leq b\,
0\quad \text{de otra manera}
\end{cases}\,.
\]</span> Esta probabilidad es útil por ejemplo para generar números aleatorios. Cualquier variable se puede convertir en una variable con distribución uniforme mediante <span class="math inline">\(u = F[x]\)</span>.</p>
</section>
<section id="normal-gaussiana" class="level2">
<h2 class="anchored" data-anchor-id="normal-gaussiana">Normal (Gaussiana)</h2>
<p>Ubicua en física por motivos que discutiremos en unos minutos. La famosa distribución a campana <span class="math display">\[
f(x) \equiv n(x; \mu, \sigma) = \frac{1}{\sqrt{2\pi}\sigma}\exp\left[-\frac{(x - \mu)^2}{2\sigma^2}\right]\,.
\]</span> Con función generatriz <span class="math display">\[
M_x(t) = \langle e^{xt}\rangle = e^{t\mu + \sigma^2 t^2/2}\,.
\]</span> Podemos tomar el logaritmo para obtener los cumulantes <span class="math display">\[
\ln M_x(t) = t\mu + \frac{1}{2}t^2\sigma^2\,.
\]</span> De aquí se puede deducir que <span class="math inline">\(\kappa_1 = \mu\)</span> y <span class="math inline">\(\kappa_2 = \sigma^2\)</span> por lo que la varianza es <span class="math inline">\(\sigma^2\)</span>. La función característica es análoga <span class="math display">\[
\phi(t) = e^{it\mu - t^2\sigma^2/2}\,.
\]</span></p>
<p>La utilidad de la gaussiana es que por motivos que vermos representa los errores de muchas cantidades medidas. Entonces es útil saber las probabilidades de obtener un resultado a un cierto número de desviaciones estándar de la media</p>
<ul>
<li><span class="math inline">\(1\sigma\)</span> es <span class="math inline">\(68.3\%\)</span>.</li>
<li><span class="math inline">\(2\sigma\)</span> es <span class="math inline">\(95.4\%\)</span>.</li>
<li><span class="math inline">\(3\sigma\)</span> es <span class="math inline">\(99.7\%\)</span>.</li>
</ul>
<p>Para varias variables es similar <span class="math display">\[
f(\mathbf{x}) = \frac{1}{(2\pi)^{n/2}|V|^{1/2}}\exp\left[-\frac{1}{2}(\mathbf{x} - \mathbf{\mu})^T V^{-1} (\mathbf{x} - \mathbf{\mu})\right]\,.
\]</span> La covarianza es fácil de calcular y es <span class="math inline">\(\sigma_{ij} = V_{ij}\)</span>.</p>
<p>Integrando, se puede demostrar que la distribución marginal también es una gaussiana.</p>
</section>
<section id="binomial" class="level2">
<h2 class="anchored" data-anchor-id="binomial">Binomial</h2>
<p>La distribución binomial es para una variable discreta. Representa intentar muchas veces un experimento con probabilidad de éxito <span class="math inline">\(p\)</span>. Esta distribución es la probabilidad de obtener <span class="math inline">\(r\)</span> éxitos en <span class="math inline">\(n\)</span> intentos <span class="math display">\[
f(r; p, n) = \frac{n!}{r!(n - r)!}p^r (1 - p)^{n - r}\,.
\]</span> No usaremos mucho esta distribución. Esta y otras se pueden encontrar descritas en el libro.</p>
</section>
<section id="poisson" class="level2">
<h2 class="anchored" data-anchor-id="poisson">Poisson</h2>
<p>Es muy importante en física. Representa la probabilidad de obtener <span class="math inline">\(r\)</span> éxitos cuando <span class="math inline">\(n\)</span> tiende a ser un número grande y <span class="math inline">\(p\)</span> tiende a ser pequeño tal que <span class="math inline">\(pn \equiv \lambda\)</span> permanece constante <span class="math display">\[
\lim_{n\rightarrow \infty} \frac{1}{r!}\frac{n!}{(n-r)!}\left(\frac{\lambda}{n}\right)^r\left(1 - \frac{\lambda}{n}\right)^{n - r} = \lim_{n\rightarrow \infty}\frac{1}{r!}n^r\frac{\lambda^r}{n^r}\left(1 - \frac{\lambda}{n}\right)^n = \frac{1}{r!}\lambda^r e^{-\lambda}\,.
\]</span> Entonces definimos la <strong>distribución de Poisson</strong> <span class="math display">\[
f(r; \lambda) = \frac{1}{r!}\lambda^r e^{-\lambda}\,.
\]</span> La función generatriz es <span class="math display">\[
M_r(t) = e^{-\lambda}\sum_{r = 0}^\infty \frac{1}{k!}(\lambda e^t)^k = e^{-\lambda}\exp(\lambda e^t)\,.
\]</span> Expandiendo, vemos que todos los cumulantes de la distribución de Poisson son iguales <span class="math display">\[
\ln M_r(t) = \lambda e^t - \lambda = \sum_{n=1}^\infty \frac{1}{n!}t^n\lambda\,.
\]</span> es decir <span class="math inline">\(\kappa_i = \lambda\)</span>. Es decir que su media es <span class="math inline">\(\lambda\)</span> y su varianza es <span class="math inline">\(\lambda\)</span>.</p>
</section>
</section>
<section id="estimación-y-muestreo" class="level1">
<h1>Estimación y Muestreo</h1>
<section id="muestras-aleatorias-y-estimadores" class="level2">
<h2 class="anchored" data-anchor-id="muestras-aleatorias-y-estimadores">Muestras aleatorias y estimadores</h2>
<p>Definimos variables <strong>independientes e idénticamente distribuídas (i.i.d.)</strong> como aquellas variables que provienen de una misma distribución de probabilidad y que además son independientes.</p>
<p>Para nosotros una <strong>muestra aleatoria</strong> será un conjunto de variables i.i.d. Esto modela el repetir un experimento u observación muchas veces. Como son i.i.d. su distribución conjunta se escribe <span class="math display">\[
f(x_1, ..., x_n) = f(x_1)...f(x_n)\,,
\]</span> para alguna distribución <span class="math inline">\(f(x)\)</span>.</p>
</section>
<section id="propiedades-de-estimadores" class="level2">
<h2 class="anchored" data-anchor-id="propiedades-de-estimadores">Propiedades de estimadores</h2>
<p>Muchas veces desconocemos la forma exacta de <span class="math inline">\(f(x)\)</span> pero tenemos un modelo para producirla. Ese modelo puede depender de unos parámetros libres (masas de partículas, varianzas, algún parámetro experimental, …) <span class="math inline">\(\mathbf{\theta} = (\theta_1, ..., \theta_m)\)</span>. Queremos sacar el valor de esos parámetros a partir de los datos. Nuestra aproximación a ese valor usando los datos se llama un <strong>estimador</strong> <span class="math inline">\(\hat{\theta}_n\)</span>, que depende del número de datos tomados <span class="math inline">\(n\)</span>.</p>
<p>Puede haber muchos estimadores diferentes, dependiendo del método usado. Discutamos cómo podemos evaluar si un estimador es bueno y en qué sentido lo puede ser.</p>
<p>Una propiedad importante de un estimador es que sea <strong>consistente</strong>. Es decir, para todo <span class="math inline">\(\epsilon &gt; 0\)</span> <span class="math display">\[
\lim_{n\rightarrow \infty} P(|\hat{\theta}_n - \theta| &gt; \epsilon) = 0\,.
\]</span> En lenguaje más cristiano, un estimador consistente es aquel que tiende al verdadero valor del parámetro si tenemos infinitos datos.</p>
<p>Que un estimador sea consistente no quiere decir que para una cantidad finita de datos nos de una buena aproximación al verdadero valor. Para caracterizar cuándo es buena la aproximación definimos otro par de propiedades.</p>
<p>Definimos el <strong>sesgo</strong> (muchas veces llamado por su nombre inglés <strong>bias</strong>) <span class="math display">\[
b \equiv \langle \hat{\theta}_n\rangle - \theta\,.
\]</span> Un estimador <strong>no sesgado</strong> si <span class="math inline">\(b = 0\)</span>. En general nos van a interesar muchos estimadores sesgados, pero queremos tratar de mantener el sesgo bajo control.</p>
<p>Además de un sesgo, un estimador tiene una varianza. Como es una cantidad que se obtiene operando sobre <span class="math inline">\(n\)</span> variables aleatorias, el mismo estimador es una variable aleatoria. Por lo tanto tiene una distribución de probabilidad y una varianza. Si la varianza es muy grande, el estimador puede ser problemático porque al medir obtenemos sólo un valor, y este puede estar muy lejos del valor verdadero porque la distribución es muy esparcida.</p>
<p>Decimos que un estimador es <strong>eficiente</strong> si la varianza cae rápidamente a medida que aumentamos <span class="math inline">\(n\)</span>.</p>
<p>Lo que nos interesa acotar en realidad es la diferencia entre el valor verdadero y el estimado. Este se relaciona con el sesgo y la varianza <span class="math display">\[
\left\langle(\hat{\theta}_n - \theta)^2\right\rangle = \left\langle(\hat{\theta}_n - \langle\hat{\theta}_n\rangle+ b)^2\right\rangle = \left\langle(\hat{\theta}_n - \langle\hat{\theta}_n\rangle)^2\right\rangle +2b\left\langle(\hat{\theta}_n - \langle\hat{\theta}_n\rangle)\right\rangle + b^2 = \sigma^2_{\hat{\theta}} + b^2\,.
\]</span> Entonces la varianza del error cometido es la suma de la varianza del estimador y el cuadrado del sesgo. Es decir que idealmente queremos reducir ambos para tener errores pequeños.</p>
<p>Veremos que en muchos métodos al aumentar el sesgo disminuye la varianza y vice versa, tal que debemos buscar un equilibrio entre ambos.</p>
</section>
<section id="estimadores-de-la-media-y-la-varianza" class="level2">
<h2 class="anchored" data-anchor-id="estimadores-de-la-media-y-la-varianza">Estimadores de la media y la varianza</h2>
<p>Para dar un ejemplo, supongamos que queremos encontrar la media y la varianza de una distribución a partir de una muestra. Existen estimadores no sesgados para ambos.</p>
<p>Para la media, el estimador es el promedio sobre la muestra <span class="math display">\[
\hat{\mu} = \frac{1}{n}\sum_{i = 1}^n x_i \equiv \bar{x}\,.
\]</span> Veamos que es no sesgado recordando que todos vienen de la misma distribución con media <span class="math inline">\(\mu\)</span> <span class="math display">\[
\langle \hat{\mu}\rangle = \frac{1}{n}\sum_{i=1}^n \langle x_i\rangle = \frac{1}{n}\sum_{i=1}^n \mu = \mu\,.
\]</span></p>
<p>Para la varianza es un poco más sutil. Queremos escribir una expresión que dependa sólo de los datos. Para obtener un estimador no sesgado necesitamos escribir <span class="math display">\[
\hat{\sigma}^2 = \frac{1}{n - 1}\sum_{i=1}^n(x_i - \bar{x})^2\,.
\]</span> Ese denominador no es lo que uno esperaría ingenuamente. Si yo no conociera este tema, habría dicho que el estimador debería ser el promedio sobre las desviaciones al cuadrado, pero el denominador no corresponde a esa intuición. Para ver de dónde viene demostremos que no es sesgado <span class="math display">\[
\begin{align}
\langle \hat{\sigma}^2\rangle &amp;= \frac{1}{n - 1}\sum_{i = 1}^n \left\langle(x_i - \bar{x})^2\right\rangle\\
&amp;= \frac{1}{n - 1}\sum_{i = 1}^n \left\langle\left(x_i - \frac{1}{n}\sum_{j=1}^n x_j\right)^2\right\rangle\\
&amp;= \frac{n}{n - 1} \left\langle\left(x_1 - \frac{1}{n}\sum_{j=1}^n x_j\right)^2\right\rangle\\
&amp;= \frac{n}{n - 1} \left(\langle x_1^2\rangle - \frac{2}{n}\sum_{j=1}^n \langle x_1 x_j\rangle + \frac{1}{n^2}\sum_{j,k=1}^n \langle x_j x_k\rangle \right)\\
&amp;= \frac{n}{n - 1} \left(\langle x_1^2\rangle - \frac{1}{n}\sum_{j=1}^n \langle x_1 x_j\rangle\right)\\
&amp;= \frac{n}{n - 1} \left(\left(1 - \frac{1}{n}\right)\langle x_1^2\rangle - \frac{1}{n}\sum_{j=2}^n \langle x_1 x_j\rangle\right)\\
&amp;= \frac{n}{n - 1} \left(\left(1 - \frac{1}{n}\right)\langle x_1^2\rangle - \frac{1}{n}\sum_{j=2}^n \langle x_1\rangle\langle x_j\rangle\right)\\
&amp;= \frac{n}{n - 1} \left(\frac{n - 1}{n}\langle x_1^2\rangle - \frac{n - 1}{n}\mu^2\right) = \langle x^2\rangle - \mu^2 = \sigma^2\,.
\end{align}
\]</span> Para ir de la segunda a la tercera igualdad hemos usado el hecho que todos los términos de la suma deben dar el mismo resultado ya que las variables son idénticamente distribuídas. Para ir de la cuarta a la quinta hemos usado ese mismo truco. Para ir de la sexta a la séptima hemos usado el hecho que las variables son independientes tal que <span class="math inline">\(\langle x_1 x_j\rangle = \langle x_1\rangle\langle x_j\rangle\)</span> para <span class="math inline">\(j\neq 1\)</span>.</p>
</section>
</section>
<section id="ejercicios-sugeridos-para-estudiar-para-la-prueba" class="level1">
<h1>Ejercicios sugeridos para estudiar para la prueba</h1>
<p>3.4, 3.5, 4.2, 4.7, 5.1</p>
<p>Si conocemos la media <span class="math inline">\(\mu\)</span> de una distribución, escriba un estimador para la varianza <span class="math display">\[
\hat{\sigma}^2 = \alpha \sum_{i=1}^n (x_i - \mu)^2\,.
\]</span> Encuentre la constante <span class="math inline">\(\alpha\)</span> para que el estimador sea no sesgado. Bonus: ¿Tiene este estimador una varianza menor a la del estimador visto en clase?</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/jorgenorena\.github\.io\/machine_learning_course\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>